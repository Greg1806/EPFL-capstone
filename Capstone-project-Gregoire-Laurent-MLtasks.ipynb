{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timing codes\n",
    "import time\n",
    "# start = time.time()\n",
    "# ..code here..\n",
    "# end = time.time()\n",
    "# print('{:.3} seconds'.format(end-start))\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "#for i in tqdm(range(0, 100), desc =\"Text You Want\"):\n",
    "#    sleep(.1)\n",
    "#print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['df_merged_train', 'df_merged_train_columns', 'df_merged_train_dep', 'df_merged_train_dep_columns', 'df_merged_train_arr', 'df_merged_train_arr_columns', 'df_merged', 'df_merged_columns', 'df_clean_final', 'df_clean_final_columns', 'df_stops_clean', 'df_stops_clean_columns']\n"
     ]
    }
   ],
   "source": [
    "# Load the npz file\n",
    "with np.load('capstone_sbb.npz', allow_pickle=False) as npz_file:\n",
    "    # It's a dictionary-like object\n",
    "    print(list(npz_file.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_merged_final: (158121, 39)\n",
      "df_merged_final_columns: (39,)\n",
      "df_merged_final_departure: (144111, 39)\n",
      "df_merged_final_departure_columns: (39,)\n",
      "df_merged_final_arrival: (144117, 39)\n",
      "df_merged_final_arrival_columns: (39,)\n",
      "df_merged: (1854124, 38)\n",
      "df_merged_columns: (38,)\n",
      "df_clean_final: (1854124, 27)\n",
      "df_clean_final_columns: (27,)\n",
      "df_stops_clean: (27738, 10)\n",
      "df_stops_clean_columns: (10,)\n"
     ]
    }
   ],
   "source": [
    "with np.load('capstone_sbb.npz', allow_pickle=True) as npz_file:\n",
    "    # Load the arrays\n",
    "    df_merged_zug_x = npz_file['df_merged_train']\n",
    "    df_merged_zug_columns_x = npz_file['df_merged_train_columns']\n",
    "    \n",
    "    df_merged_zug_dep_x = npz_file['df_merged_train_dep']\n",
    "    df_merged_zug_dep_columns_x = npz_file['df_merged_train_dep_columns']\n",
    "    df_merged_zug_arr_x = npz_file['df_merged_train_arr']\n",
    "    df_merged_zug_arr_columns_x = npz_file['df_merged_train_arr_columns']\n",
    "    \n",
    "    df_merged_x = npz_file['df_merged']\n",
    "    df_merged_columns_x = npz_file['df_merged_columns']\n",
    "    df_clean_final_x = npz_file['df_clean_final']\n",
    "    df_clean_final_columns_x = npz_file['df_clean_final_columns']\n",
    "    df_stops_clean_x = npz_file['df_stops_clean']\n",
    "    df_stops_clean_columns_x = npz_file['df_stops_clean_columns']\n",
    "\n",
    "\n",
    "print('df_merged_final:', df_merged_zug_x.shape)\n",
    "print('df_merged_final_columns:', df_merged_zug_columns_x.shape)\n",
    "print('df_merged_final_departure:', df_merged_zug_dep_x.shape)\n",
    "print('df_merged_final_departure_columns:', df_merged_zug_dep_columns_x.shape)\n",
    "print('df_merged_final_arrival:', df_merged_zug_arr_x.shape)\n",
    "print('df_merged_final_arrival_columns:', df_merged_zug_arr_columns_x.shape)\n",
    "print('df_merged:', df_merged_x.shape)\n",
    "print('df_merged_columns:', df_merged_columns_x.shape)\n",
    "print('df_clean_final:', df_clean_final_x.shape)\n",
    "print('df_clean_final_columns:', df_clean_final_columns_x.shape)\n",
    "print('df_stops_clean:', df_stops_clean_x.shape)\n",
    "print('df_stops_clean_columns:', df_stops_clean_columns_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_zug = pd.DataFrame(df_merged_zug_x, columns=df_merged_zug_columns_x)\n",
    "df_merged_zug_dep = pd.DataFrame(df_merged_zug_dep_x, columns=df_merged_zug_dep_columns_x)\n",
    "df_merged_zug_arr = pd.DataFrame(df_merged_zug_arr_x, columns=df_merged_zug_arr_columns_x)\n",
    "df_merged = pd.DataFrame(df_merged_x, columns=df_merged_columns_x)\n",
    "df_clean_final = pd.DataFrame(df_clean_final_x, columns=df_clean_final_columns_x)\n",
    "df_stops_clean = pd.DataFrame(df_stops_clean_x, columns=df_stops_clean_columns_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and Output features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['df_tr_arr_input', 'df_tr_arr_input_columns', 'X_tr_arr', 'X_va_arr_reindex', 'X_te_arr_reindex', 'y_tr_arr_delay', 'y_tr_arr_imp_delay', 'y_va_arr_delay', 'y_va_arr_imp_delay', 'y_te_arr_delay', 'y_te_arr_imp_delay', 'X_tr_dep', 'X_va_dep_reindex', 'X_te_dep_reindex', 'y_tr_dep_delay', 'y_tr_dep_imp_delay', 'y_va_dep_delay', 'y_va_dep_imp_delay', 'y_te_dep_delay', 'y_te_dep_imp_delay']\n"
     ]
    }
   ],
   "source": [
    "# Load the npz file\n",
    "import numpy as np\n",
    "with np.load('capstone_inputoutput.npz', allow_pickle=False) as npz_file:\n",
    "    # It's a dictionary-like object\n",
    "    print(list(npz_file.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_merged_final: (215050, 434)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "with np.load('capstone_inputoutput.npz', allow_pickle=True) as npz_file:\n",
    "    # Load the arrays\n",
    "    # arrival set\n",
    "    df_tr_arr_input=npz_file['df_tr_arr_input']\n",
    "    df_tr_arr_input_columns=npz_file['df_tr_arr_input_columns']\n",
    "    \n",
    "    X_tr_arr = npz_file['X_tr_arr']\n",
    "    X_va_arr_reindex = npz_file['X_va_arr_reindex']\n",
    "    X_te_arr_reindex = npz_file['X_te_arr_reindex']\n",
    "    \n",
    "    y_tr_arr_delay = npz_file['y_tr_arr_delay']\n",
    "    y_tr_arr_imp_delay = npz_file['y_tr_arr_imp_delay']\n",
    "    y_va_arr_delay = npz_file['y_va_arr_delay']\n",
    "    y_va_arr_imp_delay = npz_file['y_va_arr_imp_delay']\n",
    "    y_te_arr_delay = npz_file['y_te_arr_delay']\n",
    "    y_te_arr_imp_delay = npz_file['y_te_arr_imp_delay']\n",
    "    \n",
    "    # departure set (commented out as not needed)\n",
    "    #X_tr_dep = npz_file['X_tr_dep']\n",
    "    #X_va_dep_reindex = npz_file['X_va_dep_reindex']\n",
    "    #X_te_dep_reindex = npz_file['X_te_dep_reindex']\n",
    "    \n",
    "    #y_tr_dep_delay = npz_file['y_tr_dep_delay']\n",
    "    #y_tr_dep_imp_delay = npz_file['y_tr_dep_imp_delay']\n",
    "    #y_va_dep_delay = npz_file['y_va_dep_delay']\n",
    "    #y_va_dep_imp_delay = npz_file['y_va_dep_imp_delay']\n",
    "    #y_te_dep_delay = npz_file['y_te_dep_delay']\n",
    "    #y_te_dep_imp_delay = npz_file['y_te_dep_imp_delay']\n",
    "\n",
    "# create binary output\n",
    "y_tr_arr_delay_binary = (y_tr_arr_delay == 'delay')*1\n",
    "y_va_arr_delay_binary = (y_va_arr_delay == 'delay')*1\n",
    "y_te_arr_delay_binary = (y_te_arr_delay == 'delay')*1\n",
    "y_tr_arr_imp_delay_binary = (y_tr_arr_imp_delay == 'important_delay')*1\n",
    "y_va_arr_imp_delay_binary = (y_va_arr_imp_delay == 'important_delay')*1\n",
    "y_te_arr_imp_delay_binary = (y_te_arr_imp_delay == 'important_delay')*1\n",
    "\n",
    "print('df_merged_final:', X_tr_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning models <a name='top' />\n",
    "0. **<a href=#baseline>Baseline</a>** (show 'accuracy score' irrelevant => use Confusion matrix scores)\n",
    "    * Delay and Important delay\n",
    "        - <a href=#base_score>Accuracy score</a>\n",
    "        - <a href=#base_conf_matrix>Confusion matrix</a> and <a href=#base_class_report>Classification report</a>\n",
    "1. **<a href=#logreg>Logistic Regression</a>** (tune regularization wit GridSearch CV)\n",
    "    * <a href=#logreg_a>Delay and Important delay (no tuning)</a>\n",
    "        - <a href=#logreg_a_conf_matrix>Confusion matrix</a> and <a href=#logreg_a_class_report>Classification report</a>\n",
    "        - <a href=#logreg_a_roc>ROC curve</a> x <a href=#logreg_a_pr>PR curve</a> (including Areas under & optimized thresholds)\n",
    "            * <a href=#logreg_a_curves_class_report>Classification report</a> using best threshold\n",
    "    * <a href=#logreg_b>Delay and Important delay (with class_weight)</a>\n",
    "        - <a href=#logreg_b_class_report>Classification report</a>\n",
    "    * <a href=#logreg_c>Delay and Important delay (tuning hyper-parameters to optimize for AUPRC and F1 score)</a>\n",
    "        - <a href=#logreg_c_delay>Delay</a> (<a href=#logreg_c_delay_grid>GridSearch</a>, <a href=#logreg_c_delay_thres>optimized threshold</a> and <a href=#logreg_c_delay_report>Classification report</a>)\n",
    "        - <a href=#logreg_c_imp_delay>Important delay</a> (<a href=#logreg_c_imp_delay_grid>GridSearch</a>, <a href=#logreg_c_imp_delay_thres>optimized threshold</a> and <a href=#logreg_c_imp_delay_report>Classification report</a>)\n",
    "    * <a href=#logreg_test>Performance on test set</a>\n",
    "2. **<a href=#knn>K-NN</a>** (tune number of neighbors, weights, distance with ParameterGrid)\n",
    "    * <a href=#knn_delay>Delay</a> and <a href=#knn_imp_delay>Important delay</a> (no tuning - too slow for tuning due to large data sets and high number of categorical input features)\n",
    "    * <a href=#knn_test>Performance on test set</a>\n",
    "3. **<a href=#svms>SVMs</a>** (tune C and class_weight)\n",
    "    * <a href=#svm_lin>Linear</a>:\n",
    "        - <a href=#svm_delay>Delay</a>: <a href=#svm_delay_grid>gridsearch with loop</a>, <a href=#svm_delay_thres>best threshold on pr curve</a> and <a href=#svm_delay_report>classification report</a>\n",
    "        - <a href=#svm_imp_delay>Important delay</a>: <a href=#svm_imp_delay_grid>gridsearch with loop</a>, <a href=#svm_imp_delay_thres>best threshold on pr curve</a> and <a href=#svm_imp_delay_report>classification report</a>\n",
    "        - <a href=#svm_test>Performance on test set</a>\n",
    "    * <a href=#svm_rbf>RBF</a> (Too slow for large data sets and high number of input features)\n",
    "4. **<a href=#trees>Trees</a>** (tune class_weight, max_depth and n_estimators)\n",
    "    * <a href=#dt>DecisionTree</a>: \n",
    "        - <a href=#dt_delay>Delay (binary)</a>: <a href=#dt_delay_grid>gridsearch</a>, <a href=#dt_delay_report>classification report</a> and <a href=#dt_delay_viz>visualization</a> \n",
    "        - <a href=#dt_imp_delay>Important delay (binary)</a>: <a href=#dt_imp_delay_grid>gridsearch</a>, <a href=#dt_imp_delay_report>classification report</a> and <a href=#dt_imp_delay_viz>visualization</a> \n",
    "        - <a href=#dt_test>Performance on test set</a>\n",
    "    * <a href=#rf>RandomForest Nonlinear</a>:\n",
    "        - <a href=#rf_delay>Delay (binary)</a>: <a href=#rf_delay_grid>gridsearch</a>, <a href=#rf_delay_thres>optimze threshold</a>, <a href=#rf_delay_report>classification report</a> and <a href=#rf_delay_matrix>confusion matrix</a>\n",
    "        - <a href=#rf_imp_delay>Important delay (binary)</a>: <a href=#rf_imp_delay_grid>gridsearch</a>, <a href=#rf_imp_delay_thres>optimize threshold</a>, <a href=#rf_imp_delay_report>classification report</a> and <a href=#rf_imp_delay_matrix>confusion matrix</a>\n",
    "        - <a href=#rf_multi_report>Multi-class</a>: <a href=#rf_multi_grid>gridsearch</a>, <a href=#rf_multi_report>classification report</a> and <a href=#rf_multi_matrix>confusion matrix</a>\n",
    "        - <a href=#rf_test>Performance on test set</a>\n",
    "5. **<a href=#keras>Keras</a>** (2 dense layers and 1 dropout)\n",
    "    * <a href=#keras_delay>Delay</a>: <a href=#keras_delay_fit>fit model</a>, <a href=#keras_delay_thres>optimized threshold</a>, <a href=#keras_delay_report>classification report</a> and <a href=#keras_delay_matrix>confusion matrix</a>\n",
    "    * <a href=#keras_imp_delay>Important delay</a>: <a href=#keras_imp_delay_fit>fit model</a>, <a href=#keras_imp_delay_thres>optimized threshold</a>, <a href=#keras_imp_delay_report>classification report</a> and <a href=#keras_imp_delay_matrix>confusion matrix</a>\n",
    "    * <a href=#keras_test>Performance on test set</a> \n",
    "\n",
    "**<a href=#final>Final comparisons and comments</a>**\n",
    "   * <a href=#final_f1>F1 scores</a>\n",
    "   * <a href=#final_bar>Bar charts (f1 score, precision, recall)</a>\n",
    "   * <a href=#final_auprc>Area under PR curve</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X) Baseline <a name='baseline' /><a name='base_score' /> \n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score baseline delay: 0.797\n",
      "Score baseline important delay: 0.952\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# create dummy classifier\n",
    "dummy_d = DummyClassifier(strategy='most_frequent')\n",
    "dummy_i = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "# fit\n",
    "dummy_d.fit(X_tr_arr, y_tr_arr_delay_binary)\n",
    "dummy_i.fit(X_tr_arr, y_tr_arr_imp_delay_binary)\n",
    "\n",
    "# evaluate (accuracy)\n",
    "score_base_arr_d = dummy_d.score(X_va_arr_reindex, y_va_arr_delay_binary)\n",
    "score_base_arr_i = dummy_i.score(X_va_arr_reindex, y_va_arr_imp_delay_binary)\n",
    "\n",
    "# print\n",
    "print('Score baseline delay: {:.3f}'.format(score_base_arr_d))\n",
    "print('Score baseline important delay: {:.3f}'.format(score_base_arr_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delay (training set):\n",
      "    Total: 215050\n",
      "    Positive: 49154 (22.86% of total)\n",
      "\n",
      "Important delay (training set):\n",
      "    Total: 215050\n",
      "    Positive: 11217 (5.22% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg_d, pos_d = np.bincount(y_tr_arr_delay_binary)\n",
    "total_d = neg_d + pos_d\n",
    "print('Delay (training set):\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total_d, pos_d, 100 * pos_d / total_d))\n",
    "neg_i, pos_i = np.bincount(y_tr_arr_imp_delay_binary)\n",
    "total_i = neg_i + pos_i\n",
    "print('Important delay (training set):\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total_i, pos_i, 100 * pos_i / total_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to assess classifiers?\n",
    "Based on baseline accuracy we can determine that classes are imbalanced and therefore wouldn't make sense to use 'Accuracy' to assess performance of classifier. We shall rather use Confusion matrix/Clasisfication report as well as ROC/PR (Receiver operating characteristic/Precision-Recall) curves to compare classifiers performance on positive class ('delay' or 'important_delay')\n",
    "\n",
    "**CONFUSION MATRIX and CLASSIFICATION REPORT METRICS** *(Source: Unit 4.2 K-nearest + [Medium article](https://link.medium.com/Oiri21ldCfb))*\n",
    "\n",
    "**Precision:** Intuitively, the precision answers **\"How many times are we correct when we predict positive?\"**. The formula is simply \n",
    "'precision = tp/(tp+fp)'\n",
    "*<br>We can compute it in Scikit-learn using 'precision_score()'*\n",
    "\n",
    "**Recall** Intuitively, the recall measures **\"How many times do we predict positive when it is?\"**. The formula is simply 'recall = tp/(tp+fn)\n",
    "*<br>We can compute it in Scikit-learn using 'recall_score()'*\n",
    "\n",
    "**F1 score** The F1 score is a way to combine the precision and recall metrics into a single score. The formula is: 'f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "*<br> we can compute it in Scikit-learn using 'f1_score()'*\n",
    "\n",
    "**ROC, PRECISION-RECALL and AREA UNDER CURVES** *(Source: [how to effectively predict imbalanced classes](https://towardsdatascience.com/how-to-effectively-predict-imbalanced-classes-in-python-e8cd3b5720c4))*\n",
    "\n",
    "**ROC** Receiver Operating Characteristic plots a binary classifier's Flase Positive Rate (FPR) on the x-axis and True Positive Rate (TPR, Recall) on the y-axis with all possible threshold values between 0 and 1. Default probability threshold value for any classifier is usually 0.5, that is, classify a sample as belonging to the positive class if its predicted > 0.5. However, this default assumption should not be used for imbalanced datasets.\n",
    "*<br> we can compute it and its area under the curve in scikit-learn using 'roc_curve' and 'roc_auc_score'*\n",
    "\n",
    "**Precision-Recall** A PR curve plots Recall on the x-axis against Precision on the y-axis for all the possible probability threshold.**In contrast with the ROC curve, a perfectly skilled model bows towards the top right axis with coordinates (1,1). Since both Precision and Recall are concerned with true positives (the minority class), it makes it an effective tool for imbalanced classification problems.**\n",
    "*<br> we can compute it and its area under the curve in scikit-learn using 'precision_recall_curve' and 'auc'*\n",
    "\n",
    "**When to Use ROC vs. Precision-Recall Curves?**  *(Source: [roc curves and precision-recall curves for classification](https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/))*\n",
    "<br>Generally, the use of ROC curves and precision-recall curves are as follows:\n",
    "\n",
    "* ROC curves should be used when there are roughly equal numbers of observations for each class.\n",
    "* Precision-Recall curves should be used when there is a moderate to large class imbalance.\n",
    "\n",
    "**CONCLUSION:** For this project we wil work on optimizing first **'Area under PRC'** and then when possible find [best threshold](https://machinelearningmastery.com/threshold-moving-for-imbalanced-classification/) to optimize **F1 Score** for the positive classes\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import all necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "# classification report\n",
    "from sklearn.metrics import classification_report\n",
    "# ROC curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# Precision-Recal curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix (baseline) <a name='base_conf_matrix' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 0.0\n",
      "Recall score: 0.0\n",
      "F1 score: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred: no delay</th>\n",
       "      <th>pred: delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true: no delay</th>\n",
       "      <td>86652</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true: delay</th>\n",
       "      <td>22068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pred: no delay  pred: delay\n",
       "true: no delay           86652            0\n",
       "true: delay              22068            0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix 'baseline' (buildling for 'delay' only as proof-of-concept, but would be same results (even more extreme) for 'important_delay')\n",
    "y_pred_va_arr_d = dummy_d.predict(X_va_arr_reindex)\n",
    "matrix_base = confusion_matrix(y_true=y_va_arr_delay_binary, y_pred=y_pred_va_arr_d)\n",
    "matrix_base = pd.DataFrame(\n",
    "    matrix_base, \n",
    "    columns=['pred: no delay', 'pred: delay'],\n",
    "    index=['true: no delay', 'true: delay']\n",
    ")\n",
    "# evaluate\n",
    "precision_base_arr_d = precision_score(y_true=y_va_arr_delay_binary, y_pred=y_pred_va_arr_d, pos_label=1)\n",
    "recall_base_arr_d = recall_score(y_true=y_va_arr_delay_binary, y_pred=y_pred_va_arr_d, pos_label=1)\n",
    "f1_base_arr_d = f1_score(y_true=y_va_arr_delay_binary, y_pred=y_pred_va_arr_d, pos_label=1)\n",
    "\n",
    "# print\n",
    "print('Precision score:',precision_base_arr_d)\n",
    "print('Recall score:',recall_base_arr_d)\n",
    "print('F1 score:',f1_base_arr_d)\n",
    "#print('FBeta {:.1f} score: {:.3f}'.format(2,fbeta_score(y_true=y_va_arr_delay, beta=2, y_pred=dummy_d.predict(X_va_arr_reindex), pos_label='delay'))) # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html\n",
    "matrix_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report (baseline) <a name='base_class_report' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    no_delay       0.80      1.00      0.89     86652\n",
      "       delay       0.00      0.00      0.00     22068\n",
      "\n",
      "    accuracy                           0.80    108720\n",
      "   macro avg       0.40      0.50      0.44    108720\n",
      "weighted avg       0.64      0.80      0.71    108720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_base = classification_report(y_true=y_va_arr_delay_binary, y_pred=y_pred_va_arr_d, target_names=('no_delay','delay'))\n",
    "print(report_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Logistic Regression <a name='logreg' />\n",
    "*<a href=#top>Back to top</a>*\n",
    "#### a) Logisitic Regresison with default hyper-parameters (simple comparison to Baseline) <a name='logreg_a' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: delay\n",
      "Score LogReg delay: 0.8200\n",
      "Precision LogReg delay: 0.5748\n",
      "Recall LogReg delay: 0.4354\n",
      "F1 score LogReg delay: 0.4955\n",
      "***\n",
      "Logistic Regression: important delay\n",
      "Score LogReg important delay: 0.9534\n",
      "Precision LogReg important delay: 0.7660\n",
      "Recall LogReg important delay: 0.0481\n",
      "F1 score LogReg important delay: 0.0905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# create logisitic Regression\n",
    "logreg_d = LogisticRegression(multi_class='ovr',solver='liblinear')\n",
    "logreg_i = LogisticRegression(multi_class='ovr',solver='liblinear')\n",
    "\n",
    "# fit\n",
    "logreg_d.fit(X_tr_arr, y_tr_arr_delay_binary)\n",
    "logreg_i.fit(X_tr_arr, y_tr_arr_imp_delay_binary)\n",
    "\n",
    "# evaluate\n",
    "score_logreg_arr_d = logreg_d.score(X_va_arr_reindex, y_va_arr_delay_binary)\n",
    "score_logreg_arr_i = logreg_i.score(X_va_arr_reindex, y_va_arr_imp_delay_binary)\n",
    "\n",
    "y_pred_logreg_va_arr_d = logreg_d.predict(X_va_arr_reindex) # prediction delay\n",
    "precision_logreg_arr_d = precision_score(y_true=y_va_arr_delay_binary, y_pred=y_pred_logreg_va_arr_d, pos_label=1)\n",
    "recall_logreg_arr_d = recall_score(y_true=y_va_arr_delay_binary, y_pred=y_pred_logreg_va_arr_d, pos_label=1)\n",
    "f1_logreg_arr_d = f1_score(y_true=y_va_arr_delay_binary, y_pred=y_pred_logreg_va_arr_d, pos_label=1)\n",
    "\n",
    "y_pred_logreg_va_arr_i = logreg_i.predict(X_va_arr_reindex) # prediction important delay\n",
    "precision_logreg_arr_i = precision_score(y_true=y_va_arr_imp_delay_binary, y_pred=y_pred_logreg_va_arr_i, pos_label=1)\n",
    "recall_logreg_arr_i = recall_score(y_true=y_va_arr_imp_delay_binary, y_pred=y_pred_logreg_va_arr_i, pos_label=1)\n",
    "f1_logreg_arr_i = f1_score(y_true=y_va_arr_imp_delay_binary, y_pred=y_pred_logreg_va_arr_i, pos_label=1)\n",
    "\n",
    "# print\n",
    "print('Logistic Regression: delay')\n",
    "print('Score LogReg delay: {:.4f}'.format(score_logreg_arr_d))\n",
    "print('Precision LogReg delay: {:.4f}'.format(precision_logreg_arr_d))\n",
    "print('Recall LogReg delay: {:.4f}'.format(recall_logreg_arr_d))\n",
    "print('F1 score LogReg delay: {:.4f}'.format(f1_logreg_arr_d))\n",
    "print('***')\n",
    "print('Logistic Regression: important delay')\n",
    "print('Score LogReg important delay: {:.4f}'.format(score_logreg_arr_i))\n",
    "print('Precision LogReg important delay: {:.4f}'.format(precision_logreg_arr_i))\n",
    "print('Recall LogReg important delay: {:.4f}'.format(recall_logreg_arr_i))\n",
    "print('F1 score LogReg important delay: {:.4f}'.format(f1_logreg_arr_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix (Logistic Regression (a)) <a name='logreg_a_conf_matrix' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (normalized): Logistic Regression delay\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred: no delay</th>\n",
       "      <th>pred: delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true: no delay</th>\n",
       "      <td>0.731650</td>\n",
       "      <td>0.065370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true: delay</th>\n",
       "      <td>0.114597</td>\n",
       "      <td>0.088383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pred: no delay  pred: delay\n",
       "true: no delay        0.731650     0.065370\n",
       "true: delay           0.114597     0.088383"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix 'Logistic Regression delay'\n",
    "matrix_logreg_d = confusion_matrix(y_true=y_va_arr_delay_binary, y_pred=y_pred_logreg_va_arr_d,normalize='all') # normalize either on columns/rows or all\n",
    "matrix_logreg_d = pd.DataFrame(\n",
    "    matrix_logreg_d, \n",
    "    columns=['pred: no delay', 'pred: delay'],\n",
    "    index=['true: no delay', 'true: delay']\n",
    ")\n",
    "print('Confusion matrix (normalized): Logistic Regression delay')\n",
    "matrix_logreg_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (normalized): Logistic Regression important delay\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred: no delay</th>\n",
       "      <th>pred: delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true: no delay</th>\n",
       "      <td>0.951104</td>\n",
       "      <td>0.000708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true: delay</th>\n",
       "      <td>0.045870</td>\n",
       "      <td>0.002318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pred: no delay  pred: delay\n",
       "true: no delay        0.951104     0.000708\n",
       "true: delay           0.045870     0.002318"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix 'Logistic Regression important delay'\n",
    "matrix_logreg_i = confusion_matrix(y_true=y_va_arr_imp_delay_binary, y_pred=y_pred_logreg_va_arr_i,normalize='all') # normalize either on columns/rows or all\n",
    "matrix_logreg_i = pd.DataFrame(\n",
    "    matrix_logreg_i, \n",
    "    columns=['pred: no delay', 'pred: delay'],\n",
    "    index=['true: no delay', 'true: delay']\n",
    ")\n",
    "print('Confusion matrix (normalized): Logistic Regression important delay')\n",
    "matrix_logreg_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report (Logistic Regression (a)) <a name='logreg_a_class_report' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: Logistic Regression delay\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    no_delay       0.86      0.92      0.89     86652\n",
      "       delay       0.57      0.44      0.50     22068\n",
      "\n",
      "    accuracy                           0.82    108720\n",
      "   macro avg       0.72      0.68      0.69    108720\n",
      "weighted avg       0.81      0.82      0.81    108720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report 'Logistic Regression delay'\n",
    "print('Classification report: Logistic Regression delay')\n",
    "report_logreg_d = classification_report(y_true=y_va_arr_delay_binary, y_pred=y_pred_logreg_va_arr_d, target_names=('no_delay','delay'))\n",
    "print(report_logreg_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: Logistic Regression important delay\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       no_delay       0.95      1.00      0.98    103481\n",
      "important_delay       0.77      0.05      0.09      5239\n",
      "\n",
      "       accuracy                           0.95    108720\n",
      "      macro avg       0.86      0.52      0.53    108720\n",
      "   weighted avg       0.94      0.95      0.93    108720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report 'Logistic Regression important delay'\n",
    "print('Classification report: Logistic Regression important delay')\n",
    "report_logreg_i = classification_report(y_true=y_va_arr_imp_delay_binary, y_pred=y_pred_logreg_va_arr_i, target_names=('no_delay','important_delay'))\n",
    "print(report_logreg_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC and AUROC (incl. optimized threshold) <a name='logreg_a_roc' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.27350894 0.24693641 0.33556728 0.3055009  0.76082611]\n",
      "Predictions: [0 0 0 0 1]\n",
      "Probabilities: [0.09997347 0.08493804 0.2455714  0.21384152 0.24596633]\n",
      "Predictions: [0 0 0 0 0]\n",
      "Logistic delay: ROC AUC=0.853\n",
      "Dummy delay: ROC AUC=0.500\n",
      "Logistic important delay: ROC AUC=0.808\n",
      "Dummy important delay: ROC AUC=0.500\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC and AUROC\n",
    "# predict probabilities\n",
    "lr_probs_d = logreg_d.predict_proba(X_va_arr_reindex)\n",
    "dummy_probs_d = dummy_d.predict_proba(X_va_arr_reindex)\n",
    "\n",
    "lr_probs_i = logreg_i.predict_proba(X_va_arr_reindex)\n",
    "dummy_probs_i = dummy_i.predict_proba(X_va_arr_reindex)\n",
    "\n",
    "# check probabilities and compare to predicttions\n",
    "print('Probabilities:',lr_probs_d[0:5,1])\n",
    "print('Predictions:',y_pred_logreg_va_arr_d[0:5])\n",
    "\n",
    "print('Probabilities:',lr_probs_i[0:5,1])\n",
    "print('Predictions:',y_pred_logreg_va_arr_i[0:5])\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_probs_pos_d = lr_probs_d[:,1]\n",
    "dummy_probs_pos_d = dummy_probs_d[:,1]\n",
    "\n",
    "lr_probs_pos_i = lr_probs_i[:,1]\n",
    "dummy_probs_pos_i = dummy_probs_i[:,1]\n",
    "\n",
    "# calculate scores\n",
    "lr_auc_d = roc_auc_score(y_va_arr_delay_binary, lr_probs_pos_d)\n",
    "dummy_auc_d = roc_auc_score(y_va_arr_delay_binary, dummy_probs_pos_d)\n",
    "\n",
    "lr_auc_i = roc_auc_score(y_va_arr_imp_delay_binary, lr_probs_pos_i)\n",
    "dummy_auc_i = roc_auc_score(y_va_arr_imp_delay_binary, dummy_probs_pos_i)\n",
    "\n",
    "# summarize scores\n",
    "print('Logistic delay: ROC AUC={:.3f}'.format(lr_auc_d))\n",
    "print('Dummy delay: ROC AUC={:.3f}'.format(dummy_auc_d))\n",
    "\n",
    "print('Logistic important delay: ROC AUC={:.3f}'.format(lr_auc_i))\n",
    "print('Dummy important delay: ROC AUC={:.3f}'.format(dummy_auc_i))\n",
    "\n",
    "# calculate roc curves\n",
    "lr_fpr_d, lr_tpr_d, thres_d = roc_curve(y_va_arr_delay_binary, lr_probs_pos_d, pos_label=1)\n",
    "dummy_fpr_d, dummy_tpr_d, _= roc_curve(y_va_arr_delay_binary, dummy_probs_pos_d, pos_label=1)\n",
    "\n",
    "lr_fpr_i, lr_tpr_i, thres_i = roc_curve(y_va_arr_imp_delay_binary, lr_probs_pos_i, pos_label=1)\n",
    "dummy_fpr_i, dummy_tpr_i, _= roc_curve(y_va_arr_imp_delay_binary, dummy_probs_pos_i, pos_label=1)\n",
    "\n",
    "# plot the roc curves for both models\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "ax1.plot(lr_fpr_d, lr_tpr_d, marker='.', label='logistic, {:.3f}'.format(lr_auc_d))\n",
    "ax1.plot(dummy_fpr_d, dummy_tpr_d, marker='.', label='dummy, {:.3f}'.format(dummy_auc_d))\n",
    "ax1.set_xlabel('False Positive Rate')\n",
    "ax1.set_ylabel('True Positive Rate')\n",
    "ax1.set_title('ROC curve Logistic Regression: Delay')\n",
    "ax1.legend(title='Area under curve')\n",
    "\n",
    "ax2.plot(lr_fpr_i, lr_tpr_i, marker='.', label='logistic, {:.3f}'.format(lr_auc_i))\n",
    "ax2.plot(dummy_fpr_i, dummy_tpr_i, marker='.', label='dummy, {:.3f}'.format(dummy_auc_i))\n",
    "ax2.set_xlabel('False Positive Rate')\n",
    "ax2.set_ylabel('True Positive Rate')\n",
    "ax2.set_title('ROC curve Logistic Regression: Important delay')\n",
    "ax2.legend(title='Area under curve')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delay\n",
      "Best Threshold: 0.238755\n",
      "Probabilities: [0.27350894 0.24693641 0.33556728 0.3055009  0.76082611 0.21161996\n",
      " 0.65118221 0.77315453 0.40700482 0.31054733]\n",
      "Predictions: [1 1 1 1 1 0 1 1 1 1]\n",
      "***\n",
      "Important delay\n",
      "Best Threshold: 0.298757\n",
      "Probabilities: [0.09997347 0.08493804 0.2455714  0.21384152 0.24596633 0.08046971\n",
      " 0.21105443 0.22884169 0.14053175 0.14351464]\n",
      "Predictions: [0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# define optimized threshold\n",
    "from numpy import argmax\n",
    "print('Delay')\n",
    "# calculate inputs for the roc curve\n",
    "lr_J_d = lr_tpr_d -lr_fpr_d\n",
    "lr_bt_d = thres_d[argmax(lr_J_d)] # best threshold\n",
    "print('Best Threshold: %f' % (lr_bt_d))\n",
    "\n",
    "# use threshold in model\n",
    "lr_preds_d = np.where(logreg_d.predict_proba(X_va_arr_reindex)[:,1] > lr_bt_d, 1,0)\n",
    "print('Probabilities:',logreg_d.predict_proba(X_va_arr_reindex)[0:10,1])\n",
    "print('Predictions:',lr_preds_d[0:10])\n",
    "\n",
    "print('***')\n",
    "print('Important delay')\n",
    "# calculate inputs for the roc curve\n",
    "lr_J_i= lr_tpr_i -lr_fpr_i\n",
    "lr_bt_i = thres_d[argmax(lr_J_i)] # best threshold\n",
    "print('Best Threshold: %f' % (lr_bt_i))\n",
    "\n",
    "# use threshold in model\n",
    "lr_preds_i = np.where(logreg_i.predict_proba(X_va_arr_reindex)[:,1] > lr_bt_i, 1,0)\n",
    "print('Probabilities:',logreg_i.predict_proba(X_va_arr_reindex)[0:10,1])\n",
    "print('Predictions:',lr_preds_i[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: Logistic Regression delay - optimized threshold at 0.239 on ROC\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    no_delay       0.95      0.68      0.79     86652\n",
      "       delay       0.41      0.87      0.55     22068\n",
      "\n",
      "    accuracy                           0.72    108720\n",
      "   macro avg       0.68      0.77      0.67    108720\n",
      "weighted avg       0.84      0.72      0.74    108720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: Logistic Regression delay - optimized threshold at {:.3f} on ROC'.format(lr_bt_d))\n",
    "report_logreg_preds_d = classification_report(y_true=y_va_arr_delay_binary, y_pred=lr_preds_d, target_names=['no_delay','delay'])\n",
    "f1_logreg_arr_d_opt = classification_report(y_true=y_va_arr_delay_binary, y_pred=lr_preds_d, target_names=['no_delay','delay'], output_dict=True)['delay']['f1-score']\n",
    "print(report_logreg_preds_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: Logistic Regression important delay - optimized threshold at 0.299 on ROC\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       no_delay       0.96      0.99      0.97    103481\n",
      "important_delay       0.41      0.09      0.15      5239\n",
      "\n",
      "       accuracy                           0.95    108720\n",
      "      macro avg       0.68      0.54      0.56    108720\n",
      "   weighted avg       0.93      0.95      0.93    108720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: Logistic Regression important delay - optimized threshold at {:.3f} on ROC'.format(lr_bt_i))\n",
    "report_logreg_preds_i = classification_report(y_true=y_va_arr_imp_delay_binary, y_pred=lr_preds_i, target_names=['no_delay','important_delay'])\n",
    "f1_logreg_arr_i_opt = classification_report(y_true=y_va_arr_imp_delay_binary, y_pred=lr_preds_i, target_names=['no_delay','important_delay'], output_dict=True)['important_delay']['f1-score']\n",
    "print(report_logreg_preds_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression delay optimized f1 score: 0.553\n",
      "Logistic Regression important delay optimized f1 score: 0.149\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression delay optimized f1 score: {:.3f}'.format(f1_logreg_arr_d_opt))\n",
    "print('Logistic Regression important delay optimized f1 score: {:.3f}'.format(f1_logreg_arr_i_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PR and AUPR (incl. optimized threshold) <a name='logreg_a_pr' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Precision-Recall Curves\n",
    "# predict class values\n",
    "lr_precision_d, lr_recall_d, thres_pr_d = precision_recall_curve(y_va_arr_delay_binary, lr_probs_pos_d, pos_label=1)\n",
    "lr_auc_pr_d = auc(lr_recall_d, lr_precision_d)\n",
    "\n",
    "lr_precision_i, lr_recall_i, thres_pr_i = precision_recall_curve(y_va_arr_imp_delay_binary, lr_probs_pos_i, pos_label=1)\n",
    "lr_auc_pr_i = auc(lr_recall_i, lr_precision_i)\n",
    "\n",
    "# summarize scores\n",
    "#print('Logistic Delay: auc={:.3f}'.format(lr_auc_pr_d))\n",
    "#print('Logistic Important delay: auc={:.3f}'.format(lr_auc_pr_i))\n",
    "\n",
    "# plot the precision-recall curves for both models\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "ax1.plot([0,1], [(22068/108720),(22068/108720)], linestyle='--', label='Dummy, {:.3f}'.format(22068/108720))  # baseline is share of positive classes\n",
    "ax1.plot(lr_recall_d, lr_precision_d, marker='.', label='logistic, {:.3f}'.format(lr_auc_pr_d))\n",
    "ax1.set_xlabel('Recall')\n",
    "ax1.set_ylabel('Precision')\n",
    "ax1.legend(title='Area under curve')\n",
    "ax1.set_title('PR curve Logistic Regression: Delay')\n",
    "\n",
    "ax2.plot([0,1], [(5239/108720),(5239/108720)], linestyle='--', label='Dummy, {:.3f}'.format(5239/108720))  # baseline is share of positive classes\n",
    "ax2.plot(lr_recall_i, lr_precision_i, marker='.', label='logistic, {:.3f}'.format(lr_auc_pr_i))\n",
    "ax2.set_xlabel('Recall')\n",
    "ax2.set_ylabel('Precision')\n",
    "ax2.legend(title='Area under curve')\n",
    "ax2.set_title('PR curve Logistic Regression: Important delay')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delay\n",
      "Best Threshold: 0.297\n",
      "Probabilities: [0.27350894 0.24693641 0.33556728 0.3055009  0.76082611 0.21161996\n",
      " 0.65118221 0.77315453 0.40700482 0.31054733]\n",
      "Predictions: [1 1 1 1 1 0 1 1 1 1]\n",
      "***\n",
      "Important delay\n",
      "Best Threshold: 0.147\n",
      "Probabilities: [0.09997347 0.08493804 0.2455714  0.21384152 0.24596633 0.08046971\n",
      " 0.21105443 0.22884169 0.14053175 0.14351464]\n",
      "Predictions: [0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print('Delay')\n",
    "fscores_d = (2 * lr_precision_d * lr_recall_d) / (lr_precision_d + lr_recall_d)\n",
    "lr_bt_pr_d = thres_pr_d[argmax(fscores_d)]\n",
    "print('Best Threshold: {:.3f}'.format(lr_bt_pr_d))\n",
    "# use threshold in model\n",
    "lr_curve_d = np.where(logreg_d.predict_proba(X_va_arr_reindex)[:,1] > lr_bt_pr_d, 1,0)\n",
    "print('Probabilities:',logreg_d.predict_proba(X_va_arr_reindex)[0:10,1])\n",
    "print('Predictions:',lr_preds_d[0:10])\n",
    "\n",
    "print('***')\n",
    "\n",
    "print('Important delay')\n",
    "fscores_i = (2 * lr_precision_i * lr_recall_i) / (lr_precision_i + lr_recall_i)\n",
    "lr_bt_pr_i = thres_pr_i[argmax(fscores_i)]\n",
    "print('Best Threshold: {:.3f}'.format(lr_bt_pr_i))\n",
    "# use threshold in model\n",
    "lr_curve_i = np.where(logreg_i.predict_proba(X_va_arr_reindex)[:,1] > lr_bt_pr_i, 1,0)\n",
    "print('Probabilities:',logreg_i.predict_proba(X_va_arr_reindex)[0:10,1])\n",
    "print('Predictions:',lr_preds_i[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report (optimized threshold) <a name='logreg_a_curves_class_report' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: Logistic Regression delay - optimzed threshold at 0.297 on PR curve\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    no_delay       0.93      0.75      0.83     86652\n",
      "       delay       0.44      0.77      0.56     22068\n",
      "\n",
      "    accuracy                           0.75    108720\n",
      "   macro avg       0.68      0.76      0.69    108720\n",
      "weighted avg       0.83      0.75      0.77    108720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: Logistic Regression delay - optimzed threshold at {:.3f} on PR curve'.format(lr_bt_pr_d))\n",
    "report_logreg_preds_pr_d = classification_report(y_true=y_va_arr_delay_binary, y_pred=lr_curve_d, target_names=['no_delay','delay'])\n",
    "f1_logreg_pr_d = classification_report(y_true=y_va_arr_delay_binary, y_pred=lr_curve_d, target_names=['no_delay','delay'], output_dict=True)['delay']['f1-score']\n",
    "print(report_logreg_preds_pr_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: Logistic Regression importat delay - optimzed threshold at 0.147 on PR curve\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       no_delay       0.97      0.93      0.95    103481\n",
      "important_delay       0.21      0.34      0.26      5239\n",
      "\n",
      "       accuracy                           0.91    108720\n",
      "      macro avg       0.59      0.64      0.60    108720\n",
      "   weighted avg       0.93      0.91      0.92    108720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: Logistic Regression importat delay - optimzed threshold at {:.3f} on PR curve'.format(lr_bt_pr_i))\n",
    "report_logreg_preds_pr_i = classification_report(y_true=y_va_arr_imp_delay_binary, y_pred=lr_curve_i, target_names=['no_delay','important_delay'])\n",
    "f1_logreg_pr_i = classification_report(y_true=y_va_arr_imp_delay_binary, y_pred=lr_curve_i, target_names=['no_delay','important_delay'], output_dict=True)['important_delay']['f1-score']\n",
    "print(report_logreg_preds_pr_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression delay optimized f1 score: 0.561\n",
      "Logistic Regression important delay optimized f1 score: 0.256\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression delay optimized f1 score: {:.3f}'.format(f1_logreg_pr_d))\n",
    "print('Logistic Regression important delay optimized f1 score: {:.3f}'.format(f1_logreg_pr_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments:** *Logistic regression (a)*\n",
    "* **Delay:** \n",
    "    - Basic: f1 score of 0.50 with relatively balanced performance in precision (0.57) and recall (0.44)\n",
    "    - ROC: optimizing threshold (~0.24) we get to improved f1 score of 0.55 mostly from improvements in recall (0.87)\n",
    "    - PR: optimizing threshold (~0.30) we get to highest f1 score of 0.56 (precision at 0.44 and recall at 0.77)\n",
    "* **Important delay:** \n",
    "    - Basic: f1 score very low at 0.09 with decent precision (0.77) but bad recall (0.05) => although some important delays are possible to identify and recurring, most cases seem very hard to predict, probably a sign that there is no clear pattern to be detected in the data\n",
    "    - ROC: optimizing threshold (~0.30) we improve f1 score to 0.15 (precision 0.41 and recall at 0.09)\n",
    "    - PR: optimizing threshold (~0.15) we get to highest f1 score of 0.26 (precision at 0.21 and recall at 0.34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Logistic Regression with *'class_weight = 'balanced'* (Cost sensitive learning) <a name='logreg_b' />\n",
    "*<a href=#top>Back to top</a>*\n",
    "* **Note:** *decide to not use over- or under-sampling for this project and focus on other technics (e.g.: class_weight, thresholds optimization, ...)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', multi_class='ovr',\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_cw_d = LogisticRegression(multi_class='ovr',solver='liblinear', class_weight='balanced')\n",
    "logreg_cw_d.fit(X_tr_arr, y_tr_arr_delay_binary)\n",
    "\n",
    "logreg_cw_i = LogisticRegression(multi_class='ovr',solver='liblinear', class_weight='balanced')\n",
    "logreg_cw_i.fit(X_tr_arr, y_tr_arr_imp_delay_binary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report (Logistic Regression (b)) <a name='logreg_b_class_report' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: Logistic Regression delay\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    no_delay       0.96      0.66      0.78     86652\n",
      "       delay       0.40      0.88      0.55     22068\n",
      "\n",
      "    accuracy                           0.71    108720\n",
      "   macro avg       0.68      0.77      0.67    108720\n",
      "weighted avg       0.84      0.71      0.74    108720\n",
      "\n",
      "***\n",
      "Classification report: Logistic Regression important delay\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       no_delay       0.98      0.66      0.79    103481\n",
      "important_delay       0.11      0.79      0.19      5239\n",
      "\n",
      "       accuracy                           0.67    108720\n",
      "      macro avg       0.54      0.72      0.49    108720\n",
      "   weighted avg       0.94      0.67      0.76    108720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: Logistic Regression delay')\n",
    "report_logreg_cw_d = classification_report(y_true=y_va_arr_delay_binary, y_pred=logreg_cw_d.predict(X_va_arr_reindex), target_names=['no_delay','delay'])\n",
    "f1_logreg_cw_d = classification_report(y_true=y_va_arr_delay_binary, y_pred=logreg_cw_d.predict(X_va_arr_reindex), target_names=['no_delay','delay'], output_dict=True)['delay']['f1-score']\n",
    "print(report_logreg_cw_d)\n",
    "\n",
    "print('***')\n",
    "\n",
    "print('Classification report: Logistic Regression important delay')\n",
    "report_logreg_cw_i = classification_report(y_true=y_va_arr_imp_delay_binary, y_pred=logreg_cw_i.predict(X_va_arr_reindex), target_names=['no_delay','important_delay'])\n",
    "f1_logreg_cw_i = classification_report(y_true=y_va_arr_imp_delay_binary, y_pred=logreg_cw_i.predict(X_va_arr_reindex), target_names=['no_delay','important_delay'], output_dict=True)['important_delay']['f1-score']\n",
    "print(report_logreg_cw_i)\n",
    "# interesting to see how recall has increased significantly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression delay \"balanced\" class weight f1 score: 0.550\n",
      "Logistic Regression important delay \"balanced\" class weight f1 score: 0.186\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression delay \"balanced\" class weight f1 score: {:.3f}'.format(f1_logreg_cw_d))\n",
    "print('Logistic Regression important delay \"balanced\" class weight f1 score: {:.3f}'.format(f1_logreg_cw_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments:** *Logistic regression (b)*\n",
    "* **Delay:** \n",
    "    - class weight \"balanced\": f1 score of 0.55 close to performance of ROC and PR threshold improvements with especially high recall (0.88). Printing confusion matrix would show high share of false positive\n",
    "* **Important delay:** \n",
    "    - class weight \"balanced\": f1 score of 0.19 between performance of ROC and PR threshold improvements and especially high recall (0.79): Printing confusion matrix would also show high share of false positive here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Logistic Regression with hyper-parameters tuning (using Gridsearch and cross-validation) <a name='logreg_c' />\n",
    "*<a href=#top>Back to top</a>*\n",
    "\n",
    "1. Tune hyper-parameters in GridSearch (incl. class_weight)\n",
    "2. Optimize for Area Under PR curve\n",
    "3. Once set of hyper-parameters selected optimize thresholds on PR curve to get best f1 score\n",
    "\n",
    "**Notes on GridSearch:**\n",
    "* **Cross-validation:** the k-fold cross-validation technique is quite efficient and effective in assessing a classifier for balanced or even slightly skewed datasets. However, it fails in case of imbalanced datasets since the training data is usually split into folds assuming a uniform probability distribution. In the case of imbalanced data, this has the potential of resulting in certain folds either completely missing out on the positive (minority) class or having very few examples of it. Accordingly, this is likely to result in misleading model evaluations. A modified k-fold cross-validation, called **stratified k-fold cross-validation**, is **more suitable for imbalanced classification problems**. **Stratified k-fold or Repeated Stratified k-fold preserves the imbalanced class distribution in each fold. In GridSearch object stratified k-fold is per default for classifiers**\n",
    "* **AP (average precision):** AUPRC is not a metric available in GridSearch but AP is a very close approximation. We will be using both AUPRC and F1 scores to assess performance of combinations\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning hyperparameters with GridSearchCV (grid search and cross validation) <a name='logreg_c_delay' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging train and validation sets for the use of cross-validation\n",
    "X_tr_va = np.concatenate((X_tr_arr,X_va_arr_reindex))\n",
    "y_tr_va_d = np.concatenate((y_tr_arr_delay_binary, y_va_arr_delay_binary))\n",
    "y_tr_va_i = np.concatenate((y_tr_arr_imp_delay_binary, y_va_arr_imp_delay_binary))\n",
    "\n",
    "#imgs_tr_va = np.concatenate((imgs_tr, imgs_va))\n",
    "#labels_tr_va = np.concatenate((labels_tr, labels_va))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape train/valid input: (323770, 434)\n",
      "Shape train/valid output: (323770,)\n",
      "Shape train/valid output: (323770,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape train/valid input:',X_tr_va.shape)\n",
    "print('Shape train/valid output:',y_tr_va_d.shape)\n",
    "print('Shape train/valid output:',y_tr_va_i.shape)\n",
    "#print('Shape train/valid imgs:',imgs_tr_va.shape)\n",
    "#print('Shape train/valid labels:',labels_tr_va.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('logistic',\n",
      "                 LogisticRegression(multi_class='ovr', solver='liblinear'))])\n",
      "Pipeline(steps=[('logistic',\n",
      "                 LogisticRegression(multi_class='ovr', solver='liblinear'))])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "# Create the estimator\n",
    "logreg_tune_d = Pipeline([\n",
    "    #('scaler',StandardScaler()),\n",
    "    ('logistic',LogisticRegression(multi_class='ovr',solver='liblinear'))\n",
    "])\n",
    "logreg_tune_i = Pipeline([\n",
    "    #('scaler',StandardScaler()),\n",
    "    ('logistic',LogisticRegression(multi_class='ovr',solver='liblinear'))\n",
    "])\n",
    "\n",
    "# Fit on the train/validation set\n",
    "print(logreg_tune_d.fit(X_tr_va,y_tr_va_d))\n",
    "print(logreg_tune_i.fit(X_tr_va,y_tr_va_i))\n",
    "\n",
    "# How can I do the same without Pipeline (as I already scaled before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Pipeline.get_params of Pipeline(steps=[('logistic',\n",
      "                 LogisticRegression(multi_class='ovr', solver='liblinear'))])>\n",
      "<bound method Pipeline.get_params of Pipeline(steps=[('logistic',\n",
      "                 LogisticRegression(multi_class='ovr', solver='liblinear'))])>\n"
     ]
    }
   ],
   "source": [
    "print(logreg_tune_d.get_params)\n",
    "print(logreg_tune_i.get_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch (delay) <a name='logreg_c_delay_grid' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid\n",
    "grid = [{\n",
    "    'logistic__C':np.logspace(-4,4,3),\n",
    "    'logistic__multi_class':['ovr'],\n",
    "    'logistic__solver':['liblinear'],\n",
    "    'logistic__class_weight':[None,'balanced']\n",
    "},{\n",
    "    'logistic__C':np.logspace(-4,4,3),\n",
    "    'logistic__multi_class':['multinomial'],\n",
    "    'logistic__solver':['saga'],\n",
    "    'logistic__class_weight':[None,'balanced']\n",
    "}]\n",
    "\n",
    "# Create cross validation object\n",
    "# planning to use AP (average_precision') for scoring on AUPRC (https://glassboxmedicine.com/2019/03/02/measuring-performance-auprc/)\n",
    "scoring = ['precision','recall','average_precision','f1'] # replace in below GridSearchCV\n",
    "# not that for classifiers the CV is per-default stratified\n",
    "grid_cv_d = GridSearchCV(estimator=logreg_tune_d, param_grid=grid, n_jobs=4, cv=10, refit=False,verbose=1, return_train_score=True, scoring=['precision','recall','average_precision','f1'])\n",
    "grid_cv_i = GridSearchCV(estimator=logreg_tune_i, param_grid=grid, n_jobs=4, cv=10, refit=False,verbose=1, return_train_score=True, scoring=['precision','recall','average_precision','f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "6775.045025587082\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "grid_cv_d.fit(X_tr_va,y_tr_va_d)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_logistic__C', 'param_logistic__class_weight', 'param_logistic__multi_class', 'param_logistic__solver', 'params', 'split0_test_precision', 'split1_test_precision', 'split2_test_precision', 'split3_test_precision', 'split4_test_precision', 'split5_test_precision', 'split6_test_precision', 'split7_test_precision', 'split8_test_precision', 'split9_test_precision', 'mean_test_precision', 'std_test_precision', 'rank_test_precision', 'split0_train_precision', 'split1_train_precision', 'split2_train_precision', 'split3_train_precision', 'split4_train_precision', 'split5_train_precision', 'split6_train_precision', 'split7_train_precision', 'split8_train_precision', 'split9_train_precision', 'mean_train_precision', 'std_train_precision', 'split0_test_recall', 'split1_test_recall', 'split2_test_recall', 'split3_test_recall', 'split4_test_recall', 'split5_test_recall', 'split6_test_recall', 'split7_test_recall', 'split8_test_recall', 'split9_test_recall', 'mean_test_recall', 'std_test_recall', 'rank_test_recall', 'split0_train_recall', 'split1_train_recall', 'split2_train_recall', 'split3_train_recall', 'split4_train_recall', 'split5_train_recall', 'split6_train_recall', 'split7_train_recall', 'split8_train_recall', 'split9_train_recall', 'mean_train_recall', 'std_train_recall', 'split0_test_average_precision', 'split1_test_average_precision', 'split2_test_average_precision', 'split3_test_average_precision', 'split4_test_average_precision', 'split5_test_average_precision', 'split6_test_average_precision', 'split7_test_average_precision', 'split8_test_average_precision', 'split9_test_average_precision', 'mean_test_average_precision', 'std_test_average_precision', 'rank_test_average_precision', 'split0_train_average_precision', 'split1_train_average_precision', 'split2_train_average_precision', 'split3_train_average_precision', 'split4_train_average_precision', 'split5_train_average_precision', 'split6_train_average_precision', 'split7_train_average_precision', 'split8_train_average_precision', 'split9_train_average_precision', 'mean_train_average_precision', 'std_train_average_precision', 'split0_test_f1', 'split1_test_f1', 'split2_test_f1', 'split3_test_f1', 'split4_test_f1', 'split5_test_f1', 'split6_test_f1', 'split7_test_f1', 'split8_test_f1', 'split9_test_f1', 'mean_test_f1', 'std_test_f1', 'rank_test_f1', 'split0_train_f1', 'split1_train_f1', 'split2_train_f1', 'split3_train_f1', 'split4_train_f1', 'split5_train_f1', 'split6_train_f1', 'split7_train_f1', 'split8_train_f1', 'split9_train_f1', 'mean_train_f1', 'std_train_f1'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the results with \"cv_results\"\n",
    "grid_cv_d.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03139478, 0.89404944, 0.37013911, 0.86443844, 0.37078493,\n",
       "       0.86415762, 0.06420756, 0.89410558, 0.37039183, 0.8643542 ,\n",
       "       0.37078493, 0.86415762])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv_d.cv_results_['mean_test_recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_average_precision</th>\n",
       "      <th>mean_train_average_precision</th>\n",
       "      <th>std_test_average_precision</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>mean_train_f1</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_train_recall</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_train_precision</th>\n",
       "      <th>param_logistic__C</th>\n",
       "      <th>param_logistic__multi_class</th>\n",
       "      <th>param_logistic__class_weight</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.552158</td>\n",
       "      <td>0.621584</td>\n",
       "      <td>0.044233</td>\n",
       "      <td>0.446960</td>\n",
       "      <td>0.498237</td>\n",
       "      <td>0.370785</td>\n",
       "      <td>0.406140</td>\n",
       "      <td>0.576028</td>\n",
       "      <td>0.644511</td>\n",
       "      <td>10000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>31.540013</td>\n",
       "      <td>0.162915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.552151</td>\n",
       "      <td>0.621583</td>\n",
       "      <td>0.044227</td>\n",
       "      <td>0.446960</td>\n",
       "      <td>0.498243</td>\n",
       "      <td>0.370785</td>\n",
       "      <td>0.406153</td>\n",
       "      <td>0.576028</td>\n",
       "      <td>0.644497</td>\n",
       "      <td>10000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>None</td>\n",
       "      <td>454.693050</td>\n",
       "      <td>0.149548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.552107</td>\n",
       "      <td>0.621562</td>\n",
       "      <td>0.044242</td>\n",
       "      <td>0.446662</td>\n",
       "      <td>0.498067</td>\n",
       "      <td>0.370392</td>\n",
       "      <td>0.405855</td>\n",
       "      <td>0.575963</td>\n",
       "      <td>0.644654</td>\n",
       "      <td>1</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>None</td>\n",
       "      <td>650.182732</td>\n",
       "      <td>0.165038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.552082</td>\n",
       "      <td>0.620002</td>\n",
       "      <td>0.043591</td>\n",
       "      <td>0.559694</td>\n",
       "      <td>0.589026</td>\n",
       "      <td>0.864158</td>\n",
       "      <td>0.895812</td>\n",
       "      <td>0.415141</td>\n",
       "      <td>0.438785</td>\n",
       "      <td>10000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>57.300735</td>\n",
       "      <td>0.218698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.552075</td>\n",
       "      <td>0.619998</td>\n",
       "      <td>0.043585</td>\n",
       "      <td>0.559686</td>\n",
       "      <td>0.589023</td>\n",
       "      <td>0.864158</td>\n",
       "      <td>0.895827</td>\n",
       "      <td>0.415133</td>\n",
       "      <td>0.438779</td>\n",
       "      <td>10000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>balanced</td>\n",
       "      <td>440.055366</td>\n",
       "      <td>0.142646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.552053</td>\n",
       "      <td>0.621543</td>\n",
       "      <td>0.044270</td>\n",
       "      <td>0.446551</td>\n",
       "      <td>0.497929</td>\n",
       "      <td>0.370139</td>\n",
       "      <td>0.405589</td>\n",
       "      <td>0.576312</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>1</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>21.891480</td>\n",
       "      <td>0.195644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.552022</td>\n",
       "      <td>0.619968</td>\n",
       "      <td>0.043595</td>\n",
       "      <td>0.559685</td>\n",
       "      <td>0.588995</td>\n",
       "      <td>0.864354</td>\n",
       "      <td>0.896026</td>\n",
       "      <td>0.415088</td>\n",
       "      <td>0.438700</td>\n",
       "      <td>1</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>balanced</td>\n",
       "      <td>765.565338</td>\n",
       "      <td>0.186003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.551951</td>\n",
       "      <td>0.619945</td>\n",
       "      <td>0.043618</td>\n",
       "      <td>0.559613</td>\n",
       "      <td>0.589003</td>\n",
       "      <td>0.864438</td>\n",
       "      <td>0.896173</td>\n",
       "      <td>0.414985</td>\n",
       "      <td>0.438673</td>\n",
       "      <td>1</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>21.163220</td>\n",
       "      <td>0.173946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.415755</td>\n",
       "      <td>0.484944</td>\n",
       "      <td>0.048020</td>\n",
       "      <td>0.111040</td>\n",
       "      <td>0.128215</td>\n",
       "      <td>0.064208</td>\n",
       "      <td>0.071431</td>\n",
       "      <td>0.474121</td>\n",
       "      <td>0.635752</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>None</td>\n",
       "      <td>102.283463</td>\n",
       "      <td>0.164113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.413993</td>\n",
       "      <td>0.480634</td>\n",
       "      <td>0.046494</td>\n",
       "      <td>0.532246</td>\n",
       "      <td>0.547762</td>\n",
       "      <td>0.894106</td>\n",
       "      <td>0.923852</td>\n",
       "      <td>0.379321</td>\n",
       "      <td>0.389302</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>balanced</td>\n",
       "      <td>83.889079</td>\n",
       "      <td>0.136795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.399131</td>\n",
       "      <td>0.448922</td>\n",
       "      <td>0.038872</td>\n",
       "      <td>0.529496</td>\n",
       "      <td>0.542825</td>\n",
       "      <td>0.894049</td>\n",
       "      <td>0.922898</td>\n",
       "      <td>0.376486</td>\n",
       "      <td>0.384501</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>9.606441</td>\n",
       "      <td>0.221696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.397556</td>\n",
       "      <td>0.449161</td>\n",
       "      <td>0.039597</td>\n",
       "      <td>0.057820</td>\n",
       "      <td>0.061533</td>\n",
       "      <td>0.031395</td>\n",
       "      <td>0.032460</td>\n",
       "      <td>0.423249</td>\n",
       "      <td>0.607827</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>29.036475</td>\n",
       "      <td>0.697462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_average_precision  mean_train_average_precision  \\\n",
       "4                      0.552158                      0.621584   \n",
       "10                     0.552151                      0.621583   \n",
       "8                      0.552107                      0.621562   \n",
       "5                      0.552082                      0.620002   \n",
       "11                     0.552075                      0.619998   \n",
       "2                      0.552053                      0.621543   \n",
       "9                      0.552022                      0.619968   \n",
       "3                      0.551951                      0.619945   \n",
       "6                      0.415755                      0.484944   \n",
       "7                      0.413993                      0.480634   \n",
       "1                      0.399131                      0.448922   \n",
       "0                      0.397556                      0.449161   \n",
       "\n",
       "    std_test_average_precision  mean_test_f1  mean_train_f1  mean_test_recall  \\\n",
       "4                     0.044233      0.446960       0.498237          0.370785   \n",
       "10                    0.044227      0.446960       0.498243          0.370785   \n",
       "8                     0.044242      0.446662       0.498067          0.370392   \n",
       "5                     0.043591      0.559694       0.589026          0.864158   \n",
       "11                    0.043585      0.559686       0.589023          0.864158   \n",
       "2                     0.044270      0.446551       0.497929          0.370139   \n",
       "9                     0.043595      0.559685       0.588995          0.864354   \n",
       "3                     0.043618      0.559613       0.589003          0.864438   \n",
       "6                     0.048020      0.111040       0.128215          0.064208   \n",
       "7                     0.046494      0.532246       0.547762          0.894106   \n",
       "1                     0.038872      0.529496       0.542825          0.894049   \n",
       "0                     0.039597      0.057820       0.061533          0.031395   \n",
       "\n",
       "    mean_train_recall  mean_test_precision  mean_train_precision  \\\n",
       "4            0.406140             0.576028              0.644511   \n",
       "10           0.406153             0.576028              0.644497   \n",
       "8            0.405855             0.575963              0.644654   \n",
       "5            0.895812             0.415141              0.438785   \n",
       "11           0.895827             0.415133              0.438779   \n",
       "2            0.405589             0.576312              0.644860   \n",
       "9            0.896026             0.415088              0.438700   \n",
       "3            0.896173             0.414985              0.438673   \n",
       "6            0.071431             0.474121              0.635752   \n",
       "7            0.923852             0.379321              0.389302   \n",
       "1            0.922898             0.376486              0.384501   \n",
       "0            0.032460             0.423249              0.607827   \n",
       "\n",
       "   param_logistic__C param_logistic__multi_class param_logistic__class_weight  \\\n",
       "4              10000                         ovr                         None   \n",
       "10             10000                 multinomial                         None   \n",
       "8                  1                 multinomial                         None   \n",
       "5              10000                         ovr                     balanced   \n",
       "11             10000                 multinomial                     balanced   \n",
       "2                  1                         ovr                         None   \n",
       "9                  1                 multinomial                     balanced   \n",
       "3                  1                         ovr                     balanced   \n",
       "6             0.0001                 multinomial                         None   \n",
       "7             0.0001                 multinomial                     balanced   \n",
       "1             0.0001                         ovr                     balanced   \n",
       "0             0.0001                         ovr                         None   \n",
       "\n",
       "    mean_fit_time  mean_score_time  \n",
       "4       31.540013         0.162915  \n",
       "10     454.693050         0.149548  \n",
       "8      650.182732         0.165038  \n",
       "5       57.300735         0.218698  \n",
       "11     440.055366         0.142646  \n",
       "2       21.891480         0.195644  \n",
       "9      765.565338         0.186003  \n",
       "3       21.163220         0.173946  \n",
       "6      102.283463         0.164113  \n",
       "7       83.889079         0.136795  \n",
       "1        9.606441         0.221696  \n",
       "0       29.036475         0.697462  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['mean_test_average_precision','mean_train_average_precision','std_test_average_precision',\\\n",
    "        'mean_test_f1','mean_train_f1',\\\n",
    "        'mean_test_recall','mean_train_recall','mean_test_precision','mean_train_precision',\\\n",
    "        'param_logistic__C','param_logistic__multi_class','param_logistic__class_weight',\\\n",
    "        'mean_fit_time','mean_score_time']\n",
    "# Delay GridSearchCV\n",
    "grid_cv_df_d = pd.DataFrame(grid_cv_d.cv_results_)[cols].sort_values(by='mean_test_average_precision', ascending=False)\n",
    "grid_cv_df_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments on GridSearchCV - Delay:**\n",
    "* Many results with AP at 0.55, from those some with stronger f1 score at 0.56 which have high recall. Also taking into account 'fit time' when similar results\n",
    "* Based on above comments deciding to go with (5) following parameters:\n",
    "    * multi_class: ovr\n",
    "    * class_weight: balanced\n",
    "    * C: 1000 (could try slightly lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.56535422 0.53189748 0.64550162 0.61400207 0.91730315]\n",
      "Predictions: [1 1 1 1 1]\n",
      "Area Under PR Curve: 0.570\n"
     ]
    }
   ],
   "source": [
    "# creating final LogisticRegression\n",
    "logreg_tuned_final_d = LogisticRegression(C=1000, multi_class='ovr', class_weight='balanced', solver='liblinear')\n",
    "# fit\n",
    "logreg_tuned_final_d.fit(X_tr_arr, y_tr_arr_delay_binary)\n",
    "# predict\n",
    "lr_tuned_final_pred_d = logreg_tuned_final_d.predict(X_va_arr_reindex)\n",
    "# predict probabilities\n",
    "lr_tuned_probs_d = logreg_tuned_final_d.predict_proba(X_va_arr_reindex)\n",
    "# check probabilities and compare to predicttions\n",
    "print('Probabilities:',lr_tuned_probs_d[0:5,1])\n",
    "print('Predictions:',lr_tuned_final_pred_d[0:5])\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_tuned_probs_pos_d = lr_tuned_probs_d[:,1]\n",
    "\n",
    "lr_precision_tuned_d, lr_recall_tuned_d, thres_tuned_pr_d = precision_recall_curve(y_va_arr_delay_binary, lr_tuned_probs_pos_d, pos_label=1)\n",
    "lr_tuned_auc_pr_d = auc(lr_recall_tuned_d, lr_precision_tuned_d)\n",
    "print('Area Under PR Curve: {:.3f}'.format(lr_tuned_auc_pr_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best threshold calculation <a name='logreg_c_delay_thres' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.594\n",
      "Probabilities: [0.56535422 0.53189748 0.64550162 0.61400207 0.91730315 0.47913815\n",
      " 0.86809157 0.9221443  0.70394967 0.59859178]\n",
      "Predictions: [0 0 1 1 1 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "fscores_tuned_d = (2 * lr_precision_tuned_d * lr_recall_tuned_d) / (lr_precision_tuned_d + lr_recall_tuned_d)\n",
    "lr_bt_tuned_pr_d = thres_tuned_pr_d[argmax(fscores_tuned_d)]\n",
    "print('Best Threshold: {:.3f}'.format(lr_bt_tuned_pr_d))\n",
    "# use threshold in model\n",
    "lr_tuned_curve_d = np.where(logreg_tuned_final_d.predict_proba(X_va_arr_reindex)[:,1] > lr_bt_tuned_pr_d, 1,0)\n",
    "print('Probabilities:',logreg_tuned_final_d.predict_proba(X_va_arr_reindex)[0:10,1])\n",
    "print('Predictions:',lr_tuned_curve_d[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report <a name='logreg_c_delay_report' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: Logistic Regression delay - optimzed threshold at 0.594 on PR curve\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    no_delay       0.93      0.75      0.83     86652\n",
      "       delay       0.44      0.77      0.56     22068\n",
      "\n",
      "    accuracy                           0.76    108720\n",
      "   macro avg       0.69      0.76      0.70    108720\n",
      "weighted avg       0.83      0.76      0.78    108720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: Logistic Regression delay - optimzed threshold at {:.3f} on PR curve'.format(lr_bt_tuned_pr_d))\n",
    "report_logreg_preds_tuned_pr_d = classification_report(y_true=y_va_arr_delay_binary, y_pred=lr_tuned_curve_d, target_names=['no_delay','delay'])\n",
    "#f1_logreg_pr_d = classification_report(y_true=y_va_arr_delay_binary, y_pred=lr_curve_d, target_names=['no_delay','delay'], output_dict=True)['delay']['f1-score']\n",
    "print(report_logreg_preds_tuned_pr_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Got slightly better f1-score with (ii) balanced but much lower recall. Ok to trade-off for higher recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important delay <a name='logreg_c_imp_delay' /><a name='logreg_c_imp_delay_grid' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 12 candidates, totalling 120 fits\n",
      "6089.134136915207\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "grid_cv_i.fit(X_tr_va,y_tr_va_i)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_average_precision</th>\n",
       "      <th>mean_train_average_precision</th>\n",
       "      <th>std_test_average_precision</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>mean_train_f1</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_train_recall</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_train_precision</th>\n",
       "      <th>param_logistic__C</th>\n",
       "      <th>param_logistic__multi_class</th>\n",
       "      <th>param_logistic__class_weight</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.204887</td>\n",
       "      <td>0.266600</td>\n",
       "      <td>0.054933</td>\n",
       "      <td>0.094164</td>\n",
       "      <td>0.102085</td>\n",
       "      <td>0.051589</td>\n",
       "      <td>0.054347</td>\n",
       "      <td>0.657344</td>\n",
       "      <td>0.845221</td>\n",
       "      <td>10000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>None</td>\n",
       "      <td>407.314298</td>\n",
       "      <td>0.131594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.204876</td>\n",
       "      <td>0.266605</td>\n",
       "      <td>0.054946</td>\n",
       "      <td>0.094164</td>\n",
       "      <td>0.102085</td>\n",
       "      <td>0.051589</td>\n",
       "      <td>0.054347</td>\n",
       "      <td>0.657344</td>\n",
       "      <td>0.845221</td>\n",
       "      <td>10000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>26.393216</td>\n",
       "      <td>0.191900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.204848</td>\n",
       "      <td>0.266548</td>\n",
       "      <td>0.054867</td>\n",
       "      <td>0.094333</td>\n",
       "      <td>0.101764</td>\n",
       "      <td>0.051650</td>\n",
       "      <td>0.054165</td>\n",
       "      <td>0.663694</td>\n",
       "      <td>0.845274</td>\n",
       "      <td>1</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>None</td>\n",
       "      <td>406.623689</td>\n",
       "      <td>0.140775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.204764</td>\n",
       "      <td>0.266504</td>\n",
       "      <td>0.054780</td>\n",
       "      <td>0.094147</td>\n",
       "      <td>0.101243</td>\n",
       "      <td>0.051528</td>\n",
       "      <td>0.053868</td>\n",
       "      <td>0.665009</td>\n",
       "      <td>0.845803</td>\n",
       "      <td>1</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>14.204667</td>\n",
       "      <td>0.173727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.197163</td>\n",
       "      <td>0.253391</td>\n",
       "      <td>0.055819</td>\n",
       "      <td>0.182289</td>\n",
       "      <td>0.212806</td>\n",
       "      <td>0.778442</td>\n",
       "      <td>0.848012</td>\n",
       "      <td>0.103337</td>\n",
       "      <td>0.121674</td>\n",
       "      <td>10000</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>85.101367</td>\n",
       "      <td>0.218964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.197086</td>\n",
       "      <td>0.253277</td>\n",
       "      <td>0.055680</td>\n",
       "      <td>0.182233</td>\n",
       "      <td>0.212799</td>\n",
       "      <td>0.778685</td>\n",
       "      <td>0.848154</td>\n",
       "      <td>0.103297</td>\n",
       "      <td>0.121666</td>\n",
       "      <td>1</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>24.078090</td>\n",
       "      <td>0.190684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.182434</td>\n",
       "      <td>0.185501</td>\n",
       "      <td>0.056034</td>\n",
       "      <td>0.197487</td>\n",
       "      <td>0.199752</td>\n",
       "      <td>0.632919</td>\n",
       "      <td>0.649644</td>\n",
       "      <td>0.126577</td>\n",
       "      <td>0.123732</td>\n",
       "      <td>10000</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>balanced</td>\n",
       "      <td>404.090964</td>\n",
       "      <td>0.150601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.158580</td>\n",
       "      <td>0.182647</td>\n",
       "      <td>0.042398</td>\n",
       "      <td>0.164599</td>\n",
       "      <td>0.196865</td>\n",
       "      <td>0.637849</td>\n",
       "      <td>0.684562</td>\n",
       "      <td>0.099507</td>\n",
       "      <td>0.121273</td>\n",
       "      <td>1</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>balanced</td>\n",
       "      <td>462.361673</td>\n",
       "      <td>0.141590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.126338</td>\n",
       "      <td>0.163164</td>\n",
       "      <td>0.023031</td>\n",
       "      <td>0.161955</td>\n",
       "      <td>0.183370</td>\n",
       "      <td>0.789440</td>\n",
       "      <td>0.852772</td>\n",
       "      <td>0.090423</td>\n",
       "      <td>0.102914</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>balanced</td>\n",
       "      <td>413.333821</td>\n",
       "      <td>0.142823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.118499</td>\n",
       "      <td>0.145406</td>\n",
       "      <td>0.028762</td>\n",
       "      <td>0.162537</td>\n",
       "      <td>0.178731</td>\n",
       "      <td>0.784572</td>\n",
       "      <td>0.841004</td>\n",
       "      <td>0.090711</td>\n",
       "      <td>0.099991</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>ovr</td>\n",
       "      <td>balanced</td>\n",
       "      <td>6.852943</td>\n",
       "      <td>0.181055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.117266</td>\n",
       "      <td>0.140737</td>\n",
       "      <td>0.028932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>None</td>\n",
       "      <td>92.038737</td>\n",
       "      <td>0.162565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.103689</td>\n",
       "      <td>0.117773</td>\n",
       "      <td>0.016250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>ovr</td>\n",
       "      <td>None</td>\n",
       "      <td>6.685491</td>\n",
       "      <td>0.191661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_average_precision  mean_train_average_precision  \\\n",
       "10                     0.204887                      0.266600   \n",
       "4                      0.204876                      0.266605   \n",
       "8                      0.204848                      0.266548   \n",
       "2                      0.204764                      0.266504   \n",
       "5                      0.197163                      0.253391   \n",
       "3                      0.197086                      0.253277   \n",
       "11                     0.182434                      0.185501   \n",
       "9                      0.158580                      0.182647   \n",
       "7                      0.126338                      0.163164   \n",
       "1                      0.118499                      0.145406   \n",
       "6                      0.117266                      0.140737   \n",
       "0                      0.103689                      0.117773   \n",
       "\n",
       "    std_test_average_precision  mean_test_f1  mean_train_f1  mean_test_recall  \\\n",
       "10                    0.054933      0.094164       0.102085          0.051589   \n",
       "4                     0.054946      0.094164       0.102085          0.051589   \n",
       "8                     0.054867      0.094333       0.101764          0.051650   \n",
       "2                     0.054780      0.094147       0.101243          0.051528   \n",
       "5                     0.055819      0.182289       0.212806          0.778442   \n",
       "3                     0.055680      0.182233       0.212799          0.778685   \n",
       "11                    0.056034      0.197487       0.199752          0.632919   \n",
       "9                     0.042398      0.164599       0.196865          0.637849   \n",
       "7                     0.023031      0.161955       0.183370          0.789440   \n",
       "1                     0.028762      0.162537       0.178731          0.784572   \n",
       "6                     0.028932      0.000000       0.000000          0.000000   \n",
       "0                     0.016250      0.000000       0.000000          0.000000   \n",
       "\n",
       "    mean_train_recall  mean_test_precision  mean_train_precision  \\\n",
       "10           0.054347             0.657344              0.845221   \n",
       "4            0.054347             0.657344              0.845221   \n",
       "8            0.054165             0.663694              0.845274   \n",
       "2            0.053868             0.665009              0.845803   \n",
       "5            0.848012             0.103337              0.121674   \n",
       "3            0.848154             0.103297              0.121666   \n",
       "11           0.649644             0.126577              0.123732   \n",
       "9            0.684562             0.099507              0.121273   \n",
       "7            0.852772             0.090423              0.102914   \n",
       "1            0.841004             0.090711              0.099991   \n",
       "6            0.000000             0.000000              0.000000   \n",
       "0            0.000000             0.000000              0.000000   \n",
       "\n",
       "   param_logistic__C param_logistic__multi_class param_logistic__class_weight  \\\n",
       "10             10000                 multinomial                         None   \n",
       "4              10000                         ovr                         None   \n",
       "8                  1                 multinomial                         None   \n",
       "2                  1                         ovr                         None   \n",
       "5              10000                         ovr                     balanced   \n",
       "3                  1                         ovr                     balanced   \n",
       "11             10000                 multinomial                     balanced   \n",
       "9                  1                 multinomial                     balanced   \n",
       "7             0.0001                 multinomial                     balanced   \n",
       "1             0.0001                         ovr                     balanced   \n",
       "6             0.0001                 multinomial                         None   \n",
       "0             0.0001                         ovr                         None   \n",
       "\n",
       "    mean_fit_time  mean_score_time  \n",
       "10     407.314298         0.131594  \n",
       "4       26.393216         0.191900  \n",
       "8      406.623689         0.140775  \n",
       "2       14.204667         0.173727  \n",
       "5       85.101367         0.218964  \n",
       "3       24.078090         0.190684  \n",
       "11     404.090964         0.150601  \n",
       "9      462.361673         0.141590  \n",
       "7      413.333821         0.142823  \n",
       "1        6.852943         0.181055  \n",
       "6       92.038737         0.162565  \n",
       "0        6.685491         0.191661  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use same columns as above\n",
    "# Important delay GridSearchCV\n",
    "grid_cv_df_i = pd.DataFrame(grid_cv_i.cv_results_)[cols].sort_values(by='mean_test_average_precision', ascending=False)\n",
    "grid_cv_df_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments on GridSearchCV - Important delay:**\n",
    "* 4 results with AP around 0.20 but 2 with much higher f1 scores (0.18) driven but higher recall over lower precision. Decide to go for more recall and take 'fit time' time into consideration.\n",
    "* Based on above comments deciding to go with (3) following parameters:\n",
    "    * multi_class: ovr\n",
    "    * class_weight: balanced\n",
    "    * C: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.7131021  0.68916419 0.87460035 0.86152064 0.84779204]\n",
      "Predictions: [1 1 1 1 1]\n",
      "Area Under PR Curve: 0.206\n"
     ]
    }
   ],
   "source": [
    "# creating final LogisticRegression\n",
    "logreg_tuned_final_i = LogisticRegression(C=1, multi_class='ovr', class_weight='balanced', solver='liblinear')\n",
    "# fit\n",
    "logreg_tuned_final_i.fit(X_tr_arr, y_tr_arr_imp_delay_binary)\n",
    "# predict\n",
    "lr_tuned_final_pred_i = logreg_tuned_final_i.predict(X_va_arr_reindex)\n",
    "# predict probabilities\n",
    "lr_tuned_probs_i = logreg_tuned_final_i.predict_proba(X_va_arr_reindex)\n",
    "# check probabilities and compare to predicttions\n",
    "print('Probabilities:',lr_tuned_probs_i[0:5,1])\n",
    "print('Predictions:',lr_tuned_final_pred_i[0:5])\n",
    "# keep probabilities for the positive outcome only\n",
    "lr_tuned_probs_pos_i = lr_tuned_probs_i[:,1]\n",
    "\n",
    "lr_precision_tuned_i, lr_recall_tuned_i, thres_tuned_pr_i = precision_recall_curve(y_va_arr_imp_delay_binary, lr_tuned_probs_pos_i, pos_label=1)\n",
    "lr_tuned_auc_pr_i = auc(lr_recall_tuned_i, lr_precision_tuned_i)\n",
    "print('Area Under PR Curve: {:.3f}'.format(lr_tuned_auc_pr_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best threshold (important delay) <a name='logreg_c_imp_delay_thres' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.14017579 0.14015653 0.14015841 ... 0.00076321 0.00038168 0.        ]\n",
      "Best Threshold: 0.768\n",
      "Probabilities: [0.7131021  0.68916419 0.87460035 0.86152064 0.84779204 0.61206968\n",
      " 0.82413082 0.83835988 0.72494576 0.71871122]\n",
      "Predictions: [0 0 1 1 1 0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "fscores_tuned_i = (2 * lr_precision_tuned_i * lr_recall_tuned_i) / (lr_precision_tuned_i + lr_recall_tuned_i)\n",
    "print(fscores_tuned_i)\n",
    "lr_bt_tuned_pr_i = thres_tuned_pr_i[argmax(fscores_tuned_i)]\n",
    "print('Best Threshold: {:.3f}'.format(lr_bt_tuned_pr_i))\n",
    "# use threshold in model\n",
    "lr_tuned_curve_i = np.where(logreg_tuned_final_i.predict_proba(X_va_arr_reindex)[:,1] > lr_bt_tuned_pr_i, 1,0)\n",
    "print('Probabilities:',logreg_tuned_final_i.predict_proba(X_va_arr_reindex)[0:10,1])\n",
    "print('Predictions:',lr_tuned_curve_i[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report (important delay) <a name='logreg_c_imp_delay_report' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: Logistic Regression delay - optimzed threshold at 0.768 on PR curve\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       no_delay       0.96      0.94      0.95    103481\n",
      "important_delay       0.20      0.31      0.25      5239\n",
      "\n",
      "       accuracy                           0.91    108720\n",
      "      macro avg       0.58      0.62      0.60    108720\n",
      "   weighted avg       0.93      0.91      0.92    108720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: Logistic Regression delay - optimzed threshold at {:.3f} on PR curve'.format(lr_bt_tuned_pr_i))\n",
    "report_logreg_preds_tuned_pr_i = classification_report(y_true=y_va_arr_imp_delay_binary, y_pred=lr_tuned_curve_i, target_names=['no_delay','important_delay'])\n",
    "#f1_logreg_pr_d = classification_report(y_true=y_va_arr_delay_binary, y_pred=lr_curve_d, target_names=['no_delay','delay'], output_dict=True)['delay']['f1-score']\n",
    "print(report_logreg_preds_tuned_pr_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Strong performance very similar to (ii) balanced, interesting to have high recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance on test set (Logistic regression) <a name='logreg_test' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under PR Curve: 0.652\n",
      "Probabilities: [0.56535422 0.53189748 0.64550162 0.61400207 0.91730315 0.47913815\n",
      " 0.86809157 0.9221443  0.70394967 0.59859178]\n",
      "Predictions: [0 0 1 1 1 0 1 1 1 1]\n",
      "Classification report: Logistic Regression delay TEST - optimzed threshold at 0.594 on PR curve\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    no_delay       0.90      0.79      0.84     80088\n",
      "       delay       0.55      0.76      0.64     27278\n",
      "\n",
      "    accuracy                           0.78    107366\n",
      "   macro avg       0.73      0.77      0.74    107366\n",
      "weighted avg       0.81      0.78      0.79    107366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# delay\n",
    "# area under precision-recall curve test\n",
    "lr_test_probs_pos_d = logreg_tuned_final_d.predict_proba(X_te_arr_reindex)[:,1]\n",
    "lr_precision_test_d, lr_recall_test_d, _ = precision_recall_curve(y_te_arr_delay_binary, lr_test_probs_pos_d, pos_label=1)\n",
    "lr_test_auc_pr_d = auc(lr_recall_test_d, lr_precision_test_d)\n",
    "print('Area Under PR Curve: {:.3f}'.format(lr_test_auc_pr_d))\n",
    "# use threshold in model\n",
    "lr_test_d = np.where(logreg_tuned_final_d.predict_proba(X_te_arr_reindex)[:,1] > lr_bt_tuned_pr_d, 1,0)\n",
    "print('Probabilities:',logreg_tuned_final_d.predict_proba(X_te_arr_reindex)[0:10,1])\n",
    "print('Predictions:',lr_test_d[0:10])\n",
    "print('Classification report: Logistic Regression delay TEST - optimzed threshold at {:.3f} on PR curve'.format(lr_bt_tuned_pr_d))\n",
    "report_logreg_test_d = classification_report(y_true=y_te_arr_delay_binary, y_pred=lr_test_d, target_names=['no_delay','delay'])\n",
    "f1_logreg_test_d = classification_report(y_true=y_te_arr_delay_binary, y_pred=lr_test_d, target_names=['no_delay','delay'], output_dict=True)['delay']['f1-score']\n",
    "precision_logreg_test_d = classification_report(y_true=y_te_arr_delay_binary, y_pred=lr_test_d, target_names=['no_delay','delay'], output_dict=True)['delay']['precision']\n",
    "recall_logreg_test_d = classification_report(y_true=y_te_arr_delay_binary, y_pred=lr_test_d, target_names=['no_delay','delay'], output_dict=True)['delay']['recall']\n",
    "print(report_logreg_test_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under PR Curve: 0.270\n",
      "Probabilities: [0.7131021  0.68916419 0.87460035 0.86152064 0.84779204 0.61206968\n",
      " 0.82413082 0.83835988 0.72494576 0.71871122]\n",
      "Predictions: [0 0 1 1 1 0 1 1 0 0]\n",
      "Classification report: Logistic Regression important delay TEST - optimzed threshold at 0.768 on PR curve\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       no_delay       0.95      0.94      0.95    100362\n",
      "important_delay       0.28      0.32      0.30      7004\n",
      "\n",
      "       accuracy                           0.90    107366\n",
      "      macro avg       0.62      0.63      0.62    107366\n",
      "   weighted avg       0.91      0.90      0.91    107366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# important delay\n",
    "# area under precision-recall curve test\n",
    "lr_test_probs_pos_i = logreg_tuned_final_i.predict_proba(X_te_arr_reindex)[:,1]\n",
    "lr_precision_test_i, lr_recall_test_i, _ = precision_recall_curve(y_te_arr_imp_delay_binary, lr_test_probs_pos_i, pos_label=1)\n",
    "lr_test_auc_pr_i = auc(lr_recall_test_i, lr_precision_test_i)\n",
    "print('Area Under PR Curve: {:.3f}'.format(lr_test_auc_pr_i))\n",
    "# use threshold in model\n",
    "lr_test_i = np.where(logreg_tuned_final_i.predict_proba(X_te_arr_reindex)[:,1] > lr_bt_tuned_pr_i, 1,0)\n",
    "print('Probabilities:',logreg_tuned_final_i.predict_proba(X_te_arr_reindex)[0:10,1])\n",
    "print('Predictions:',lr_test_i[0:10])\n",
    "print('Classification report: Logistic Regression important delay TEST - optimzed threshold at {:.3f} on PR curve'.format(lr_bt_tuned_pr_i))\n",
    "report_logreg_test_i = classification_report(y_true=y_te_arr_imp_delay_binary, y_pred=lr_test_i, target_names=['no_delay','important_delay'])\n",
    "f1_logreg_test_i = classification_report(y_true=y_te_arr_imp_delay_binary, y_pred=lr_test_i, target_names=['no_delay','important_delay'], output_dict=True)['important_delay']['f1-score']\n",
    "precision_logreg_test_i = classification_report(y_true=y_te_arr_imp_delay_binary, y_pred=lr_test_i, target_names=['no_delay','important_delay'], output_dict=True)['important_delay']['precision']\n",
    "recall_logreg_test_i = classification_report(y_true=y_te_arr_imp_delay_binary, y_pred=lr_test_i, target_names=['no_delay','important_delay'], output_dict=True)['important_delay']['recall']\n",
    "print(report_logreg_test_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) k-NN (decided to not tune classifier for comparative analysis due to computation power) <a name='knn' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delay <a name='knn_delay' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN: delay\n",
      "Precision k-NN delay: 0.5079\n",
      "Recall k-NN delay: 0.4928\n",
      "F1 score k-NN delay: 0.5003\n",
      "1349.2175543308258\n"
     ]
    }
   ],
   "source": [
    "start_knn = time.time()\n",
    "# create classifier\n",
    "knn_d = KNeighborsClassifier()\n",
    "\n",
    "# fit\n",
    "knn_d.fit(X_tr_arr, y_tr_arr_delay_binary)\n",
    "#logreg_i.fit(X_tr_arr, y_tr_arr_imp_delay)\n",
    "\n",
    "# evaluate\n",
    "score_knn_arr_d = knn_d.score(X_va_arr_reindex, y_va_arr_delay_binary)\n",
    "\n",
    "y_pred_knn_va_arr_d = knn_d.predict(X_va_arr_reindex) # prediction delay\n",
    "precision_knn_arr_d = precision_score(y_true=y_va_arr_delay_binary, y_pred=y_pred_knn_va_arr_d, pos_label=1)\n",
    "recall_knn_arr_d = recall_score(y_true=y_va_arr_delay_binary, y_pred=y_pred_knn_va_arr_d, pos_label=1)\n",
    "f1_knn_arr_d = f1_score(y_true=y_va_arr_delay_binary, y_pred=y_pred_knn_va_arr_d, pos_label=1)\n",
    "\n",
    "# print\n",
    "print('k-NN: delay')\n",
    "#print('Score k-NN delay: {:.4f}'.format(score_knn_arr_d))\n",
    "print('Precision k-NN delay: {:.4f}'.format(precision_knn_arr_d))\n",
    "print('Recall k-NN delay: {:.4f}'.format(recall_knn_arr_d))\n",
    "print('F1 score k-NN delay: {:.4f}'.format(f1_knn_arr_d))\n",
    "\n",
    "end_knn = time.time()\n",
    "print(end_knn - start_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (normalized): k-NN delay\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred: delay</th>\n",
       "      <th>pred: no delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true: delay</th>\n",
       "      <td>0.700101</td>\n",
       "      <td>0.096919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true: no delay</th>\n",
       "      <td>0.102943</td>\n",
       "      <td>0.100037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pred: delay  pred: no delay\n",
       "true: delay        0.700101        0.096919\n",
       "true: no delay     0.102943        0.100037"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix 'k-NN delay'\n",
    "matrix_knn_d = confusion_matrix(y_true=y_va_arr_delay_binary, y_pred=y_pred_knn_va_arr_d,normalize='all') # normalize either on columns/rows or all\n",
    "matrix_knn_d = pd.DataFrame(\n",
    "    matrix_knn_d, \n",
    "    columns=['pred: delay', 'pred: no delay'],\n",
    "    index=['true: delay', 'true: no delay']\n",
    ")\n",
    "print('Confusion matrix (normalized): k-NN delay')\n",
    "matrix_knn_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: k-NN delay\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88     86652\n",
      "           1       0.51      0.49      0.50     22068\n",
      "\n",
      "    accuracy                           0.80    108720\n",
      "   macro avg       0.69      0.69      0.69    108720\n",
      "weighted avg       0.80      0.80      0.80    108720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: k-NN delay')\n",
    "report_knn_d = classification_report(y_true=y_va_arr_delay_binary, y_pred=y_pred_knn_va_arr_d)\n",
    "print(report_knn_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important delay <a name='knn_imp_delay' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN: delay\n",
      "Precision k-NN delay: 0.3639\n",
      "Recall k-NN delay: 0.1210\n",
      "F1 score k-NN delay: 0.1816\n",
      "21470.36544728279\n"
     ]
    }
   ],
   "source": [
    "start_knn_i = time.time()\n",
    "# create classifier\n",
    "knn_i = KNeighborsClassifier()\n",
    "\n",
    "# fit\n",
    "knn_i.fit(X_tr_arr, y_tr_arr_imp_delay_binary)\n",
    "#logreg_i.fit(X_tr_arr, y_tr_arr_imp_delay)\n",
    "\n",
    "# evaluate\n",
    "score_knn_arr_i = knn_i.score(X_va_arr_reindex, y_va_arr_imp_delay_binary)\n",
    "\n",
    "y_pred_knn_va_arr_i = knn_i.predict(X_va_arr_reindex) # prediction delay\n",
    "precision_knn_arr_i = precision_score(y_true=y_va_arr_imp_delay_binary, y_pred=y_pred_knn_va_arr_i, pos_label=1)\n",
    "recall_knn_arr_i = recall_score(y_true=y_va_arr_imp_delay_binary, y_pred=y_pred_knn_va_arr_i, pos_label=1)\n",
    "f1_knn_arr_i = f1_score(y_true=y_va_arr_imp_delay_binary, y_pred=y_pred_knn_va_arr_i, pos_label=1)\n",
    "\n",
    "# print\n",
    "print('k-NN: delay')\n",
    "#print('Score k-NN delay: {:.4f}'.format(score_knn_arr_d))\n",
    "print('Precision k-NN delay: {:.4f}'.format(precision_knn_arr_i))\n",
    "print('Recall k-NN delay: {:.4f}'.format(recall_knn_arr_i))\n",
    "print('F1 score k-NN delay: {:.4f}'.format(f1_knn_arr_i))\n",
    "\n",
    "end_knn_i = time.time()\n",
    "print(end_knn_i - start_knn_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (normalized): k-NN important delay\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred: no delay</th>\n",
       "      <th>pred: important delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true: no delay</th>\n",
       "      <td>0.941621</td>\n",
       "      <td>0.010191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true: important delay</th>\n",
       "      <td>0.042357</td>\n",
       "      <td>0.005831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       pred: no delay  pred: important delay\n",
       "true: no delay               0.941621               0.010191\n",
       "true: important delay        0.042357               0.005831"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix 'k-NN important delay'\n",
    "matrix_knn_i = confusion_matrix(y_true=y_va_arr_imp_delay_binary, y_pred=y_pred_knn_va_arr_i,normalize='all') # normalize either on columns/rows or all\n",
    "matrix_knn_i = pd.DataFrame(\n",
    "    matrix_knn_i, \n",
    "    columns=['pred: no delay', 'pred: important delay'],\n",
    "    index=['true: no delay', 'true: important delay']\n",
    ")\n",
    "print('Confusion matrix (normalized): k-NN important delay')\n",
    "matrix_knn_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: k-NN important delay\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97    103481\n",
      "           1       0.36      0.12      0.18      5239\n",
      "\n",
      "    accuracy                           0.95    108720\n",
      "   macro avg       0.66      0.56      0.58    108720\n",
      "weighted avg       0.93      0.95      0.93    108720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: k-NN important delay')\n",
    "report_knn_i = classification_report(y_true=y_va_arr_imp_delay_binary, y_pred=y_pred_knn_va_arr_i)\n",
    "print(report_knn_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments:**\n",
    "* Takes too long to run due to \"Curse of dimensionality\" issue, 1 hour without tuning. Decide not to try optimized as we use too many ressource without potentially improving performance\n",
    "* Alternative I have thought of:\n",
    "    * A-NN: seems in theory to better perform on large data sets but \"Curse of dimensionality\" would still apply ([knn to be replaced by ann](https://pub.towardsai.net/knn-k-nearest-neighbors-is-dead-fc16507eb3e))\n",
    "    * PCA: also sub-optimal for categorical variables (also thought about other dimensionality reduction technics like ['Prince package'](https://towardsdatascience.com/5-must-know-dimensionality-reduction-techniques-via-prince-e6ffb27e55d1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance on test set (k-NN) <a name='knn_test' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN: delay\n",
      "Precision k-NN delay: 0.6116\n",
      "Recall k-NN delay: 0.4787\n",
      "F1 score k-NN delay: 0.5371\n",
      "Area Under PR Curve: 0.610\n",
      "Classification report: k-NN delay\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86     80088\n",
      "           1       0.61      0.48      0.54     27278\n",
      "\n",
      "    accuracy                           0.79    107366\n",
      "   macro avg       0.72      0.69      0.70    107366\n",
      "weighted avg       0.78      0.79      0.78    107366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# delay\n",
    "y_pred_knn_d = knn_d.predict(X_te_arr_reindex) # prediction delay\n",
    "precision_knn_d = precision_score(y_true=y_te_arr_delay_binary, y_pred=y_pred_knn_d, pos_label=1)\n",
    "recall_knn_d = recall_score(y_true=y_te_arr_delay_binary, y_pred=y_pred_knn_d, pos_label=1)\n",
    "f1_knn_d = f1_score(y_true=y_te_arr_delay_binary, y_pred=y_pred_knn_d, pos_label=1)\n",
    "\n",
    "# print\n",
    "print('k-NN: delay')\n",
    "#print('Score k-NN delay: {:.4f}'.format(score_knn_arr_d))\n",
    "print('Precision k-NN delay: {:.4f}'.format(precision_knn_d))\n",
    "print('Recall k-NN delay: {:.4f}'.format(recall_knn_d))\n",
    "print('F1 score k-NN delay: {:.4f}'.format(f1_knn_d))\n",
    "\n",
    "knn_test_probs_pos_d = knn_d.predict_proba(X_te_arr_reindex)[:,1]\n",
    "knn_precision_test_d, knn_recall_test_d, _ = precision_recall_curve(y_te_arr_delay_binary, knn_test_probs_pos_d, pos_label=1)\n",
    "knn_test_auc_pr_d = auc(knn_recall_test_d, knn_precision_test_d)\n",
    "print('Area Under PR Curve: {:.3f}'.format(knn_test_auc_pr_d))\n",
    "\n",
    "print('Classification report: k-NN delay')\n",
    "# below are duplicates from above but consistant with calculation from other classifiers\n",
    "report_knn_test_d = classification_report(y_true=y_te_arr_delay_binary, y_pred=y_pred_knn_d)\n",
    "f1_knn_test_d = classification_report(y_true=y_te_arr_delay_binary, y_pred=y_pred_knn_d, target_names=['no_delay','delay'], output_dict=True)['delay']['f1-score']\n",
    "precision_knn_test_d = classification_report(y_true=y_te_arr_delay_binary, y_pred=y_pred_knn_d, target_names=['no_delay','delay'], output_dict=True)['delay']['precision']\n",
    "recall_knn_test_d = classification_report(y_true=y_te_arr_delay_binary, y_pred=y_pred_knn_d, target_names=['no_delay','delay'], output_dict=True)['delay']['recall']\n",
    "print(report_knn_test_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN: important delay\n",
      "Precision k-NN important delay: 0.4074\n",
      "Recall k-NN important delay: 0.1015\n",
      "F1 score k-NN important delay: 0.1625\n",
      "Area Under PR Curve: 0.223\n",
      "Classification report: k-NN important delay\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96    100362\n",
      "           1       0.41      0.10      0.16      7004\n",
      "\n",
      "    accuracy                           0.93    107366\n",
      "   macro avg       0.67      0.55      0.56    107366\n",
      "weighted avg       0.91      0.93      0.91    107366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# important delay\n",
    "y_pred_knn_i = knn_i.predict(X_te_arr_reindex) # prediction delay\n",
    "precision_knn_i = precision_score(y_true=y_te_arr_imp_delay_binary, y_pred=y_pred_knn_i, pos_label=1)\n",
    "recall_knn_i = recall_score(y_true=y_te_arr_imp_delay_binary, y_pred=y_pred_knn_i, pos_label=1)\n",
    "f1_knn_i = f1_score(y_true=y_te_arr_imp_delay_binary, y_pred=y_pred_knn_i, pos_label=1)\n",
    "\n",
    "# print\n",
    "print('k-NN: important delay')\n",
    "#print('Score k-NN delay: {:.4f}'.format(score_knn_arr_d))\n",
    "print('Precision k-NN important delay: {:.4f}'.format(precision_knn_i))\n",
    "print('Recall k-NN important delay: {:.4f}'.format(recall_knn_i))\n",
    "print('F1 score k-NN important delay: {:.4f}'.format(f1_knn_i))\n",
    "\n",
    "knn_test_probs_pos_i = knn_i.predict_proba(X_te_arr_reindex)[:,1]\n",
    "knn_precision_test_i, knn_recall_test_i, _ = precision_recall_curve(y_te_arr_imp_delay_binary, knn_test_probs_pos_i, pos_label=1)\n",
    "knn_test_auc_pr_i = auc(knn_recall_test_i, knn_precision_test_i)\n",
    "print('Area Under PR Curve: {:.3f}'.format(knn_test_auc_pr_i))\n",
    "\n",
    "print('Classification report: k-NN important delay')\n",
    "# below are duplicates from above but consistant with calculation from other classifiers\n",
    "report_knn_test_i = classification_report(y_true=y_te_arr_imp_delay_binary, y_pred=y_pred_knn_i)\n",
    "f1_knn_test_i = classification_report(y_true=y_te_arr_imp_delay_binary, y_pred=y_pred_knn_i, target_names=['no_delay','important_delay'], output_dict=True)['important_delay']['f1-score']\n",
    "precision_knn_test_i = classification_report(y_true=y_te_arr_imp_delay_binary, y_pred=y_pred_knn_i, target_names=['no_delay','important_delay'], output_dict=True)['important_delay']['precision']\n",
    "recall_knn_test_i = classification_report(y_true=y_te_arr_imp_delay_binary, y_pred=y_pred_knn_i, target_names=['no_delay','important_delay'], output_dict=True)['important_delay']['recall']\n",
    "print(report_knn_test_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii) SVMs (support vector Machine) <a name='svms' />\n",
    "*<a href=#top>Back to top</a>*\n",
    "* Linear (Delay and Important delay)\n",
    "* RBF (too slow, decided to not include classifier in anaylsis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC # don't 'predict_proba()'\n",
    "from sklearn.svm import SVC # accepts 'predict_proba()', but very slow with current data set\n",
    "from sklearn.calibration import CalibratedClassifierCV # use with LinearSVC to have 'predict_proba()'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM (Delay) <a name='svm_lin' /><a name='svm_delay' />\n",
    "*<a href=#top>Back to top</a>*\n",
    "##### Grid search using loop <a name='svm_delay_loop' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001 class weight: None auprc_valid 0.5621938611743411\n",
      "C: 0.001 class weight: balanced auprc_valid 0.5561051449399246\n",
      "C: 0.01 class weight: None auprc_valid 0.5704918333337253\n",
      "C: 0.01 class weight: balanced auprc_valid 0.56462618249401\n",
      "C: 0.1 class weight: None auprc_valid 0.5713425828468711\n",
      "C: 0.1 class weight: balanced auprc_valid 0.5655830949513916\n",
      "C: 1 class weight: None auprc_valid 0.5713760332406144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 1 class weight: balanced auprc_valid 0.5656395001235871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 10 class weight: None auprc_valid 0.5714835223604716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 10 class weight: balanced auprc_valid 0.5629977773134216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 100 class weight: None auprc_valid 0.5536324428153062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 100 class weight: balanced auprc_valid 0.5492368433434655\n"
     ]
    }
   ],
   "source": [
    "#for i in tqdm(range(0, 100), desc =\"Text You Want\"):\n",
    "#    sleep(.1)\n",
    "#print('done')\n",
    "\n",
    "Cs  = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "class_weight = [None,'balanced']\n",
    "\n",
    "linear_results = []\n",
    "for c in Cs:\n",
    "    for cw in class_weight:\n",
    "        #svc_d = SVC(C=c, class_weight=cw, kernel='linear')\n",
    "        svc_lin = LinearSVC(C=c, class_weight=cw)\n",
    "        svc_d = CalibratedClassifierCV(svc_lin)\n",
    "        # fit\n",
    "        svc_d.fit(X_tr_arr, y_tr_arr_delay_binary)\n",
    "        # predict\n",
    "        y_pred_svc_va_arr_d = svc_d.predict(X_va_arr_reindex) # validation\n",
    "        y_pred_svc_tr_arr_d = svc_d.predict(X_tr_arr) # train\n",
    "        # predict probabilities\n",
    "        svc_va_probs_d = svc_d.predict_proba(X_va_arr_reindex) # validation\n",
    "        svc_tr_probs_d = svc_d.predict_proba(X_tr_arr) # train\n",
    "        # keep probabilities for the positive outcome only\n",
    "        svc_va_probs_pos_d = svc_va_probs_d[:,1] # validation\n",
    "        svc_tr_probs_pos_d = svc_tr_probs_d[:,1] # train\n",
    "        # calculate precission and recall\n",
    "        svc_va_precision_d, svc_va_recall_d, _ = precision_recall_curve(y_va_arr_delay_binary, svc_va_probs_pos_d, pos_label=1) # validation\n",
    "        svc_tr_precision_d, svc_tr_recall_d, _ = precision_recall_curve(y_tr_arr_delay_binary, svc_tr_probs_pos_d, pos_label=1) # train\n",
    "        # calculate auprc\n",
    "        svc_va_auprc_d = auc(svc_va_recall_d, svc_va_precision_d) # validation\n",
    "        svc_tr_auprc_d = auc(svc_tr_recall_d, svc_tr_precision_d) # train\n",
    "        \n",
    "        linear_results.append({\n",
    "            'C':c,\n",
    "            'Class_weight':cw,\n",
    "            'auprc_valid':svc_va_auprc_d,\n",
    "            'auprc_train':svc_tr_auprc_d,\n",
    "            'f1_score_valid':f1_score(y_true=y_va_arr_delay_binary, y_pred=y_pred_svc_va_arr_d, pos_label=1),\n",
    "            'f1_score_train':f1_score(y_true=y_tr_arr_delay_binary, y_pred=y_pred_svc_tr_arr_d, pos_label=1),\n",
    "            'recall_valid': recall_score(y_true=y_va_arr_delay_binary, y_pred=y_pred_svc_va_arr_d, pos_label=1),\n",
    "            'recall_train': recall_score(y_true=y_tr_arr_delay_binary, y_pred=y_pred_svc_tr_arr_d, pos_label=1),\n",
    "            'precision_valid': precision_score(y_true=y_va_arr_delay_binary, y_pred=y_pred_svc_va_arr_d, pos_label=1),\n",
    "            'precision_train': precision_score(y_true=y_tr_arr_delay_binary, y_pred=y_pred_svc_tr_arr_d, pos_label=1)\n",
    "        })\n",
    "        print('C:',c,'class weight:',cw,'auprc_valid',svc_va_auprc_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>Class_weight</th>\n",
       "      <th>auprc_train</th>\n",
       "      <th>auprc_valid</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_valid</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>precision_valid</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>recall_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.638223</td>\n",
       "      <td>0.571484</td>\n",
       "      <td>0.514066</td>\n",
       "      <td>0.488407</td>\n",
       "      <td>0.654085</td>\n",
       "      <td>0.577976</td>\n",
       "      <td>0.423424</td>\n",
       "      <td>0.422875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.638352</td>\n",
       "      <td>0.571376</td>\n",
       "      <td>0.516003</td>\n",
       "      <td>0.491052</td>\n",
       "      <td>0.651016</td>\n",
       "      <td>0.576392</td>\n",
       "      <td>0.427371</td>\n",
       "      <td>0.427723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.638318</td>\n",
       "      <td>0.571343</td>\n",
       "      <td>0.516346</td>\n",
       "      <td>0.491299</td>\n",
       "      <td>0.651401</td>\n",
       "      <td>0.576662</td>\n",
       "      <td>0.427676</td>\n",
       "      <td>0.427950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010</td>\n",
       "      <td>None</td>\n",
       "      <td>0.637601</td>\n",
       "      <td>0.570492</td>\n",
       "      <td>0.514369</td>\n",
       "      <td>0.490219</td>\n",
       "      <td>0.651447</td>\n",
       "      <td>0.577566</td>\n",
       "      <td>0.424950</td>\n",
       "      <td>0.425820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.633464</td>\n",
       "      <td>0.565640</td>\n",
       "      <td>0.528361</td>\n",
       "      <td>0.498998</td>\n",
       "      <td>0.640769</td>\n",
       "      <td>0.566826</td>\n",
       "      <td>0.449506</td>\n",
       "      <td>0.445668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.100</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.633420</td>\n",
       "      <td>0.565583</td>\n",
       "      <td>0.528498</td>\n",
       "      <td>0.499036</td>\n",
       "      <td>0.640716</td>\n",
       "      <td>0.566705</td>\n",
       "      <td>0.449729</td>\n",
       "      <td>0.445804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.632594</td>\n",
       "      <td>0.564626</td>\n",
       "      <td>0.527813</td>\n",
       "      <td>0.498999</td>\n",
       "      <td>0.639985</td>\n",
       "      <td>0.566388</td>\n",
       "      <td>0.449099</td>\n",
       "      <td>0.445940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.632487</td>\n",
       "      <td>0.562998</td>\n",
       "      <td>0.530365</td>\n",
       "      <td>0.501423</td>\n",
       "      <td>0.637371</td>\n",
       "      <td>0.564374</td>\n",
       "      <td>0.454124</td>\n",
       "      <td>0.451106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>None</td>\n",
       "      <td>0.629291</td>\n",
       "      <td>0.562194</td>\n",
       "      <td>0.503620</td>\n",
       "      <td>0.481256</td>\n",
       "      <td>0.653428</td>\n",
       "      <td>0.580480</td>\n",
       "      <td>0.409692</td>\n",
       "      <td>0.411002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.624115</td>\n",
       "      <td>0.556105</td>\n",
       "      <td>0.512704</td>\n",
       "      <td>0.486877</td>\n",
       "      <td>0.642498</td>\n",
       "      <td>0.569996</td>\n",
       "      <td>0.426537</td>\n",
       "      <td>0.424914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        C Class_weight  auprc_train  auprc_valid  f1_score_train  \\\n",
       "8  10.000         None     0.638223     0.571484        0.514066   \n",
       "6   1.000         None     0.638352     0.571376        0.516003   \n",
       "4   0.100         None     0.638318     0.571343        0.516346   \n",
       "2   0.010         None     0.637601     0.570492        0.514369   \n",
       "7   1.000     balanced     0.633464     0.565640        0.528361   \n",
       "5   0.100     balanced     0.633420     0.565583        0.528498   \n",
       "3   0.010     balanced     0.632594     0.564626        0.527813   \n",
       "9  10.000     balanced     0.632487     0.562998        0.530365   \n",
       "0   0.001         None     0.629291     0.562194        0.503620   \n",
       "1   0.001     balanced     0.624115     0.556105        0.512704   \n",
       "\n",
       "   f1_score_valid  precision_train  precision_valid  recall_train  \\\n",
       "8        0.488407         0.654085         0.577976      0.423424   \n",
       "6        0.491052         0.651016         0.576392      0.427371   \n",
       "4        0.491299         0.651401         0.576662      0.427676   \n",
       "2        0.490219         0.651447         0.577566      0.424950   \n",
       "7        0.498998         0.640769         0.566826      0.449506   \n",
       "5        0.499036         0.640716         0.566705      0.449729   \n",
       "3        0.498999         0.639985         0.566388      0.449099   \n",
       "9        0.501423         0.637371         0.564374      0.454124   \n",
       "0        0.481256         0.653428         0.580480      0.409692   \n",
       "1        0.486877         0.642498         0.569996      0.426537   \n",
       "\n",
       "   recall_valid  \n",
       "8      0.422875  \n",
       "6      0.427723  \n",
       "4      0.427950  \n",
       "2      0.425820  \n",
       "7      0.445668  \n",
       "5      0.445804  \n",
       "3      0.445940  \n",
       "9      0.451106  \n",
       "0      0.411002  \n",
       "1      0.424914  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_results_df = pd.DataFrame(linear_results).sort_values(by='auprc_valid', ascending=False)\n",
    "linear_results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under PR Curve: 0.571\n"
     ]
    }
   ],
   "source": [
    "svc_final_d = CalibratedClassifierCV(LinearSVC(C=1 , class_weight=None))\n",
    "# fit\n",
    "svc_final_d.fit(X_tr_arr, y_tr_arr_delay_binary)\n",
    "# predict\n",
    "y_pred_svc_final_d = svc_final_d.predict(X_va_arr_reindex)\n",
    "# predict probabilities\n",
    "svc_final_probs_d = svc_final_d.predict_proba(X_va_arr_reindex)\n",
    "# keep probabilities for the positive outcome only\n",
    "svc_final_probs_pos_d = svc_final_probs_d[:,1]\n",
    "# Precision-recall curve metrics\n",
    "svc_precision_final_d, svc_recall_final_d, svc_thres_final_d = precision_recall_curve(y_va_arr_delay_binary, svc_final_probs_pos_d, pos_label=1)\n",
    "svc_final_auprc_d = auc(svc_recall_final_d, svc_precision_final_d)\n",
    "print('Area Under PR Curve: {:.3f}'.format(svc_final_auprc_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best threshold (Linear SVM - Delay) <a name='svm_delay_thres' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.284\n",
      "Probabilities: [0.2329558  0.21055468 0.29083123 0.26459183 0.79053612 0.18808951\n",
      " 0.67454621 0.80348959 0.37042526 0.26811565]\n",
      "Predictions: [0 0 1 0 1 0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from numpy import argmax\n",
    "fscores_svc_d = (2 * svc_precision_final_d * svc_recall_final_d) / (svc_precision_final_d + svc_recall_final_d)\n",
    "svc_bt_d = svc_thres_final_d[argmax(fscores_svc_d)]\n",
    "print('Best Threshold: {:.3f}'.format(svc_bt_d))\n",
    "# use threshold in model\n",
    "svc_final_curve_d = np.where(svc_final_probs_d[:,1] > svc_bt_d, 1,0)\n",
    "print('Probabilities:',svc_final_probs_d[0:10,1])\n",
    "print('Predictions:',svc_final_curve_d[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification report (Linear SVM - Delay) <a name='svm_delay_report' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: SVC Linear delay - optimzed threshold at 0.284 on PR curve\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    no_delay       0.92      0.77      0.84     86652\n",
      "       delay       0.45      0.73      0.56     22068\n",
      "\n",
      "    accuracy                           0.77    108720\n",
      "   macro avg       0.69      0.75      0.70    108720\n",
      "weighted avg       0.83      0.77      0.78    108720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: SVC Linear delay - optimzed threshold at {:.3f} on PR curve'.format(svc_bt_d))\n",
    "report_svc_preds_final_pr_d = classification_report(y_true=y_va_arr_delay_binary, y_pred=svc_final_curve_d, target_names=['no_delay','delay'])\n",
    "#f1_logreg_pr_d = classification_report(y_true=y_va_arr_delay_binary, y_pred=lr_curve_d, target_names=['no_delay','delay'], output_dict=True)['delay']['f1-score']\n",
    "print(report_svc_preds_final_pr_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM (Important delay) <a name='svm_imp_delay' />\n",
    "*<a href=#top>Back to top</a>*\n",
    "#### Grid search using loop <a name='svm_imp_delay_loop' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001 class weight: None auprc_valid 0.2110644718267538\n",
      "C: 0.001 class weight: balanced auprc_valid 0.18944952245373603\n",
      "C: 0.01 class weight: None auprc_valid 0.21500971202279331\n",
      "C: 0.01 class weight: balanced auprc_valid 0.20053616332773117\n",
      "C: 0.1 class weight: None auprc_valid 0.21569242637452726\n",
      "C: 0.1 class weight: balanced auprc_valid 0.2026441757679611\n",
      "C: 1 class weight: None auprc_valid 0.21569326362997177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 1 class weight: balanced auprc_valid 0.20292878690166027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 10 class weight: None auprc_valid 0.21364852641646473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 10 class weight: balanced auprc_valid 0.21132059493766522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 100 class weight: None auprc_valid 0.18355209756048838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 100 class weight: balanced auprc_valid 0.20608632860449883\n"
     ]
    }
   ],
   "source": [
    "#for i in tqdm(range(0, 100), desc =\"Text You Want\"):\n",
    "#    sleep(.1)\n",
    "#print('done')\n",
    "\n",
    "Cs  = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "class_weight = [None,'balanced']\n",
    "\n",
    "linear_results_i = []\n",
    "for c in Cs:\n",
    "    for cw in class_weight:\n",
    "        #svc_d = SVC(C=c, class_weight=cw, kernel='linear')\n",
    "        svc_lin_i = LinearSVC(C=c, class_weight=cw)\n",
    "        svc_i = CalibratedClassifierCV(svc_lin_i)\n",
    "        # fit\n",
    "        svc_i.fit(X_tr_arr, y_tr_arr_imp_delay_binary)\n",
    "        # predict\n",
    "        y_pred_svc_va_arr_i = svc_i.predict(X_va_arr_reindex) # validation\n",
    "        y_pred_svc_tr_arr_i = svc_i.predict(X_tr_arr) # train\n",
    "        # predict probabilities\n",
    "        svc_va_probs_i = svc_i.predict_proba(X_va_arr_reindex) # validation\n",
    "        svc_tr_probs_i = svc_i.predict_proba(X_tr_arr) # train\n",
    "        # keep probabilities for the positive outcome only\n",
    "        svc_va_probs_pos_i = svc_va_probs_i[:,1] # validation\n",
    "        svc_tr_probs_pos_i = svc_tr_probs_i[:,1] # train\n",
    "        # calculate precission and recall\n",
    "        svc_va_precision_i, svc_va_recall_i, _ = precision_recall_curve(y_va_arr_imp_delay_binary, svc_va_probs_pos_i, pos_label=1) # validation\n",
    "        svc_tr_precision_i, svc_tr_recall_i, _ = precision_recall_curve(y_tr_arr_imp_delay_binary, svc_tr_probs_pos_i, pos_label=1) # train\n",
    "        # calculate auprc\n",
    "        svc_va_auprc_i = auc(svc_va_recall_i, svc_va_precision_i) # validation\n",
    "        svc_tr_auprc_i = auc(svc_tr_recall_i, svc_tr_precision_i) # train\n",
    "        \n",
    "        linear_results_i.append({\n",
    "            'C':c,\n",
    "            'Class_weight':cw,\n",
    "            'auprc_valid':svc_va_auprc_i,\n",
    "            'auprc_train':svc_tr_auprc_i,\n",
    "            'f1_score_valid':f1_score(y_true=y_va_arr_imp_delay_binary, y_pred=y_pred_svc_va_arr_i, pos_label=1),\n",
    "            'f1_score_train':f1_score(y_true=y_tr_arr_imp_delay_binary, y_pred=y_pred_svc_tr_arr_i, pos_label=1),\n",
    "            'recall_valid': recall_score(y_true=y_va_arr_imp_delay_binary, y_pred=y_pred_svc_va_arr_i, pos_label=1),\n",
    "            'recall_train': recall_score(y_true=y_tr_arr_imp_delay_binary, y_pred=y_pred_svc_tr_arr_i, pos_label=1),\n",
    "            'precision_valid': precision_score(y_true=y_va_arr_imp_delay_binary, y_pred=y_pred_svc_va_arr_i, pos_label=1),\n",
    "            'precision_train': precision_score(y_true=y_tr_arr_imp_delay_binary, y_pred=y_pred_svc_tr_arr_i, pos_label=1)\n",
    "        })\n",
    "        print('C:',c,'class weight:',cw,'auprc_valid',svc_va_auprc_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>Class_weight</th>\n",
       "      <th>auprc_train</th>\n",
       "      <th>auprc_valid</th>\n",
       "      <th>f1_score_train</th>\n",
       "      <th>f1_score_valid</th>\n",
       "      <th>precision_train</th>\n",
       "      <th>precision_valid</th>\n",
       "      <th>recall_train</th>\n",
       "      <th>recall_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.276136</td>\n",
       "      <td>0.215693</td>\n",
       "      <td>0.113478</td>\n",
       "      <td>0.095920</td>\n",
       "      <td>0.849315</td>\n",
       "      <td>0.767908</td>\n",
       "      <td>0.060801</td>\n",
       "      <td>0.051155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.100</td>\n",
       "      <td>None</td>\n",
       "      <td>0.276208</td>\n",
       "      <td>0.215692</td>\n",
       "      <td>0.112850</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.848561</td>\n",
       "      <td>0.766571</td>\n",
       "      <td>0.060444</td>\n",
       "      <td>0.050773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010</td>\n",
       "      <td>None</td>\n",
       "      <td>0.275458</td>\n",
       "      <td>0.215010</td>\n",
       "      <td>0.111028</td>\n",
       "      <td>0.093599</td>\n",
       "      <td>0.853846</td>\n",
       "      <td>0.772189</td>\n",
       "      <td>0.059374</td>\n",
       "      <td>0.049819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.000</td>\n",
       "      <td>None</td>\n",
       "      <td>0.274304</td>\n",
       "      <td>0.213649</td>\n",
       "      <td>0.113164</td>\n",
       "      <td>0.095579</td>\n",
       "      <td>0.848939</td>\n",
       "      <td>0.767241</td>\n",
       "      <td>0.060622</td>\n",
       "      <td>0.050964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.269406</td>\n",
       "      <td>0.211321</td>\n",
       "      <td>0.048522</td>\n",
       "      <td>0.045793</td>\n",
       "      <td>0.985866</td>\n",
       "      <td>0.924812</td>\n",
       "      <td>0.024873</td>\n",
       "      <td>0.023478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>None</td>\n",
       "      <td>0.269414</td>\n",
       "      <td>0.211064</td>\n",
       "      <td>0.100303</td>\n",
       "      <td>0.085683</td>\n",
       "      <td>0.893553</td>\n",
       "      <td>0.808874</td>\n",
       "      <td>0.053134</td>\n",
       "      <td>0.045238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100.000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.246350</td>\n",
       "      <td>0.206086</td>\n",
       "      <td>0.082058</td>\n",
       "      <td>0.077908</td>\n",
       "      <td>0.995851</td>\n",
       "      <td>0.930131</td>\n",
       "      <td>0.042792</td>\n",
       "      <td>0.040657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.264434</td>\n",
       "      <td>0.202929</td>\n",
       "      <td>0.025334</td>\n",
       "      <td>0.023724</td>\n",
       "      <td>0.953642</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.012838</td>\n",
       "      <td>0.012025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.100</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.264166</td>\n",
       "      <td>0.202644</td>\n",
       "      <td>0.026202</td>\n",
       "      <td>0.024468</td>\n",
       "      <td>0.955128</td>\n",
       "      <td>0.878378</td>\n",
       "      <td>0.013283</td>\n",
       "      <td>0.012407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0.261936</td>\n",
       "      <td>0.200536</td>\n",
       "      <td>0.021158</td>\n",
       "      <td>0.019253</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.010698</td>\n",
       "      <td>0.009735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          C Class_weight  auprc_train  auprc_valid  f1_score_train  \\\n",
       "6     1.000         None     0.276136     0.215693        0.113478   \n",
       "4     0.100         None     0.276208     0.215692        0.112850   \n",
       "2     0.010         None     0.275458     0.215010        0.111028   \n",
       "8    10.000         None     0.274304     0.213649        0.113164   \n",
       "9    10.000     balanced     0.269406     0.211321        0.048522   \n",
       "0     0.001         None     0.269414     0.211064        0.100303   \n",
       "11  100.000     balanced     0.246350     0.206086        0.082058   \n",
       "7     1.000     balanced     0.264434     0.202929        0.025334   \n",
       "5     0.100     balanced     0.264166     0.202644        0.026202   \n",
       "3     0.010     balanced     0.261936     0.200536        0.021158   \n",
       "\n",
       "    f1_score_valid  precision_train  precision_valid  recall_train  \\\n",
       "6         0.095920         0.849315         0.767908      0.060801   \n",
       "4         0.095238         0.848561         0.766571      0.060444   \n",
       "2         0.093599         0.853846         0.772189      0.059374   \n",
       "8         0.095579         0.848939         0.767241      0.060622   \n",
       "9         0.045793         0.985866         0.924812      0.024873   \n",
       "0         0.085683         0.893553         0.808874      0.053134   \n",
       "11        0.077908         0.995851         0.930131      0.042792   \n",
       "7         0.023724         0.953642         0.875000      0.012838   \n",
       "5         0.024468         0.955128         0.878378      0.013283   \n",
       "3         0.019253         0.952381         0.864407      0.010698   \n",
       "\n",
       "    recall_valid  \n",
       "6       0.051155  \n",
       "4       0.050773  \n",
       "2       0.049819  \n",
       "8       0.050964  \n",
       "9       0.023478  \n",
       "0       0.045238  \n",
       "11      0.040657  \n",
       "7       0.012025  \n",
       "5       0.012407  \n",
       "3       0.009735  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_results_i_df = pd.DataFrame(linear_results_i).sort_values(by='auprc_valid', ascending=False)\n",
    "linear_results_i_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\glaurent\\AppData\\Local\\Continuum\\anaconda3\\envs\\exts-ml\\lib\\site-packages\\sklearn\\svm\\_base.py:986: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under PR Curve: 0.217\n"
     ]
    }
   ],
   "source": [
    "svc_final_i = CalibratedClassifierCV(LinearSVC(C=10 , class_weight=None))\n",
    "# fit\n",
    "svc_final_i.fit(X_tr_arr, y_tr_arr_imp_delay_binary)\n",
    "# predict\n",
    "y_pred_svc_final_i = svc_final_i.predict(X_va_arr_reindex)\n",
    "# predict probabilities\n",
    "svc_final_probs_i = svc_final_i.predict_proba(X_va_arr_reindex)\n",
    "# keep probabilities for the positive outcome only\n",
    "svc_final_probs_pos_i = svc_final_probs_i[:,1]\n",
    "# Precision-recall curve metrics\n",
    "svc_precision_final_i, svc_recall_final_i, svc_thres_final_i = precision_recall_curve(y_va_arr_imp_delay_binary, svc_final_probs_pos_i, pos_label=1)\n",
    "svc_final_auprc_i = auc(svc_recall_final_i, svc_precision_final_i)\n",
    "print('Area Under PR Curve: {:.3f}'.format(svc_final_auprc_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best threshold (Linear SVM - Important delay) <a name='svm_imp_delay_thres' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.117\n",
      "Probabilities: [0.10463581 0.09249484 0.19290287 0.17204313 0.18062454 0.07309018\n",
      " 0.15289864 0.16557212 0.10502478 0.10492923]\n",
      "Predictions: [0 0 1 1 1 0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from numpy import argmax\n",
    "fscores_svc_i = (2 * svc_precision_final_i * svc_recall_final_i) / (svc_precision_final_i + svc_recall_final_i)\n",
    "svc_bt_i = svc_thres_final_i[argmax(fscores_svc_i)]\n",
    "print('Best Threshold: {:.3f}'.format(svc_bt_i))\n",
    "# use threshold in model\n",
    "svc_final_curve_i = np.where(svc_final_probs_i[:,1] > svc_bt_i, 1,0)\n",
    "print('Probabilities:',svc_final_probs_i[0:10,1])\n",
    "print('Predictions:',svc_final_curve_i[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification report (Linear SVM - Important delay) <a name='svm_imp_delay_report' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: SVC Linear important delay - optimzed threshold at 0.117 on PR curve\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       no_delay       0.97      0.93      0.95    103481\n",
      "important_delay       0.20      0.36      0.26      5239\n",
      "\n",
      "       accuracy                           0.90    108720\n",
      "      macro avg       0.58      0.64      0.60    108720\n",
      "   weighted avg       0.93      0.90      0.91    108720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: SVC Linear important delay - optimzed threshold at {:.3f} on PR curve'.format(svc_bt_i))\n",
    "report_svc_preds_final_pr_i = classification_report(y_true=y_va_arr_imp_delay_binary, y_pred=svc_final_curve_i, target_names=['no_delay','important_delay'])\n",
    "#f1_logreg_pr_d = classification_report(y_true=y_va_arr_delay_binary, y_pred=lr_curve_d, target_names=['no_delay','delay'], output_dict=True)['delay']['f1-score']\n",
    "print(report_svc_preds_final_pr_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments SVC Linear:**\n",
    "* Linear SVC seems to be working weel and achieves good performance on the metrics with f1 scores of 0.56 and 0.26 which is equal or better than tuned LogisiticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance on test set (SVC Linear) <a name='svm_test' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under PR Curve: 0.652\n",
      "Probabilities: [0.2329558  0.21055468 0.29083123 0.26459183 0.79053612 0.18808951\n",
      " 0.67454621 0.80348959 0.37042526 0.26811565]\n",
      "Predictions: [0 0 1 0 1 0 1 1 1 0]\n",
      "Classification report: SVC delay TEST - optimzed threshold at 0.284 on PR curve\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    no_delay       0.89      0.80      0.85     80088\n",
      "       delay       0.56      0.72      0.63     27278\n",
      "\n",
      "    accuracy                           0.78    107366\n",
      "   macro avg       0.73      0.76      0.74    107366\n",
      "weighted avg       0.81      0.78      0.79    107366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# delay\n",
    "svc_test_probs_pos_d = svc_final_d.predict_proba(X_te_arr_reindex)[:,1]\n",
    "svc_precision_test_d, svc_recall_test_d, _ = precision_recall_curve(y_te_arr_delay_binary, svc_test_probs_pos_d, pos_label=1)\n",
    "svc_test_auc_pr_d = auc(svc_recall_test_d, svc_precision_test_d)\n",
    "print('Area Under PR Curve: {:.3f}'.format(svc_test_auc_pr_d))\n",
    "# use threshold in model\n",
    "svc_test_d = np.where(svc_final_d.predict_proba(X_te_arr_reindex)[:,1] > svc_bt_d, 1,0)\n",
    "print('Probabilities:',svc_final_d.predict_proba(X_te_arr_reindex)[0:10,1])\n",
    "print('Predictions:',svc_test_d[0:10])\n",
    "print('Classification report: SVC delay TEST - optimzed threshold at {:.3f} on PR curve'.format(svc_bt_d))\n",
    "report_svc_test_d = classification_report(y_true=y_te_arr_delay_binary, y_pred=svc_test_d, target_names=['no_delay','delay'])\n",
    "f1_svc_test_d = classification_report(y_true=y_te_arr_delay_binary, y_pred=svc_test_d, target_names=['no_delay','delay'], output_dict=True)['delay']['f1-score']\n",
    "precision_svc_test_d = classification_report(y_true=y_te_arr_delay_binary, y_pred=svc_test_d, target_names=['no_delay','delay'], output_dict=True)['delay']['precision']\n",
    "recall_svc_test_d = classification_report(y_true=y_te_arr_delay_binary, y_pred=svc_test_d, target_names=['no_delay','delay'], output_dict=True)['delay']['recall']\n",
    "print(report_svc_test_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under PR Curve: 0.281\n",
      "Probabilities: [0.10463581 0.09249484 0.19290287 0.17204313 0.18062454 0.07309018\n",
      " 0.15289864 0.16557212 0.10502478 0.10492923]\n",
      "Predictions: [0 0 1 1 1 0 1 1 0 0]\n",
      "Classification report: SVC important delay TEST - optimzed threshold at 0.117 on PR curve\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       no_delay       0.96      0.93      0.94    100362\n",
      "important_delay       0.28      0.37      0.32      7004\n",
      "\n",
      "       accuracy                           0.90    107366\n",
      "      macro avg       0.62      0.65      0.63    107366\n",
      "   weighted avg       0.91      0.90      0.90    107366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# important delay\n",
    "svc_test_probs_pos_i = svc_final_i.predict_proba(X_te_arr_reindex)[:,1]\n",
    "svc_precision_test_i, svc_recall_test_i, _ = precision_recall_curve(y_te_arr_imp_delay_binary, svc_test_probs_pos_i, pos_label=1)\n",
    "svc_test_auc_pr_i = auc(svc_recall_test_i, svc_precision_test_i)\n",
    "print('Area Under PR Curve: {:.3f}'.format(svc_test_auc_pr_i))\n",
    "# use threshold in model\n",
    "svc_test_i = np.where(svc_final_i.predict_proba(X_te_arr_reindex)[:,1] > svc_bt_i, 1,0)\n",
    "print('Probabilities:',svc_final_i.predict_proba(X_te_arr_reindex)[0:10,1])\n",
    "print('Predictions:',svc_test_i[0:10])\n",
    "print('Classification report: SVC important delay TEST - optimzed threshold at {:.3f} on PR curve'.format(svc_bt_i))\n",
    "report_svc_test_i = classification_report(y_true=y_te_arr_imp_delay_binary, y_pred=svc_test_i, target_names=['no_delay','important_delay'])\n",
    "f1_svc_test_i = classification_report(y_true=y_te_arr_imp_delay_binary, y_pred=svc_test_i, target_names=['no_delay','important_delay'], output_dict=True)['important_delay']['f1-score']\n",
    "precision_svc_test_i = classification_report(y_true=y_te_arr_imp_delay_binary, y_pred=svc_test_i, target_names=['no_delay','important_delay'], output_dict=True)['important_delay']['precision']\n",
    "recall_svc_test_i = classification_report(y_true=y_te_arr_imp_delay_binary, y_pred=svc_test_i, target_names=['no_delay','important_delay'], output_dict=True)['important_delay']['recall']\n",
    "print(report_svc_test_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RBF kernel <a name='svm_rbf' />\n",
    "*<a href=#top>Back to top</a>*\n",
    "* **Note:** take tool long to run, decide to not use for this project and to use RandomForest instead as Non-linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## start_rbf = time.time()\n",
    "## svc = SVC(C=1,kernel='rbf', gamma=1)\n",
    "## svc.fit(X_tr_arr, y_tr_arr_delay_binary)\n",
    "## svc.score(X_va_arr_reindex, y_va_arr_delay_binary)\n",
    "## end_rbf = time.time()\n",
    "## print(end_rbf - start_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV) Trees <a name='trees' />\n",
    "*<a href=#top>Back to top</a>*\n",
    "* Decision Trees tuning class_weight and max_depth\n",
    "* RandomForest tuning class_weight, max_depth and n_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees <a name='dt' />\n",
    "*<a href=#top>Back to top</a>*\n",
    "#### Delay <a name='dt_delay' /> <a name='dt_delay_grid' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=DecisionTreeClassifier(max_depth=3, random_state=0),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'class_weight': [None, {0: 1, 1: 10}, 'balanced',\n",
       "                                          {0: 1, 1: 500}],\n",
       "                         'max_depth': [3, 5, 7, 9, 11]},\n",
       "             refit=False, return_train_score=True,\n",
       "             scoring=['precision', 'recall', 'average_precision', 'f1'])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without class_weight\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Create decision tree\n",
    "dt_d = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=0)\n",
    "\n",
    "balance = [None, {0:1,1:10}, 'balanced', {0:1,1:500}]\n",
    "trees = [3,5,7,9,11]\n",
    "param_grid = dict(class_weight=balance, max_depth=trees)\n",
    "#cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scoring = ['precision','recall','average_precision','f1']\n",
    "# define grid search\n",
    "grid_dt_d = GridSearchCV(estimator=dt_d, param_grid=param_grid, n_jobs=-1, cv=5, scoring=scoring, refit=False, return_train_score=True)\n",
    "# fit\n",
    "grid_dt_d.fit(X_tr_arr, y_tr_arr_delay_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_class_weight', 'param_max_depth', 'params', 'split0_test_precision', 'split1_test_precision', 'split2_test_precision', 'split3_test_precision', 'split4_test_precision', 'mean_test_precision', 'std_test_precision', 'rank_test_precision', 'split0_train_precision', 'split1_train_precision', 'split2_train_precision', 'split3_train_precision', 'split4_train_precision', 'mean_train_precision', 'std_train_precision', 'split0_test_recall', 'split1_test_recall', 'split2_test_recall', 'split3_test_recall', 'split4_test_recall', 'mean_test_recall', 'std_test_recall', 'rank_test_recall', 'split0_train_recall', 'split1_train_recall', 'split2_train_recall', 'split3_train_recall', 'split4_train_recall', 'mean_train_recall', 'std_train_recall', 'split0_test_average_precision', 'split1_test_average_precision', 'split2_test_average_precision', 'split3_test_average_precision', 'split4_test_average_precision', 'mean_test_average_precision', 'std_test_average_precision', 'rank_test_average_precision', 'split0_train_average_precision', 'split1_train_average_precision', 'split2_train_average_precision', 'split3_train_average_precision', 'split4_train_average_precision', 'mean_train_average_precision', 'std_train_average_precision', 'split0_test_f1', 'split1_test_f1', 'split2_test_f1', 'split3_test_f1', 'split4_test_f1', 'mean_test_f1', 'std_test_f1', 'rank_test_f1', 'split0_train_f1', 'split1_train_f1', 'split2_train_f1', 'split3_train_f1', 'split4_train_f1', 'mean_train_f1', 'std_train_f1'])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the results with \"cv_results\"\n",
    "grid_dt_d.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0887047 , 0.24667164, 0.28468362, 0.32058189, 0.35808122,\n",
       "       0.51467831, 0.5522439 , 0.55246277, 0.55371974, 0.55706241,\n",
       "       0.55361628, 0.55648236, 0.55647828, 0.56772067, 0.5730252 ,\n",
       "       0.51467831, 0.535788  , 0.54338845, 0.54773661, 0.55029902])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_dt_d.cv_results_['mean_test_f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_average_precision</th>\n",
       "      <th>mean_train_average_precision</th>\n",
       "      <th>std_test_average_precision</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>mean_train_f1</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_train_recall</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_train_precision</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.501945</td>\n",
       "      <td>0.616725</td>\n",
       "      <td>0.047844</td>\n",
       "      <td>0.358081</td>\n",
       "      <td>0.461179</td>\n",
       "      <td>0.274098</td>\n",
       "      <td>0.345883</td>\n",
       "      <td>0.541208</td>\n",
       "      <td>0.701455</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "      <td>23.493954</td>\n",
       "      <td>0.453613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.498925</td>\n",
       "      <td>0.616347</td>\n",
       "      <td>0.038370</td>\n",
       "      <td>0.573025</td>\n",
       "      <td>0.611402</td>\n",
       "      <td>0.874701</td>\n",
       "      <td>0.929136</td>\n",
       "      <td>0.426863</td>\n",
       "      <td>0.455667</td>\n",
       "      <td>11</td>\n",
       "      <td>balanced</td>\n",
       "      <td>21.588996</td>\n",
       "      <td>0.508606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.491560</td>\n",
       "      <td>0.581987</td>\n",
       "      <td>0.044461</td>\n",
       "      <td>0.320582</td>\n",
       "      <td>0.415596</td>\n",
       "      <td>0.234081</td>\n",
       "      <td>0.296227</td>\n",
       "      <td>0.545400</td>\n",
       "      <td>0.705958</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>23.202752</td>\n",
       "      <td>0.480320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.489679</td>\n",
       "      <td>0.584214</td>\n",
       "      <td>0.044733</td>\n",
       "      <td>0.567721</td>\n",
       "      <td>0.599644</td>\n",
       "      <td>0.891709</td>\n",
       "      <td>0.935600</td>\n",
       "      <td>0.417361</td>\n",
       "      <td>0.441302</td>\n",
       "      <td>9</td>\n",
       "      <td>balanced</td>\n",
       "      <td>20.848585</td>\n",
       "      <td>0.487936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.467765</td>\n",
       "      <td>0.541766</td>\n",
       "      <td>0.052229</td>\n",
       "      <td>0.556478</td>\n",
       "      <td>0.587256</td>\n",
       "      <td>0.903875</td>\n",
       "      <td>0.941048</td>\n",
       "      <td>0.402346</td>\n",
       "      <td>0.426812</td>\n",
       "      <td>7</td>\n",
       "      <td>balanced</td>\n",
       "      <td>19.949856</td>\n",
       "      <td>0.489433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.463551</td>\n",
       "      <td>0.549563</td>\n",
       "      <td>0.049463</td>\n",
       "      <td>0.284684</td>\n",
       "      <td>0.368222</td>\n",
       "      <td>0.201225</td>\n",
       "      <td>0.252670</td>\n",
       "      <td>0.545927</td>\n",
       "      <td>0.699550</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>23.219895</td>\n",
       "      <td>0.497844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.449107</td>\n",
       "      <td>0.505270</td>\n",
       "      <td>0.044975</td>\n",
       "      <td>0.246672</td>\n",
       "      <td>0.319744</td>\n",
       "      <td>0.173109</td>\n",
       "      <td>0.215954</td>\n",
       "      <td>0.509121</td>\n",
       "      <td>0.655044</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>21.757136</td>\n",
       "      <td>0.651752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.428274</td>\n",
       "      <td>0.495361</td>\n",
       "      <td>0.054824</td>\n",
       "      <td>0.556482</td>\n",
       "      <td>0.571096</td>\n",
       "      <td>0.937462</td>\n",
       "      <td>0.958218</td>\n",
       "      <td>0.396362</td>\n",
       "      <td>0.406859</td>\n",
       "      <td>5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>18.251687</td>\n",
       "      <td>0.498474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.418443</td>\n",
       "      <td>0.493400</td>\n",
       "      <td>0.036503</td>\n",
       "      <td>0.557062</td>\n",
       "      <td>0.562324</td>\n",
       "      <td>0.982952</td>\n",
       "      <td>0.996063</td>\n",
       "      <td>0.388867</td>\n",
       "      <td>0.391763</td>\n",
       "      <td>11</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "      <td>28.461951</td>\n",
       "      <td>0.519497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.417734</td>\n",
       "      <td>0.446944</td>\n",
       "      <td>0.039587</td>\n",
       "      <td>0.088705</td>\n",
       "      <td>0.138523</td>\n",
       "      <td>0.053324</td>\n",
       "      <td>0.081931</td>\n",
       "      <td>0.600196</td>\n",
       "      <td>0.796294</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>21.425175</td>\n",
       "      <td>0.802204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.399709</td>\n",
       "      <td>0.465151</td>\n",
       "      <td>0.039184</td>\n",
       "      <td>0.553720</td>\n",
       "      <td>0.556931</td>\n",
       "      <td>0.988078</td>\n",
       "      <td>0.997315</td>\n",
       "      <td>0.384878</td>\n",
       "      <td>0.386360</td>\n",
       "      <td>9</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "      <td>27.830964</td>\n",
       "      <td>0.490263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.399330</td>\n",
       "      <td>0.438379</td>\n",
       "      <td>0.019348</td>\n",
       "      <td>0.550299</td>\n",
       "      <td>0.550134</td>\n",
       "      <td>0.997437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.380195</td>\n",
       "      <td>0.379454</td>\n",
       "      <td>11</td>\n",
       "      <td>{0: 1, 1: 500}</td>\n",
       "      <td>25.353389</td>\n",
       "      <td>0.282579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.393887</td>\n",
       "      <td>0.441794</td>\n",
       "      <td>0.041075</td>\n",
       "      <td>0.553616</td>\n",
       "      <td>0.557738</td>\n",
       "      <td>0.974427</td>\n",
       "      <td>0.981670</td>\n",
       "      <td>0.387181</td>\n",
       "      <td>0.389582</td>\n",
       "      <td>3</td>\n",
       "      <td>balanced</td>\n",
       "      <td>15.291849</td>\n",
       "      <td>0.466013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.392887</td>\n",
       "      <td>0.418158</td>\n",
       "      <td>0.015675</td>\n",
       "      <td>0.547737</td>\n",
       "      <td>0.546791</td>\n",
       "      <td>0.998271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.377644</td>\n",
       "      <td>0.376285</td>\n",
       "      <td>9</td>\n",
       "      <td>{0: 1, 1: 500}</td>\n",
       "      <td>27.829173</td>\n",
       "      <td>0.494301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.382074</td>\n",
       "      <td>0.393269</td>\n",
       "      <td>0.022238</td>\n",
       "      <td>0.543388</td>\n",
       "      <td>0.542239</td>\n",
       "      <td>0.998596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.373493</td>\n",
       "      <td>0.372005</td>\n",
       "      <td>7</td>\n",
       "      <td>{0: 1, 1: 500}</td>\n",
       "      <td>23.995641</td>\n",
       "      <td>0.515838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.382018</td>\n",
       "      <td>0.381235</td>\n",
       "      <td>0.018983</td>\n",
       "      <td>0.535788</td>\n",
       "      <td>0.531807</td>\n",
       "      <td>0.998718</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.366408</td>\n",
       "      <td>0.362292</td>\n",
       "      <td>5</td>\n",
       "      <td>{0: 1, 1: 500}</td>\n",
       "      <td>20.278978</td>\n",
       "      <td>0.475152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.381020</td>\n",
       "      <td>0.437132</td>\n",
       "      <td>0.032252</td>\n",
       "      <td>0.552463</td>\n",
       "      <td>0.552972</td>\n",
       "      <td>0.998108</td>\n",
       "      <td>0.998728</td>\n",
       "      <td>0.382200</td>\n",
       "      <td>0.382343</td>\n",
       "      <td>7</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "      <td>25.682498</td>\n",
       "      <td>0.558156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.379630</td>\n",
       "      <td>0.405137</td>\n",
       "      <td>0.021666</td>\n",
       "      <td>0.552244</td>\n",
       "      <td>0.551581</td>\n",
       "      <td>0.998718</td>\n",
       "      <td>0.998718</td>\n",
       "      <td>0.381893</td>\n",
       "      <td>0.381018</td>\n",
       "      <td>5</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "      <td>20.597832</td>\n",
       "      <td>0.528004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.346673</td>\n",
       "      <td>0.346097</td>\n",
       "      <td>0.014776</td>\n",
       "      <td>0.514678</td>\n",
       "      <td>0.514195</td>\n",
       "      <td>0.999837</td>\n",
       "      <td>0.999837</td>\n",
       "      <td>0.346690</td>\n",
       "      <td>0.346101</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "      <td>15.762505</td>\n",
       "      <td>0.513857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.346673</td>\n",
       "      <td>0.346097</td>\n",
       "      <td>0.014776</td>\n",
       "      <td>0.514678</td>\n",
       "      <td>0.514195</td>\n",
       "      <td>0.999837</td>\n",
       "      <td>0.999837</td>\n",
       "      <td>0.346690</td>\n",
       "      <td>0.346101</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 1, 1: 500}</td>\n",
       "      <td>14.952596</td>\n",
       "      <td>0.468155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_average_precision  mean_train_average_precision  \\\n",
       "4                      0.501945                      0.616725   \n",
       "14                     0.498925                      0.616347   \n",
       "3                      0.491560                      0.581987   \n",
       "13                     0.489679                      0.584214   \n",
       "12                     0.467765                      0.541766   \n",
       "2                      0.463551                      0.549563   \n",
       "1                      0.449107                      0.505270   \n",
       "11                     0.428274                      0.495361   \n",
       "9                      0.418443                      0.493400   \n",
       "0                      0.417734                      0.446944   \n",
       "8                      0.399709                      0.465151   \n",
       "19                     0.399330                      0.438379   \n",
       "10                     0.393887                      0.441794   \n",
       "18                     0.392887                      0.418158   \n",
       "17                     0.382074                      0.393269   \n",
       "16                     0.382018                      0.381235   \n",
       "7                      0.381020                      0.437132   \n",
       "6                      0.379630                      0.405137   \n",
       "5                      0.346673                      0.346097   \n",
       "15                     0.346673                      0.346097   \n",
       "\n",
       "    std_test_average_precision  mean_test_f1  mean_train_f1  mean_test_recall  \\\n",
       "4                     0.047844      0.358081       0.461179          0.274098   \n",
       "14                    0.038370      0.573025       0.611402          0.874701   \n",
       "3                     0.044461      0.320582       0.415596          0.234081   \n",
       "13                    0.044733      0.567721       0.599644          0.891709   \n",
       "12                    0.052229      0.556478       0.587256          0.903875   \n",
       "2                     0.049463      0.284684       0.368222          0.201225   \n",
       "1                     0.044975      0.246672       0.319744          0.173109   \n",
       "11                    0.054824      0.556482       0.571096          0.937462   \n",
       "9                     0.036503      0.557062       0.562324          0.982952   \n",
       "0                     0.039587      0.088705       0.138523          0.053324   \n",
       "8                     0.039184      0.553720       0.556931          0.988078   \n",
       "19                    0.019348      0.550299       0.550134          0.997437   \n",
       "10                    0.041075      0.553616       0.557738          0.974427   \n",
       "18                    0.015675      0.547737       0.546791          0.998271   \n",
       "17                    0.022238      0.543388       0.542239          0.998596   \n",
       "16                    0.018983      0.535788       0.531807          0.998718   \n",
       "7                     0.032252      0.552463       0.552972          0.998108   \n",
       "6                     0.021666      0.552244       0.551581          0.998718   \n",
       "5                     0.014776      0.514678       0.514195          0.999837   \n",
       "15                    0.014776      0.514678       0.514195          0.999837   \n",
       "\n",
       "    mean_train_recall  mean_test_precision  mean_train_precision  \\\n",
       "4            0.345883             0.541208              0.701455   \n",
       "14           0.929136             0.426863              0.455667   \n",
       "3            0.296227             0.545400              0.705958   \n",
       "13           0.935600             0.417361              0.441302   \n",
       "12           0.941048             0.402346              0.426812   \n",
       "2            0.252670             0.545927              0.699550   \n",
       "1            0.215954             0.509121              0.655044   \n",
       "11           0.958218             0.396362              0.406859   \n",
       "9            0.996063             0.388867              0.391763   \n",
       "0            0.081931             0.600196              0.796294   \n",
       "8            0.997315             0.384878              0.386360   \n",
       "19           1.000000             0.380195              0.379454   \n",
       "10           0.981670             0.387181              0.389582   \n",
       "18           1.000000             0.377644              0.376285   \n",
       "17           1.000000             0.373493              0.372005   \n",
       "16           1.000000             0.366408              0.362292   \n",
       "7            0.998728             0.382200              0.382343   \n",
       "6            0.998718             0.381893              0.381018   \n",
       "5            0.999837             0.346690              0.346101   \n",
       "15           0.999837             0.346690              0.346101   \n",
       "\n",
       "   param_max_depth param_class_weight  mean_fit_time  mean_score_time  \n",
       "4               11               None      23.493954         0.453613  \n",
       "14              11           balanced      21.588996         0.508606  \n",
       "3                9               None      23.202752         0.480320  \n",
       "13               9           balanced      20.848585         0.487936  \n",
       "12               7           balanced      19.949856         0.489433  \n",
       "2                7               None      23.219895         0.497844  \n",
       "1                5               None      21.757136         0.651752  \n",
       "11               5           balanced      18.251687         0.498474  \n",
       "9               11      {0: 1, 1: 10}      28.461951         0.519497  \n",
       "0                3               None      21.425175         0.802204  \n",
       "8                9      {0: 1, 1: 10}      27.830964         0.490263  \n",
       "19              11     {0: 1, 1: 500}      25.353389         0.282579  \n",
       "10               3           balanced      15.291849         0.466013  \n",
       "18               9     {0: 1, 1: 500}      27.829173         0.494301  \n",
       "17               7     {0: 1, 1: 500}      23.995641         0.515838  \n",
       "16               5     {0: 1, 1: 500}      20.278978         0.475152  \n",
       "7                7      {0: 1, 1: 10}      25.682498         0.558156  \n",
       "6                5      {0: 1, 1: 10}      20.597832         0.528004  \n",
       "5                3      {0: 1, 1: 10}      15.762505         0.513857  \n",
       "15               3     {0: 1, 1: 500}      14.952596         0.468155  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['mean_test_average_precision','mean_train_average_precision','std_test_average_precision',\\\n",
    "        'mean_test_f1','mean_train_f1',\\\n",
    "        'mean_test_recall','mean_train_recall','mean_test_precision','mean_train_precision',\\\n",
    "        'param_max_depth','param_class_weight',\\\n",
    "        'mean_fit_time','mean_score_time']\n",
    "# Delay GridSearchCV\n",
    "grid_dt_df_d = pd.DataFrame(grid_dt_d.cv_results_)[cols].sort_values(by='mean_test_average_precision', ascending=False)\n",
    "grid_dt_df_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report (DecisionTree - Delay) <a name='dt_delay_report' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: DecisionTree delay\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    no_delay       0.96      0.65      0.77     86652\n",
      "       delay       0.39      0.88      0.54     22068\n",
      "\n",
      "    accuracy                           0.69    108720\n",
      "   macro avg       0.67      0.76      0.66    108720\n",
      "weighted avg       0.84      0.69      0.72    108720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# take (14) from above because f1 score much better and recall as well\n",
    "dt_final_d = DecisionTreeClassifier(criterion='gini', max_depth=11, random_state=0, class_weight='balanced')\n",
    "dt_final_d.fit(X_tr_arr, y_tr_arr_delay_binary)\n",
    "y_pred_dt_va_final_d = dt_final_d.predict(X_va_arr_reindex) # prediction delay\n",
    "print('Classification report: DecisionTree delay')\n",
    "report_dt_final_d = classification_report(y_true=y_va_arr_delay_binary, y_pred=y_pred_dt_va_final_d, target_names=['no_delay','delay'])\n",
    "print(report_dt_final_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Decision Tree of depth 3 (DecisionTree - Delay) <a name='dt_delay_viz' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"1698pt\" height=\"520pt\"\r\n",
       " viewBox=\"0.00 0.00 1698.00 520.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 516)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-516 1694,-516 1694,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<path fill=\"#ffffff\" stroke=\"black\" d=\"M875.5,-512C875.5,-512 708.5,-512 708.5,-512 702.5,-512 696.5,-506 696.5,-500 696.5,-500 696.5,-441 696.5,-441 696.5,-435 702.5,-429 708.5,-429 708.5,-429 875.5,-429 875.5,-429 881.5,-429 887.5,-435 887.5,-441 887.5,-441 887.5,-500 887.5,-500 887.5,-506 881.5,-512 875.5,-512\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"792\" y=\"-496.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">operator_short_SBB &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"792\" y=\"-481.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"792\" y=\"-466.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100.0%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"792\" y=\"-451.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.5, 0.5]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"792\" y=\"-436.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = delay</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<path fill=\"#f1bc96\" stroke=\"black\" d=\"M688.5,-393C688.5,-393 549.5,-393 549.5,-393 543.5,-393 537.5,-387 537.5,-381 537.5,-381 537.5,-322 537.5,-322 537.5,-316 543.5,-310 549.5,-310 549.5,-310 688.5,-310 688.5,-310 694.5,-310 700.5,-316 700.5,-322 700.5,-322 700.5,-381 700.5,-381 700.5,-387 694.5,-393 688.5,-393\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"619\" y=\"-377.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">longitude_ch &lt;= &#45;0.277</text>\r\n",
       "<text text-anchor=\"middle\" x=\"619\" y=\"-362.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.435</text>\r\n",
       "<text text-anchor=\"middle\" x=\"619\" y=\"-347.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 60.9%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"619\" y=\"-332.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.68, 0.32]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"619\" y=\"-317.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = no_delay</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M731.979,-428.907C717.62,-419.197 702.185,-408.758 687.477,-398.811\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"689.16,-395.724 678.915,-393.021 685.238,-401.522 689.16,-395.724\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"683.655\" y=\"-413.867\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 902 -->\r\n",
       "<g id=\"node17\" class=\"node\"><title>902</title>\r\n",
       "<path fill=\"#93caf1\" stroke=\"black\" d=\"M1031,-393C1031,-393 901,-393 901,-393 895,-393 889,-387 889,-381 889,-381 889,-322 889,-322 889,-316 895,-310 901,-310 901,-310 1031,-310 1031,-310 1037,-310 1043,-316 1043,-322 1043,-322 1043,-381 1043,-381 1043,-387 1037,-393 1031,-393\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"966\" y=\"-377.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">product_id_S &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"966\" y=\"-362.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.43</text>\r\n",
       "<text text-anchor=\"middle\" x=\"966\" y=\"-347.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 39.1%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"966\" y=\"-332.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.313, 0.687]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"966\" y=\"-317.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = delay</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;902 -->\r\n",
       "<g id=\"edge16\" class=\"edge\"><title>0&#45;&gt;902</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M852.368,-428.907C866.809,-419.197 882.334,-408.758 897.127,-398.811\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"899.393,-401.505 905.738,-393.021 895.487,-395.696 899.393,-401.505\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"900.933\" y=\"-413.855\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<path fill=\"#a3d1f3\" stroke=\"black\" d=\"M333,-274C333,-274 165,-274 165,-274 159,-274 153,-268 153,-262 153,-262 153,-203 153,-203 153,-197 159,-191 165,-191 165,-191 333,-191 333,-191 339,-191 345,-197 345,-203 345,-203 345,-262 345,-262 345,-268 339,-274 333,-274\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"249\" y=\"-258.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">provider_short_MBC &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"249\" y=\"-243.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.454</text>\r\n",
       "<text text-anchor=\"middle\" x=\"249\" y=\"-228.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 19.2%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"249\" y=\"-213.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.349, 0.651]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"249\" y=\"-198.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = delay</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M537.344,-324.679C483.62,-307.691 412.775,-285.288 354.754,-266.941\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"355.778,-263.594 345.188,-263.916 353.668,-270.269 355.778,-263.594\"/>\r\n",
       "</g>\r\n",
       "<!-- 605 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>605</title>\r\n",
       "<path fill=\"#e68743\" stroke=\"black\" d=\"M684,-274C684,-274 554,-274 554,-274 548,-274 542,-268 542,-262 542,-262 542,-203 542,-203 542,-197 548,-191 554,-191 554,-191 684,-191 684,-191 690,-191 696,-197 696,-203 696,-203 696,-262 696,-262 696,-268 690,-274 684,-274\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"619\" y=\"-258.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">latitude_ch &lt;= 1.662</text>\r\n",
       "<text text-anchor=\"middle\" x=\"619\" y=\"-243.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.091</text>\r\n",
       "<text text-anchor=\"middle\" x=\"619\" y=\"-228.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 41.7%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"619\" y=\"-213.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.952, 0.048]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"619\" y=\"-198.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = no_delay</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;605 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>1&#45;&gt;605</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M619,-309.907C619,-301.649 619,-292.864 619,-284.302\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"622.5,-284.021 619,-274.021 615.5,-284.021 622.5,-284.021\"/>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<path fill=\"#bcdef6\" stroke=\"black\" d=\"M142,-155C142,-155 12,-155 12,-155 6,-155 0,-149 0,-143 0,-143 0,-84 0,-84 0,-78 6,-72 12,-72 12,-72 142,-72 142,-72 148,-72 154,-78 154,-84 154,-84 154,-143 154,-143 154,-149 148,-155 142,-155\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"77\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">latitude_ch &lt;= &#45;0.688</text>\r\n",
       "<text text-anchor=\"middle\" x=\"77\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.479</text>\r\n",
       "<text text-anchor=\"middle\" x=\"77\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 12.8%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"77\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.398, 0.602]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"77\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = delay</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M189.325,-190.907C175.05,-181.197 159.704,-170.758 145.082,-160.811\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"146.806,-157.751 136.569,-155.021 142.869,-163.539 146.806,-157.751\"/>\r\n",
       "</g>\r\n",
       "<!-- 284 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>284</title>\r\n",
       "<path fill=\"#80c0ee\" stroke=\"black\" d=\"M314,-155C314,-155 184,-155 184,-155 178,-155 172,-149 172,-143 172,-143 172,-84 172,-84 172,-78 178,-72 184,-72 184,-72 314,-72 314,-72 320,-72 326,-78 326,-84 326,-84 326,-143 326,-143 326,-149 320,-155 314,-155\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"249\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">altitude &lt;= 0.13</text>\r\n",
       "<text text-anchor=\"middle\" x=\"249\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.39</text>\r\n",
       "<text text-anchor=\"middle\" x=\"249\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 6.3%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"249\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.265, 0.735]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"249\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = delay</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;284 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>2&#45;&gt;284</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M249,-190.907C249,-182.649 249,-173.864 249,-165.302\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"252.5,-165.021 249,-155.021 245.5,-165.021 252.5,-165.021\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M70,-36C70,-36 40,-36 40,-36 34,-36 28,-30 28,-24 28,-24 28,-12 28,-12 28,-6 34,-0 40,-0 40,-0 70,-0 70,-0 76,-0 82,-6 82,-12 82,-12 82,-24 82,-24 82,-30 76,-36 70,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"55\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M67.4145,-71.7615C65.3856,-63.1387 63.2914,-54.2385 61.4143,-46.2606\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"64.7927,-45.3376 59.0953,-36.4051 57.9788,-46.9409 64.7927,-45.3376\"/>\r\n",
       "</g>\r\n",
       "<!-- 117 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>117</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M142,-36C142,-36 112,-36 112,-36 106,-36 100,-30 100,-24 100,-24 100,-12 100,-12 100,-6 106,-0 112,-0 112,-0 142,-0 142,-0 148,-0 154,-6 154,-12 154,-12 154,-24 154,-24 154,-30 148,-36 142,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"127\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;117 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>3&#45;&gt;117</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M98.7853,-71.7615C103.552,-62.8481 108.477,-53.6382 112.852,-45.4571\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"116.063,-46.8739 117.692,-36.4051 109.89,-43.5729 116.063,-46.8739\"/>\r\n",
       "</g>\r\n",
       "<!-- 285 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>285</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M215,-36C215,-36 185,-36 185,-36 179,-36 173,-30 173,-24 173,-24 173,-12 173,-12 173,-6 179,-0 185,-0 185,-0 215,-0 215,-0 221,-0 227,-6 227,-12 227,-12 227,-24 227,-24 227,-30 221,-36 215,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"200\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 284&#45;&gt;285 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>284&#45;&gt;285</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M227.65,-71.7615C222.979,-62.8481 218.153,-53.6382 213.865,-45.4571\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"216.863,-43.6378 209.121,-36.4051 210.663,-46.8872 216.863,-43.6378\"/>\r\n",
       "</g>\r\n",
       "<!-- 442 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>442</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M287,-36C287,-36 257,-36 257,-36 251,-36 245,-30 245,-24 245,-24 245,-12 245,-12 245,-6 251,-0 257,-0 257,-0 287,-0 287,-0 293,-0 299,-6 299,-12 299,-12 299,-24 299,-24 299,-30 293,-36 287,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"272\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 284&#45;&gt;442 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>284&#45;&gt;442</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M259.021,-71.7615C261.142,-63.1387 263.332,-54.2385 265.294,-46.2606\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"268.728,-46.9517 267.719,-36.4051 261.931,-45.2796 268.728,-46.9517\"/>\r\n",
       "</g>\r\n",
       "<!-- 606 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>606</title>\r\n",
       "<path fill=\"#e5813a\" stroke=\"black\" d=\"M522,-155C522,-155 356,-155 356,-155 350,-155 344,-149 344,-143 344,-143 344,-84 344,-84 344,-78 350,-72 356,-72 356,-72 522,-72 522,-72 528,-72 534,-78 534,-84 534,-84 534,-143 534,-143 534,-149 528,-155 522,-155\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"439\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">operator_short_TPF &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"439\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.007</text>\r\n",
       "<text text-anchor=\"middle\" x=\"439\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 40.3%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"439\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.997, 0.003]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"439\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = no_delay</text>\r\n",
       "</g>\r\n",
       "<!-- 605&#45;&gt;606 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>605&#45;&gt;606</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M556.55,-190.907C541.471,-181.106 525.251,-170.563 509.819,-160.533\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"511.632,-157.536 501.34,-155.021 507.817,-163.405 511.632,-157.536\"/>\r\n",
       "</g>\r\n",
       "<!-- 723 -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>723</title>\r\n",
       "<path fill=\"#8bc6f0\" stroke=\"black\" d=\"M798,-155C798,-155 564,-155 564,-155 558,-155 552,-149 552,-143 552,-143 552,-84 552,-84 552,-78 558,-72 564,-72 564,-72 798,-72 798,-72 804,-72 810,-78 810,-84 810,-84 810,-143 810,-143 810,-149 804,-155 798,-155\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"681\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">start_middle_end_middle_stop &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"681\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.415</text>\r\n",
       "<text text-anchor=\"middle\" x=\"681\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1.4%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"681\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.294, 0.706]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"681\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = delay</text>\r\n",
       "</g>\r\n",
       "<!-- 605&#45;&gt;723 -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>605&#45;&gt;723</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M640.511,-190.907C645.127,-182.195 650.055,-172.897 654.826,-163.893\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"657.938,-165.496 659.527,-155.021 651.752,-162.218 657.938,-165.496\"/>\r\n",
       "</g>\r\n",
       "<!-- 607 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>607</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M418,-36C418,-36 388,-36 388,-36 382,-36 376,-30 376,-24 376,-24 376,-12 376,-12 376,-6 382,-0 388,-0 388,-0 418,-0 418,-0 424,-0 430,-6 430,-12 430,-12 430,-24 430,-24 430,-30 424,-36 418,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"403\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 606&#45;&gt;607 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>606&#45;&gt;607</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M423.315,-71.7615C419.957,-63.0419 416.491,-54.0385 413.393,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"416.561,-44.4797 409.701,-36.4051 410.028,-46.9949 416.561,-44.4797\"/>\r\n",
       "</g>\r\n",
       "<!-- 676 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>676</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M490,-36C490,-36 460,-36 460,-36 454,-36 448,-30 448,-24 448,-24 448,-12 448,-12 448,-6 454,-0 460,-0 460,-0 490,-0 490,-0 496,-0 502,-6 502,-12 502,-12 502,-24 502,-24 502,-30 496,-36 490,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"475\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 606&#45;&gt;676 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>606&#45;&gt;676</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M454.685,-71.7615C458.043,-63.0419 461.509,-54.0385 464.607,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"467.972,-46.9949 468.299,-36.4051 461.439,-44.4797 467.972,-46.9949\"/>\r\n",
       "</g>\r\n",
       "<!-- 724 -->\r\n",
       "<g id=\"node15\" class=\"node\"><title>724</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M660,-36C660,-36 630,-36 630,-36 624,-36 618,-30 618,-24 618,-24 618,-12 618,-12 618,-6 624,-0 630,-0 630,-0 660,-0 660,-0 666,-0 672,-6 672,-12 672,-12 672,-24 672,-24 672,-30 666,-36 660,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"645\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 723&#45;&gt;724 -->\r\n",
       "<g id=\"edge14\" class=\"edge\"><title>723&#45;&gt;724</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M665.315,-71.7615C661.957,-63.0419 658.491,-54.0385 655.393,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"658.561,-44.4797 651.701,-36.4051 652.028,-46.9949 658.561,-44.4797\"/>\r\n",
       "</g>\r\n",
       "<!-- 779 -->\r\n",
       "<g id=\"node16\" class=\"node\"><title>779</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M732,-36C732,-36 702,-36 702,-36 696,-36 690,-30 690,-24 690,-24 690,-12 690,-12 690,-6 696,-0 702,-0 702,-0 732,-0 732,-0 738,-0 744,-6 744,-12 744,-12 744,-24 744,-24 744,-30 738,-36 732,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"717\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 723&#45;&gt;779 -->\r\n",
       "<g id=\"edge15\" class=\"edge\"><title>723&#45;&gt;779</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M696.685,-71.7615C700.043,-63.0419 703.509,-54.0385 706.607,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"709.972,-46.9949 710.299,-36.4051 703.439,-44.4797 709.972,-46.9949\"/>\r\n",
       "</g>\r\n",
       "<!-- 903 -->\r\n",
       "<g id=\"node18\" class=\"node\"><title>903</title>\r\n",
       "<path fill=\"#c2e1f7\" stroke=\"black\" d=\"M1088.5,-274C1088.5,-274 843.5,-274 843.5,-274 837.5,-274 831.5,-268 831.5,-262 831.5,-262 831.5,-203 831.5,-203 831.5,-197 837.5,-191 843.5,-191 843.5,-191 1088.5,-191 1088.5,-191 1094.5,-191 1100.5,-197 1100.5,-203 1100.5,-203 1100.5,-262 1100.5,-262 1100.5,-268 1094.5,-274 1088.5,-274\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"966\" y=\"-258.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">operating_day_of_week_Sunday &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"966\" y=\"-243.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.484</text>\r\n",
       "<text text-anchor=\"middle\" x=\"966\" y=\"-228.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 10.9%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"966\" y=\"-213.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.409, 0.591]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"966\" y=\"-198.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = delay</text>\r\n",
       "</g>\r\n",
       "<!-- 902&#45;&gt;903 -->\r\n",
       "<g id=\"edge17\" class=\"edge\"><title>902&#45;&gt;903</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M966,-309.907C966,-301.649 966,-292.864 966,-284.302\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"969.5,-284.021 966,-274.021 962.5,-284.021 969.5,-284.021\"/>\r\n",
       "</g>\r\n",
       "<!-- 1264 -->\r\n",
       "<g id=\"node25\" class=\"node\"><title>1264</title>\r\n",
       "<path fill=\"#87c3ef\" stroke=\"black\" d=\"M1463.5,-274C1463.5,-274 1314.5,-274 1314.5,-274 1308.5,-274 1302.5,-268 1302.5,-262 1302.5,-262 1302.5,-203 1302.5,-203 1302.5,-197 1308.5,-191 1314.5,-191 1314.5,-191 1463.5,-191 1463.5,-191 1469.5,-191 1475.5,-197 1475.5,-203 1475.5,-203 1475.5,-262 1475.5,-262 1475.5,-268 1469.5,-274 1463.5,-274\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1389\" y=\"-258.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">city_Renens (VD) &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1389\" y=\"-243.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.405</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1389\" y=\"-228.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 28.3%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1389\" y=\"-213.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.282, 0.718]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1389\" y=\"-198.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = delay</text>\r\n",
       "</g>\r\n",
       "<!-- 902&#45;&gt;1264 -->\r\n",
       "<g id=\"edge24\" class=\"edge\"><title>902&#45;&gt;1264</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1043.09,-329.176C1113.11,-309.811 1216.67,-281.165 1292.23,-260.267\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1293.53,-263.539 1302.23,-257.5 1291.66,-256.793 1293.53,-263.539\"/>\r\n",
       "</g>\r\n",
       "<!-- 904 -->\r\n",
       "<g id=\"node19\" class=\"node\"><title>904</title>\r\n",
       "<path fill=\"#b6dbf5\" stroke=\"black\" d=\"M970,-155C970,-155 840,-155 840,-155 834,-155 828,-149 828,-143 828,-143 828,-84 828,-84 828,-78 834,-72 840,-72 840,-72 970,-72 970,-72 976,-72 982,-78 982,-84 982,-84 982,-143 982,-143 982,-149 976,-155 970,-155\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"905\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">latitude_ch &lt;= 1.097</text>\r\n",
       "<text text-anchor=\"middle\" x=\"905\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.474</text>\r\n",
       "<text text-anchor=\"middle\" x=\"905\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 9.4%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"905\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.387, 0.613]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"905\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = delay</text>\r\n",
       "</g>\r\n",
       "<!-- 903&#45;&gt;904 -->\r\n",
       "<g id=\"edge18\" class=\"edge\"><title>903&#45;&gt;904</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M944.836,-190.907C940.294,-182.195 935.446,-172.897 930.752,-163.893\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"933.853,-162.27 926.126,-155.021 927.646,-165.506 933.853,-162.27\"/>\r\n",
       "</g>\r\n",
       "<!-- 1161 -->\r\n",
       "<g id=\"node22\" class=\"node\"><title>1161</title>\r\n",
       "<path fill=\"#f7d8c2\" stroke=\"black\" d=\"M1230,-155C1230,-155 1012,-155 1012,-155 1006,-155 1000,-149 1000,-143 1000,-143 1000,-84 1000,-84 1000,-78 1006,-72 1012,-72 1012,-72 1230,-72 1230,-72 1236,-72 1242,-78 1242,-84 1242,-84 1242,-143 1242,-143 1242,-149 1236,-155 1230,-155\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1121\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">arrival_time_of_day_evening &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1121\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.483</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1121\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1.4%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1121\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.591, 0.409]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1121\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = no_delay</text>\r\n",
       "</g>\r\n",
       "<!-- 903&#45;&gt;1161 -->\r\n",
       "<g id=\"edge21\" class=\"edge\"><title>903&#45;&gt;1161</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1019.78,-190.907C1032.52,-181.288 1046.21,-170.953 1059.28,-161.09\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1061.45,-163.839 1067.32,-155.021 1057.23,-158.252 1061.45,-163.839\"/>\r\n",
       "</g>\r\n",
       "<!-- 905 -->\r\n",
       "<g id=\"node20\" class=\"node\"><title>905</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M884,-36C884,-36 854,-36 854,-36 848,-36 842,-30 842,-24 842,-24 842,-12 842,-12 842,-6 848,-0 854,-0 854,-0 884,-0 884,-0 890,-0 896,-6 896,-12 896,-12 896,-24 896,-24 896,-30 890,-36 884,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"869\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 904&#45;&gt;905 -->\r\n",
       "<g id=\"edge19\" class=\"edge\"><title>904&#45;&gt;905</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M889.315,-71.7615C885.957,-63.0419 882.491,-54.0385 879.393,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"882.561,-44.4797 875.701,-36.4051 876.028,-46.9949 882.561,-44.4797\"/>\r\n",
       "</g>\r\n",
       "<!-- 1076 -->\r\n",
       "<g id=\"node21\" class=\"node\"><title>1076</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M956,-36C956,-36 926,-36 926,-36 920,-36 914,-30 914,-24 914,-24 914,-12 914,-12 914,-6 920,-0 926,-0 926,-0 956,-0 956,-0 962,-0 968,-6 968,-12 968,-12 968,-24 968,-24 968,-30 962,-36 956,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"941\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 904&#45;&gt;1076 -->\r\n",
       "<g id=\"edge20\" class=\"edge\"><title>904&#45;&gt;1076</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M920.685,-71.7615C924.043,-63.0419 927.509,-54.0385 930.607,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"933.972,-46.9949 934.299,-36.4051 927.439,-44.4797 933.972,-46.9949\"/>\r\n",
       "</g>\r\n",
       "<!-- 1162 -->\r\n",
       "<g id=\"node23\" class=\"node\"><title>1162</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M1100,-36C1100,-36 1070,-36 1070,-36 1064,-36 1058,-30 1058,-24 1058,-24 1058,-12 1058,-12 1058,-6 1064,-0 1070,-0 1070,-0 1100,-0 1100,-0 1106,-0 1112,-6 1112,-12 1112,-12 1112,-24 1112,-24 1112,-30 1106,-36 1100,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1085\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 1161&#45;&gt;1162 -->\r\n",
       "<g id=\"edge22\" class=\"edge\"><title>1161&#45;&gt;1162</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1105.31,-71.7615C1101.96,-63.0419 1098.49,-54.0385 1095.39,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1098.56,-44.4797 1091.7,-36.4051 1092.03,-46.9949 1098.56,-44.4797\"/>\r\n",
       "</g>\r\n",
       "<!-- 1237 -->\r\n",
       "<g id=\"node24\" class=\"node\"><title>1237</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M1172,-36C1172,-36 1142,-36 1142,-36 1136,-36 1130,-30 1130,-24 1130,-24 1130,-12 1130,-12 1130,-6 1136,-0 1142,-0 1142,-0 1172,-0 1172,-0 1178,-0 1184,-6 1184,-12 1184,-12 1184,-24 1184,-24 1184,-30 1178,-36 1172,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1157\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 1161&#45;&gt;1237 -->\r\n",
       "<g id=\"edge23\" class=\"edge\"><title>1161&#45;&gt;1237</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1136.69,-71.7615C1140.04,-63.0419 1143.51,-54.0385 1146.61,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1149.97,-46.9949 1150.3,-36.4051 1143.44,-44.4797 1149.97,-46.9949\"/>\r\n",
       "</g>\r\n",
       "<!-- 1265 -->\r\n",
       "<g id=\"node26\" class=\"node\"><title>1265</title>\r\n",
       "<path fill=\"#83c2ef\" stroke=\"black\" d=\"M1506,-155C1506,-155 1272,-155 1272,-155 1266,-155 1260,-149 1260,-143 1260,-143 1260,-84 1260,-84 1260,-78 1266,-72 1272,-72 1272,-72 1506,-72 1506,-72 1512,-72 1518,-78 1518,-84 1518,-84 1518,-143 1518,-143 1518,-149 1512,-155 1506,-155\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1389\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">start_middle_end_middle_stop &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1389\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.397</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1389\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 27.0%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1389\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.273, 0.727]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1389\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = delay</text>\r\n",
       "</g>\r\n",
       "<!-- 1264&#45;&gt;1265 -->\r\n",
       "<g id=\"edge25\" class=\"edge\"><title>1264&#45;&gt;1265</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1389,-190.907C1389,-182.649 1389,-173.864 1389,-165.302\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1392.5,-165.021 1389,-155.021 1385.5,-165.021 1392.5,-165.021\"/>\r\n",
       "</g>\r\n",
       "<!-- 1532 -->\r\n",
       "<g id=\"node29\" class=\"node\"><title>1532</title>\r\n",
       "<path fill=\"#fbeee4\" stroke=\"black\" d=\"M1678,-155C1678,-155 1548,-155 1548,-155 1542,-155 1536,-149 1536,-143 1536,-143 1536,-84 1536,-84 1536,-78 1542,-72 1548,-72 1548,-72 1678,-72 1678,-72 1684,-72 1690,-78 1690,-84 1690,-84 1690,-143 1690,-143 1690,-149 1684,-155 1678,-155\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1613\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">line_name_S &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1613\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.497</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1613\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1.3%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1613\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.536, 0.464]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1613\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = no_delay</text>\r\n",
       "</g>\r\n",
       "<!-- 1264&#45;&gt;1532 -->\r\n",
       "<g id=\"edge28\" class=\"edge\"><title>1264&#45;&gt;1532</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1466.72,-190.907C1486.11,-180.777 1507.02,-169.853 1526.8,-159.523\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1528.56,-162.555 1535.8,-154.823 1525.32,-156.35 1528.56,-162.555\"/>\r\n",
       "</g>\r\n",
       "<!-- 1266 -->\r\n",
       "<g id=\"node27\" class=\"node\"><title>1266</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M1368,-36C1368,-36 1338,-36 1338,-36 1332,-36 1326,-30 1326,-24 1326,-24 1326,-12 1326,-12 1326,-6 1332,-0 1338,-0 1338,-0 1368,-0 1368,-0 1374,-0 1380,-6 1380,-12 1380,-12 1380,-24 1380,-24 1380,-30 1374,-36 1368,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1353\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 1265&#45;&gt;1266 -->\r\n",
       "<g id=\"edge26\" class=\"edge\"><title>1265&#45;&gt;1266</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1373.31,-71.7615C1369.96,-63.0419 1366.49,-54.0385 1363.39,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1366.56,-44.4797 1359.7,-36.4051 1360.03,-46.9949 1366.56,-44.4797\"/>\r\n",
       "</g>\r\n",
       "<!-- 1401 -->\r\n",
       "<g id=\"node28\" class=\"node\"><title>1401</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M1440,-36C1440,-36 1410,-36 1410,-36 1404,-36 1398,-30 1398,-24 1398,-24 1398,-12 1398,-12 1398,-6 1404,-0 1410,-0 1410,-0 1440,-0 1440,-0 1446,-0 1452,-6 1452,-12 1452,-12 1452,-24 1452,-24 1452,-30 1446,-36 1440,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1425\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 1265&#45;&gt;1401 -->\r\n",
       "<g id=\"edge27\" class=\"edge\"><title>1265&#45;&gt;1401</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1404.69,-71.7615C1408.04,-63.0419 1411.51,-54.0385 1414.61,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1417.97,-46.9949 1418.3,-36.4051 1411.44,-44.4797 1417.97,-46.9949\"/>\r\n",
       "</g>\r\n",
       "<!-- 1533 -->\r\n",
       "<g id=\"node30\" class=\"node\"><title>1533</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M1592,-36C1592,-36 1562,-36 1562,-36 1556,-36 1550,-30 1550,-24 1550,-24 1550,-12 1550,-12 1550,-6 1556,-0 1562,-0 1562,-0 1592,-0 1592,-0 1598,-0 1604,-6 1604,-12 1604,-12 1604,-24 1604,-24 1604,-30 1598,-36 1592,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1577\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 1532&#45;&gt;1533 -->\r\n",
       "<g id=\"edge29\" class=\"edge\"><title>1532&#45;&gt;1533</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1597.31,-71.7615C1593.96,-63.0419 1590.49,-54.0385 1587.39,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1590.56,-44.4797 1583.7,-36.4051 1584.03,-46.9949 1590.56,-44.4797\"/>\r\n",
       "</g>\r\n",
       "<!-- 1652 -->\r\n",
       "<g id=\"node31\" class=\"node\"><title>1652</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M1664,-36C1664,-36 1634,-36 1634,-36 1628,-36 1622,-30 1622,-24 1622,-24 1622,-12 1622,-12 1622,-6 1628,-0 1634,-0 1634,-0 1664,-0 1664,-0 1670,-0 1676,-6 1676,-12 1676,-12 1676,-24 1676,-24 1676,-30 1670,-36 1664,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1649\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 1532&#45;&gt;1652 -->\r\n",
       "<g id=\"edge30\" class=\"edge\"><title>1532&#45;&gt;1652</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1628.69,-71.7615C1632.04,-63.0419 1635.51,-54.0385 1638.61,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1641.97,-46.9949 1642.3,-36.4051 1635.44,-44.4797 1641.97,-46.9949\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1f38f984ef0>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "# Export decision tree\n",
    "dot_data = export_graphviz(\n",
    "    dt_final_d, out_file=None,\n",
    "    max_depth=3,\n",
    "    feature_names=df_tr_arr_input_columns, \n",
    "    class_names=['no_delay','delay'],\n",
    "    filled=True, rounded=True, proportion=True)\n",
    "\n",
    "# Display decision tree\n",
    "graphviz.Source(dot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important delay (DecisionTree) <a name='dt_imp_delay' /> <a name='dt_imp_delay_grid' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=DecisionTreeClassifier(max_depth=3, random_state=0),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'class_weight': [None, {0: 1, 1: 10}, 'balanced',\n",
       "                                          {0: 1, 1: 500}],\n",
       "                         'max_depth': [3, 5, 7, 9, 11]},\n",
       "             refit=False, return_train_score=True,\n",
       "             scoring=['precision', 'recall', 'average_precision', 'f1'])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without class_weight\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# Create decision tree\n",
    "dt_i = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=0)\n",
    "\n",
    "balance = [None, {0:1,1:10}, 'balanced', {0:1,1:500}]\n",
    "trees = [3,5,7,9,11]\n",
    "param_grid = dict(class_weight=balance, max_depth=trees)\n",
    "#cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "scoring = ['precision','recall','average_precision','f1']\n",
    "# define grid search\n",
    "grid_dt_i = GridSearchCV(estimator=dt_i, param_grid=param_grid, n_jobs=-1, cv=5, scoring=scoring, refit=False, return_train_score=True)\n",
    "# fit\n",
    "grid_dt_i.fit(X_tr_arr, y_tr_arr_imp_delay_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_class_weight', 'param_max_depth', 'params', 'split0_test_precision', 'split1_test_precision', 'split2_test_precision', 'split3_test_precision', 'split4_test_precision', 'mean_test_precision', 'std_test_precision', 'rank_test_precision', 'split0_train_precision', 'split1_train_precision', 'split2_train_precision', 'split3_train_precision', 'split4_train_precision', 'mean_train_precision', 'std_train_precision', 'split0_test_recall', 'split1_test_recall', 'split2_test_recall', 'split3_test_recall', 'split4_test_recall', 'mean_test_recall', 'std_test_recall', 'rank_test_recall', 'split0_train_recall', 'split1_train_recall', 'split2_train_recall', 'split3_train_recall', 'split4_train_recall', 'mean_train_recall', 'std_train_recall', 'split0_test_average_precision', 'split1_test_average_precision', 'split2_test_average_precision', 'split3_test_average_precision', 'split4_test_average_precision', 'mean_test_average_precision', 'std_test_average_precision', 'rank_test_average_precision', 'split0_train_average_precision', 'split1_train_average_precision', 'split2_train_average_precision', 'split3_train_average_precision', 'split4_train_average_precision', 'mean_train_average_precision', 'std_train_average_precision', 'split0_test_f1', 'split1_test_f1', 'split2_test_f1', 'split3_test_f1', 'split4_test_f1', 'mean_test_f1', 'std_test_f1', 'rank_test_f1', 'split0_train_f1', 'split1_train_f1', 'split2_train_f1', 'split3_train_f1', 'split4_train_f1', 'mean_train_f1', 'std_train_f1'])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the results with \"cv_results\"\n",
    "grid_dt_i.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07108861, 0.10626231, 0.10555651, 0.10952679, 0.12957206,\n",
       "       0.17949642, 0.22992921, 0.19915481, 0.23232697, 0.2256163 ,\n",
       "       0.15426296, 0.17591529, 0.1762475 , 0.18412881, 0.19536847,\n",
       "       0.1466481 , 0.15357783, 0.15700178, 0.15750067, 0.15993078])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_dt_i.cv_results_['mean_test_f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_average_precision</th>\n",
       "      <th>mean_train_average_precision</th>\n",
       "      <th>std_test_average_precision</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>mean_train_f1</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_train_recall</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_train_precision</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.199899</td>\n",
       "      <td>0.383682</td>\n",
       "      <td>0.072548</td>\n",
       "      <td>0.129572</td>\n",
       "      <td>0.228174</td>\n",
       "      <td>0.079701</td>\n",
       "      <td>0.135307</td>\n",
       "      <td>0.405887</td>\n",
       "      <td>0.765003</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "      <td>28.074581</td>\n",
       "      <td>0.503927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.193977</td>\n",
       "      <td>0.307361</td>\n",
       "      <td>0.069905</td>\n",
       "      <td>0.184129</td>\n",
       "      <td>0.231847</td>\n",
       "      <td>0.795130</td>\n",
       "      <td>0.921369</td>\n",
       "      <td>0.104343</td>\n",
       "      <td>0.132617</td>\n",
       "      <td>9</td>\n",
       "      <td>balanced</td>\n",
       "      <td>22.258346</td>\n",
       "      <td>0.489962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.193955</td>\n",
       "      <td>0.335905</td>\n",
       "      <td>0.076232</td>\n",
       "      <td>0.109527</td>\n",
       "      <td>0.196422</td>\n",
       "      <td>0.063741</td>\n",
       "      <td>0.114334</td>\n",
       "      <td>0.439056</td>\n",
       "      <td>0.805041</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>26.597215</td>\n",
       "      <td>0.545439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.193319</td>\n",
       "      <td>0.324783</td>\n",
       "      <td>0.064883</td>\n",
       "      <td>0.232327</td>\n",
       "      <td>0.313080</td>\n",
       "      <td>0.519573</td>\n",
       "      <td>0.680729</td>\n",
       "      <td>0.151243</td>\n",
       "      <td>0.203549</td>\n",
       "      <td>9</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "      <td>22.807055</td>\n",
       "      <td>0.474027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.188240</td>\n",
       "      <td>0.261417</td>\n",
       "      <td>0.079509</td>\n",
       "      <td>0.176248</td>\n",
       "      <td>0.212782</td>\n",
       "      <td>0.854512</td>\n",
       "      <td>0.917401</td>\n",
       "      <td>0.098375</td>\n",
       "      <td>0.120538</td>\n",
       "      <td>7</td>\n",
       "      <td>balanced</td>\n",
       "      <td>20.910563</td>\n",
       "      <td>0.527060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.186410</td>\n",
       "      <td>0.345853</td>\n",
       "      <td>0.068069</td>\n",
       "      <td>0.195368</td>\n",
       "      <td>0.262491</td>\n",
       "      <td>0.680495</td>\n",
       "      <td>0.903740</td>\n",
       "      <td>0.114300</td>\n",
       "      <td>0.153689</td>\n",
       "      <td>11</td>\n",
       "      <td>balanced</td>\n",
       "      <td>22.707811</td>\n",
       "      <td>0.509347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.185805</td>\n",
       "      <td>0.271268</td>\n",
       "      <td>0.075777</td>\n",
       "      <td>0.199155</td>\n",
       "      <td>0.282361</td>\n",
       "      <td>0.523760</td>\n",
       "      <td>0.685993</td>\n",
       "      <td>0.126517</td>\n",
       "      <td>0.181377</td>\n",
       "      <td>7</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "      <td>22.893670</td>\n",
       "      <td>0.480742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.185518</td>\n",
       "      <td>0.366257</td>\n",
       "      <td>0.066810</td>\n",
       "      <td>0.225616</td>\n",
       "      <td>0.328961</td>\n",
       "      <td>0.522429</td>\n",
       "      <td>0.730832</td>\n",
       "      <td>0.145435</td>\n",
       "      <td>0.213339</td>\n",
       "      <td>11</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "      <td>23.061724</td>\n",
       "      <td>0.475922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.183939</td>\n",
       "      <td>0.279622</td>\n",
       "      <td>0.076683</td>\n",
       "      <td>0.105557</td>\n",
       "      <td>0.169163</td>\n",
       "      <td>0.059909</td>\n",
       "      <td>0.096527</td>\n",
       "      <td>0.530213</td>\n",
       "      <td>0.811791</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>24.938460</td>\n",
       "      <td>0.526406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.182806</td>\n",
       "      <td>0.223289</td>\n",
       "      <td>0.078234</td>\n",
       "      <td>0.106262</td>\n",
       "      <td>0.131155</td>\n",
       "      <td>0.059106</td>\n",
       "      <td>0.071543</td>\n",
       "      <td>0.637769</td>\n",
       "      <td>0.820056</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>22.169120</td>\n",
       "      <td>0.501666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.181778</td>\n",
       "      <td>0.215379</td>\n",
       "      <td>0.080279</td>\n",
       "      <td>0.229929</td>\n",
       "      <td>0.261807</td>\n",
       "      <td>0.482135</td>\n",
       "      <td>0.524070</td>\n",
       "      <td>0.156379</td>\n",
       "      <td>0.176308</td>\n",
       "      <td>5</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "      <td>18.968045</td>\n",
       "      <td>0.516067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.161944</td>\n",
       "      <td>0.203734</td>\n",
       "      <td>0.052978</td>\n",
       "      <td>0.175915</td>\n",
       "      <td>0.185457</td>\n",
       "      <td>0.912377</td>\n",
       "      <td>0.945060</td>\n",
       "      <td>0.097514</td>\n",
       "      <td>0.102885</td>\n",
       "      <td>5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>18.299803</td>\n",
       "      <td>0.522205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.140049</td>\n",
       "      <td>0.170666</td>\n",
       "      <td>0.046745</td>\n",
       "      <td>0.179496</td>\n",
       "      <td>0.236903</td>\n",
       "      <td>0.364522</td>\n",
       "      <td>0.447965</td>\n",
       "      <td>0.132663</td>\n",
       "      <td>0.176108</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 1, 1: 10}</td>\n",
       "      <td>15.153674</td>\n",
       "      <td>0.498516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.137216</td>\n",
       "      <td>0.158312</td>\n",
       "      <td>0.057620</td>\n",
       "      <td>0.071089</td>\n",
       "      <td>0.089748</td>\n",
       "      <td>0.038957</td>\n",
       "      <td>0.047116</td>\n",
       "      <td>0.748160</td>\n",
       "      <td>0.988682</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>19.519696</td>\n",
       "      <td>0.498948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.133905</td>\n",
       "      <td>0.152164</td>\n",
       "      <td>0.024726</td>\n",
       "      <td>0.159931</td>\n",
       "      <td>0.164086</td>\n",
       "      <td>0.968173</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.087192</td>\n",
       "      <td>0.089378</td>\n",
       "      <td>11</td>\n",
       "      <td>{0: 1, 1: 500}</td>\n",
       "      <td>24.700949</td>\n",
       "      <td>0.290865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.127697</td>\n",
       "      <td>0.165079</td>\n",
       "      <td>0.035642</td>\n",
       "      <td>0.154263</td>\n",
       "      <td>0.167881</td>\n",
       "      <td>0.946966</td>\n",
       "      <td>0.970357</td>\n",
       "      <td>0.083990</td>\n",
       "      <td>0.091905</td>\n",
       "      <td>3</td>\n",
       "      <td>balanced</td>\n",
       "      <td>14.758364</td>\n",
       "      <td>0.473955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.121931</td>\n",
       "      <td>0.139999</td>\n",
       "      <td>0.010470</td>\n",
       "      <td>0.157501</td>\n",
       "      <td>0.160087</td>\n",
       "      <td>0.975483</td>\n",
       "      <td>0.999978</td>\n",
       "      <td>0.085692</td>\n",
       "      <td>0.087009</td>\n",
       "      <td>9</td>\n",
       "      <td>{0: 1, 1: 500}</td>\n",
       "      <td>27.554982</td>\n",
       "      <td>0.530872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.099246</td>\n",
       "      <td>0.124388</td>\n",
       "      <td>0.014534</td>\n",
       "      <td>0.157002</td>\n",
       "      <td>0.156409</td>\n",
       "      <td>0.992956</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.085267</td>\n",
       "      <td>0.084841</td>\n",
       "      <td>7</td>\n",
       "      <td>{0: 1, 1: 500}</td>\n",
       "      <td>24.272562</td>\n",
       "      <td>0.504530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.091916</td>\n",
       "      <td>0.094215</td>\n",
       "      <td>0.012117</td>\n",
       "      <td>0.153578</td>\n",
       "      <td>0.152300</td>\n",
       "      <td>0.994383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083254</td>\n",
       "      <td>0.082430</td>\n",
       "      <td>5</td>\n",
       "      <td>{0: 1, 1: 500}</td>\n",
       "      <td>20.120695</td>\n",
       "      <td>0.474525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.079131</td>\n",
       "      <td>0.078937</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>0.146648</td>\n",
       "      <td>0.146323</td>\n",
       "      <td>0.999287</td>\n",
       "      <td>0.999287</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.078942</td>\n",
       "      <td>3</td>\n",
       "      <td>{0: 1, 1: 500}</td>\n",
       "      <td>14.802378</td>\n",
       "      <td>0.471957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_average_precision  mean_train_average_precision  \\\n",
       "4                      0.199899                      0.383682   \n",
       "13                     0.193977                      0.307361   \n",
       "3                      0.193955                      0.335905   \n",
       "8                      0.193319                      0.324783   \n",
       "12                     0.188240                      0.261417   \n",
       "14                     0.186410                      0.345853   \n",
       "7                      0.185805                      0.271268   \n",
       "9                      0.185518                      0.366257   \n",
       "2                      0.183939                      0.279622   \n",
       "1                      0.182806                      0.223289   \n",
       "6                      0.181778                      0.215379   \n",
       "11                     0.161944                      0.203734   \n",
       "5                      0.140049                      0.170666   \n",
       "0                      0.137216                      0.158312   \n",
       "19                     0.133905                      0.152164   \n",
       "10                     0.127697                      0.165079   \n",
       "18                     0.121931                      0.139999   \n",
       "17                     0.099246                      0.124388   \n",
       "16                     0.091916                      0.094215   \n",
       "15                     0.079131                      0.078937   \n",
       "\n",
       "    std_test_average_precision  mean_test_f1  mean_train_f1  mean_test_recall  \\\n",
       "4                     0.072548      0.129572       0.228174          0.079701   \n",
       "13                    0.069905      0.184129       0.231847          0.795130   \n",
       "3                     0.076232      0.109527       0.196422          0.063741   \n",
       "8                     0.064883      0.232327       0.313080          0.519573   \n",
       "12                    0.079509      0.176248       0.212782          0.854512   \n",
       "14                    0.068069      0.195368       0.262491          0.680495   \n",
       "7                     0.075777      0.199155       0.282361          0.523760   \n",
       "9                     0.066810      0.225616       0.328961          0.522429   \n",
       "2                     0.076683      0.105557       0.169163          0.059909   \n",
       "1                     0.078234      0.106262       0.131155          0.059106   \n",
       "6                     0.080279      0.229929       0.261807          0.482135   \n",
       "11                    0.052978      0.175915       0.185457          0.912377   \n",
       "5                     0.046745      0.179496       0.236903          0.364522   \n",
       "0                     0.057620      0.071089       0.089748          0.038957   \n",
       "19                    0.024726      0.159931       0.164086          0.968173   \n",
       "10                    0.035642      0.154263       0.167881          0.946966   \n",
       "18                    0.010470      0.157501       0.160087          0.975483   \n",
       "17                    0.014534      0.157002       0.156409          0.992956   \n",
       "16                    0.012117      0.153578       0.152300          0.994383   \n",
       "15                    0.004177      0.146648       0.146323          0.999287   \n",
       "\n",
       "    mean_train_recall  mean_test_precision  mean_train_precision  \\\n",
       "4            0.135307             0.405887              0.765003   \n",
       "13           0.921369             0.104343              0.132617   \n",
       "3            0.114334             0.439056              0.805041   \n",
       "8            0.680729             0.151243              0.203549   \n",
       "12           0.917401             0.098375              0.120538   \n",
       "14           0.903740             0.114300              0.153689   \n",
       "7            0.685993             0.126517              0.181377   \n",
       "9            0.730832             0.145435              0.213339   \n",
       "2            0.096527             0.530213              0.811791   \n",
       "1            0.071543             0.637769              0.820056   \n",
       "6            0.524070             0.156379              0.176308   \n",
       "11           0.945060             0.097514              0.102885   \n",
       "5            0.447965             0.132663              0.176108   \n",
       "0            0.047116             0.748160              0.988682   \n",
       "19           1.000000             0.087192              0.089378   \n",
       "10           0.970357             0.083990              0.091905   \n",
       "18           0.999978             0.085692              0.087009   \n",
       "17           1.000000             0.085267              0.084841   \n",
       "16           1.000000             0.083254              0.082430   \n",
       "15           0.999287             0.079146              0.078942   \n",
       "\n",
       "   param_max_depth param_class_weight  mean_fit_time  mean_score_time  \n",
       "4               11               None      28.074581         0.503927  \n",
       "13               9           balanced      22.258346         0.489962  \n",
       "3                9               None      26.597215         0.545439  \n",
       "8                9      {0: 1, 1: 10}      22.807055         0.474027  \n",
       "12               7           balanced      20.910563         0.527060  \n",
       "14              11           balanced      22.707811         0.509347  \n",
       "7                7      {0: 1, 1: 10}      22.893670         0.480742  \n",
       "9               11      {0: 1, 1: 10}      23.061724         0.475922  \n",
       "2                7               None      24.938460         0.526406  \n",
       "1                5               None      22.169120         0.501666  \n",
       "6                5      {0: 1, 1: 10}      18.968045         0.516067  \n",
       "11               5           balanced      18.299803         0.522205  \n",
       "5                3      {0: 1, 1: 10}      15.153674         0.498516  \n",
       "0                3               None      19.519696         0.498948  \n",
       "19              11     {0: 1, 1: 500}      24.700949         0.290865  \n",
       "10               3           balanced      14.758364         0.473955  \n",
       "18               9     {0: 1, 1: 500}      27.554982         0.530872  \n",
       "17               7     {0: 1, 1: 500}      24.272562         0.504530  \n",
       "16               5     {0: 1, 1: 500}      20.120695         0.474525  \n",
       "15               3     {0: 1, 1: 500}      14.802378         0.471957  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['mean_test_average_precision','mean_train_average_precision','std_test_average_precision',\\\n",
    "        'mean_test_f1','mean_train_f1',\\\n",
    "        'mean_test_recall','mean_train_recall','mean_test_precision','mean_train_precision',\\\n",
    "        'param_max_depth','param_class_weight',\\\n",
    "        'mean_fit_time','mean_score_time']\n",
    "# Delay GridSearchCV\n",
    "grid_dt_df_i = pd.DataFrame(grid_dt_i.cv_results_)[cols].sort_values(by='mean_test_average_precision', ascending=False)\n",
    "grid_dt_df_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report (DecisionTree - Importat delay) <a name='dt_imp_delay_report' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: DecisionTree important delay\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       no_delay       0.98      0.61      0.75    103481\n",
      "important_delay       0.10      0.81      0.17      5239\n",
      "\n",
      "       accuracy                           0.62    108720\n",
      "      macro avg       0.54      0.71      0.46    108720\n",
      "   weighted avg       0.94      0.62      0.73    108720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# going with (9) because high AP, high f1 and high recall\n",
    "dt_final_i = DecisionTreeClassifier(criterion='gini', max_depth=9, random_state=0, class_weight='balanced')\n",
    "dt_final_i.fit(X_tr_arr, y_tr_arr_imp_delay_binary)\n",
    "y_pred_dt_va_final_i = dt_final_i.predict(X_va_arr_reindex) # prediction delay\n",
    "print('Classification report: DecisionTree important delay')\n",
    "report_dt_final_i= classification_report(y_true=y_va_arr_imp_delay_binary, y_pred=y_pred_dt_va_final_i, target_names=['no_delay','important_delay'])\n",
    "print(report_dt_final_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize Decision Tree of depth 3 (DecisionTree - Important delay) <a name='dt_imp_delay_viz' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\r\n",
       " -->\r\n",
       "<!-- Title: Tree Pages: 1 -->\r\n",
       "<svg width=\"1868pt\" height=\"520pt\"\r\n",
       " viewBox=\"0.00 0.00 1867.50 520.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 516)\">\r\n",
       "<title>Tree</title>\r\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-516 1863.5,-516 1863.5,4 -4,4\"/>\r\n",
       "<!-- 0 -->\r\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\r\n",
       "<path fill=\"#ffffff\" stroke=\"black\" d=\"M1064,-512C1064,-512 897,-512 897,-512 891,-512 885,-506 885,-500 885,-500 885,-441 885,-441 885,-435 891,-429 897,-429 897,-429 1064,-429 1064,-429 1070,-429 1076,-435 1076,-441 1076,-441 1076,-500 1076,-500 1076,-506 1070,-512 1064,-512\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"980.5\" y=\"-496.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">operator_short_SBB &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"980.5\" y=\"-481.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"980.5\" y=\"-466.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 100.0%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"980.5\" y=\"-451.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.5, 0.5]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"980.5\" y=\"-436.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = no_delay</text>\r\n",
       "</g>\r\n",
       "<!-- 1 -->\r\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\r\n",
       "<path fill=\"#f2bf9a\" stroke=\"black\" d=\"M874,-393C874,-393 735,-393 735,-393 729,-393 723,-387 723,-381 723,-381 723,-322 723,-322 723,-316 729,-310 735,-310 735,-310 874,-310 874,-310 880,-310 886,-316 886,-322 886,-322 886,-381 886,-381 886,-387 880,-393 874,-393\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"804.5\" y=\"-377.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">longitude_ch &lt;= &#45;0.277</text>\r\n",
       "<text text-anchor=\"middle\" x=\"804.5\" y=\"-362.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.441</text>\r\n",
       "<text text-anchor=\"middle\" x=\"804.5\" y=\"-347.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 60.9%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"804.5\" y=\"-332.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.671, 0.329]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"804.5\" y=\"-317.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = no_delay</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;1 -->\r\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M919.438,-428.907C904.831,-419.197 889.128,-408.758 874.165,-398.811\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"875.72,-395.642 865.454,-393.021 871.845,-401.472 875.72,-395.642\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"870.389\" y=\"-413.829\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\r\n",
       "</g>\r\n",
       "<!-- 282 -->\r\n",
       "<g id=\"node17\" class=\"node\"><title>282</title>\r\n",
       "<path fill=\"#a4d2f3\" stroke=\"black\" d=\"M1285.5,-393C1285.5,-393 1027.5,-393 1027.5,-393 1021.5,-393 1015.5,-387 1015.5,-381 1015.5,-381 1015.5,-322 1015.5,-322 1015.5,-316 1021.5,-310 1027.5,-310 1027.5,-310 1285.5,-310 1285.5,-310 1291.5,-310 1297.5,-316 1297.5,-322 1297.5,-322 1297.5,-381 1297.5,-381 1297.5,-387 1291.5,-393 1285.5,-393\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1156.5\" y=\"-377.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">arrival_time_of_day_early_morning &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1156.5\" y=\"-362.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.455</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1156.5\" y=\"-347.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 39.1%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1156.5\" y=\"-332.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.351, 0.649]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1156.5\" y=\"-317.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = important_delay</text>\r\n",
       "</g>\r\n",
       "<!-- 0&#45;&gt;282 -->\r\n",
       "<g id=\"edge16\" class=\"edge\"><title>0&#45;&gt;282</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1041.56,-428.907C1056.17,-419.197 1071.87,-408.758 1086.84,-398.811\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1089.16,-401.472 1095.55,-393.021 1085.28,-395.642 1089.16,-401.472\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1090.61\" y=\"-413.829\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\r\n",
       "</g>\r\n",
       "<!-- 2 -->\r\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\r\n",
       "<path fill=\"#bbddf6\" stroke=\"black\" d=\"M528,-274C528,-274 307,-274 307,-274 301,-274 295,-268 295,-262 295,-262 295,-203 295,-203 295,-197 301,-191 307,-191 307,-191 528,-191 528,-191 534,-191 540,-197 540,-203 540,-203 540,-262 540,-262 540,-268 534,-274 528,-274\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"417.5\" y=\"-258.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">operator_short_TRAVYS&#45;pbr &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"417.5\" y=\"-243.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.478</text>\r\n",
       "<text text-anchor=\"middle\" x=\"417.5\" y=\"-228.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 19.2%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"417.5\" y=\"-213.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.396, 0.604]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"417.5\" y=\"-198.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = important_delay</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;2 -->\r\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M722.9,-325.83C672.798,-310.683 607.446,-290.925 550.058,-273.576\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"550.768,-270.134 540.183,-270.59 548.742,-276.834 550.768,-270.134\"/>\r\n",
       "</g>\r\n",
       "<!-- 161 -->\r\n",
       "<g id=\"node10\" class=\"node\"><title>161</title>\r\n",
       "<path fill=\"#e68743\" stroke=\"black\" d=\"M915.5,-274C915.5,-274 693.5,-274 693.5,-274 687.5,-274 681.5,-268 681.5,-262 681.5,-262 681.5,-203 681.5,-203 681.5,-197 687.5,-191 693.5,-191 693.5,-191 915.5,-191 915.5,-191 921.5,-191 927.5,-197 927.5,-203 927.5,-203 927.5,-262 927.5,-262 927.5,-268 921.5,-274 915.5,-274\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"804.5\" y=\"-258.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">operator_short_TRAVYS&#45;ysc &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"804.5\" y=\"-243.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.089</text>\r\n",
       "<text text-anchor=\"middle\" x=\"804.5\" y=\"-228.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 41.7%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"804.5\" y=\"-213.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.953, 0.047]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"804.5\" y=\"-198.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = no_delay</text>\r\n",
       "</g>\r\n",
       "<!-- 1&#45;&gt;161 -->\r\n",
       "<g id=\"edge9\" class=\"edge\"><title>1&#45;&gt;161</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M804.5,-309.907C804.5,-301.649 804.5,-292.864 804.5,-284.302\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"808,-284.021 804.5,-274.021 801,-284.021 808,-284.021\"/>\r\n",
       "</g>\r\n",
       "<!-- 3 -->\r\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\r\n",
       "<path fill=\"#ddeefb\" stroke=\"black\" d=\"M265,-155C265,-155 12,-155 12,-155 6,-155 0,-149 0,-143 0,-143 0,-84 0,-84 0,-78 6,-72 12,-72 12,-72 265,-72 265,-72 271,-72 277,-78 277,-84 277,-84 277,-143 277,-143 277,-149 271,-155 265,-155\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"138.5\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">operating_day_of_week_Saturday &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"138.5\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.496</text>\r\n",
       "<text text-anchor=\"middle\" x=\"138.5\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 16.2%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"138.5\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.454, 0.546]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"138.5\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = important_delay</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;3 -->\r\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M320.702,-190.907C296.14,-180.607 269.623,-169.487 244.626,-159.004\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"245.702,-155.66 235.127,-155.021 242.995,-162.116 245.702,-155.66\"/>\r\n",
       "</g>\r\n",
       "<!-- 100 -->\r\n",
       "<g id=\"node7\" class=\"node\"><title>100</title>\r\n",
       "<path fill=\"#73b9ed\" stroke=\"black\" d=\"M527.5,-155C527.5,-155 307.5,-155 307.5,-155 301.5,-155 295.5,-149 295.5,-143 295.5,-143 295.5,-84 295.5,-84 295.5,-78 301.5,-72 307.5,-72 307.5,-72 527.5,-72 527.5,-72 533.5,-72 539.5,-78 539.5,-84 539.5,-84 539.5,-143 539.5,-143 539.5,-149 533.5,-155 527.5,-155\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"417.5\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">arrival_time_of_day_morning &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"417.5\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.349</text>\r\n",
       "<text text-anchor=\"middle\" x=\"417.5\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 3.0%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"417.5\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.225, 0.775]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"417.5\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = important_delay</text>\r\n",
       "</g>\r\n",
       "<!-- 2&#45;&gt;100 -->\r\n",
       "<g id=\"edge6\" class=\"edge\"><title>2&#45;&gt;100</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M417.5,-190.907C417.5,-182.649 417.5,-173.864 417.5,-165.302\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"421,-165.021 417.5,-155.021 414,-165.021 421,-165.021\"/>\r\n",
       "</g>\r\n",
       "<!-- 4 -->\r\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M117.5,-36C117.5,-36 87.5,-36 87.5,-36 81.5,-36 75.5,-30 75.5,-24 75.5,-24 75.5,-12 75.5,-12 75.5,-6 81.5,-0 87.5,-0 87.5,-0 117.5,-0 117.5,-0 123.5,-0 129.5,-6 129.5,-12 129.5,-12 129.5,-24 129.5,-24 129.5,-30 123.5,-36 117.5,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"102.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;4 -->\r\n",
       "<g id=\"edge4\" class=\"edge\"><title>3&#45;&gt;4</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M122.815,-71.7615C119.457,-63.0419 115.991,-54.0385 112.893,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"116.061,-44.4797 109.201,-36.4051 109.528,-46.9949 116.061,-44.4797\"/>\r\n",
       "</g>\r\n",
       "<!-- 65 -->\r\n",
       "<g id=\"node6\" class=\"node\"><title>65</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M189.5,-36C189.5,-36 159.5,-36 159.5,-36 153.5,-36 147.5,-30 147.5,-24 147.5,-24 147.5,-12 147.5,-12 147.5,-6 153.5,-0 159.5,-0 159.5,-0 189.5,-0 189.5,-0 195.5,-0 201.5,-6 201.5,-12 201.5,-12 201.5,-24 201.5,-24 201.5,-30 195.5,-36 189.5,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"174.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 3&#45;&gt;65 -->\r\n",
       "<g id=\"edge5\" class=\"edge\"><title>3&#45;&gt;65</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M154.185,-71.7615C157.543,-63.0419 161.009,-54.0385 164.107,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"167.472,-46.9949 167.799,-36.4051 160.939,-44.4797 167.472,-46.9949\"/>\r\n",
       "</g>\r\n",
       "<!-- 101 -->\r\n",
       "<g id=\"node8\" class=\"node\"><title>101</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M396.5,-36C396.5,-36 366.5,-36 366.5,-36 360.5,-36 354.5,-30 354.5,-24 354.5,-24 354.5,-12 354.5,-12 354.5,-6 360.5,-0 366.5,-0 366.5,-0 396.5,-0 396.5,-0 402.5,-0 408.5,-6 408.5,-12 408.5,-12 408.5,-24 408.5,-24 408.5,-30 402.5,-36 396.5,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"381.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 100&#45;&gt;101 -->\r\n",
       "<g id=\"edge7\" class=\"edge\"><title>100&#45;&gt;101</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M401.815,-71.7615C398.457,-63.0419 394.991,-54.0385 391.893,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"395.061,-44.4797 388.201,-36.4051 388.528,-46.9949 395.061,-44.4797\"/>\r\n",
       "</g>\r\n",
       "<!-- 142 -->\r\n",
       "<g id=\"node9\" class=\"node\"><title>142</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M468.5,-36C468.5,-36 438.5,-36 438.5,-36 432.5,-36 426.5,-30 426.5,-24 426.5,-24 426.5,-12 426.5,-12 426.5,-6 432.5,-0 438.5,-0 438.5,-0 468.5,-0 468.5,-0 474.5,-0 480.5,-6 480.5,-12 480.5,-12 480.5,-24 480.5,-24 480.5,-30 474.5,-36 468.5,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"453.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 100&#45;&gt;142 -->\r\n",
       "<g id=\"edge8\" class=\"edge\"><title>100&#45;&gt;142</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M433.185,-71.7615C436.543,-63.0419 440.009,-54.0385 443.107,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"446.472,-46.9949 446.799,-36.4051 439.939,-44.4797 446.472,-46.9949\"/>\r\n",
       "</g>\r\n",
       "<!-- 162 -->\r\n",
       "<g id=\"node11\" class=\"node\"><title>162</title>\r\n",
       "<path fill=\"#e5833c\" stroke=\"black\" d=\"M699.5,-155C699.5,-155 569.5,-155 569.5,-155 563.5,-155 557.5,-149 557.5,-143 557.5,-143 557.5,-84 557.5,-84 557.5,-78 563.5,-72 569.5,-72 569.5,-72 699.5,-72 699.5,-72 705.5,-72 711.5,-78 711.5,-84 711.5,-84 711.5,-143 711.5,-143 711.5,-149 705.5,-155 699.5,-155\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"634.5\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">city_Montreux &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"634.5\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.03</text>\r\n",
       "<text text-anchor=\"middle\" x=\"634.5\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 40.5%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"634.5\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.985, 0.015]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"634.5\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = no_delay</text>\r\n",
       "</g>\r\n",
       "<!-- 161&#45;&gt;162 -->\r\n",
       "<g id=\"edge10\" class=\"edge\"><title>161&#45;&gt;162</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M745.519,-190.907C731.41,-181.197 716.243,-170.758 701.79,-160.811\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"703.598,-157.807 693.376,-155.021 699.63,-163.573 703.598,-157.807\"/>\r\n",
       "</g>\r\n",
       "<!-- 235 -->\r\n",
       "<g id=\"node14\" class=\"node\"><title>235</title>\r\n",
       "<path fill=\"#d5eaf9\" stroke=\"black\" d=\"M959.5,-155C959.5,-155 741.5,-155 741.5,-155 735.5,-155 729.5,-149 729.5,-143 729.5,-143 729.5,-84 729.5,-84 729.5,-78 735.5,-72 741.5,-72 741.5,-72 959.5,-72 959.5,-72 965.5,-72 971.5,-78 971.5,-84 971.5,-84 971.5,-143 971.5,-143 971.5,-149 965.5,-155 959.5,-155\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"850.5\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">arrival_time_of_day_evening &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"850.5\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.493</text>\r\n",
       "<text text-anchor=\"middle\" x=\"850.5\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 1.2%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"850.5\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.44, 0.56]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"850.5\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = important_delay</text>\r\n",
       "</g>\r\n",
       "<!-- 161&#45;&gt;235 -->\r\n",
       "<g id=\"edge13\" class=\"edge\"><title>161&#45;&gt;235</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M820.459,-190.907C823.813,-182.377 827.388,-173.284 830.859,-164.456\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"834.167,-165.608 834.569,-155.021 827.652,-163.047 834.167,-165.608\"/>\r\n",
       "</g>\r\n",
       "<!-- 163 -->\r\n",
       "<g id=\"node12\" class=\"node\"><title>163</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M613.5,-36C613.5,-36 583.5,-36 583.5,-36 577.5,-36 571.5,-30 571.5,-24 571.5,-24 571.5,-12 571.5,-12 571.5,-6 577.5,-0 583.5,-0 583.5,-0 613.5,-0 613.5,-0 619.5,-0 625.5,-6 625.5,-12 625.5,-12 625.5,-24 625.5,-24 625.5,-30 619.5,-36 613.5,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"598.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 162&#45;&gt;163 -->\r\n",
       "<g id=\"edge11\" class=\"edge\"><title>162&#45;&gt;163</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M618.815,-71.7615C615.457,-63.0419 611.991,-54.0385 608.893,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"612.061,-44.4797 605.201,-36.4051 605.528,-46.9949 612.061,-44.4797\"/>\r\n",
       "</g>\r\n",
       "<!-- 202 -->\r\n",
       "<g id=\"node13\" class=\"node\"><title>202</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M685.5,-36C685.5,-36 655.5,-36 655.5,-36 649.5,-36 643.5,-30 643.5,-24 643.5,-24 643.5,-12 643.5,-12 643.5,-6 649.5,-0 655.5,-0 655.5,-0 685.5,-0 685.5,-0 691.5,-0 697.5,-6 697.5,-12 697.5,-12 697.5,-24 697.5,-24 697.5,-30 691.5,-36 685.5,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"670.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 162&#45;&gt;202 -->\r\n",
       "<g id=\"edge12\" class=\"edge\"><title>162&#45;&gt;202</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M650.185,-71.7615C653.543,-63.0419 657.009,-54.0385 660.107,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"663.472,-46.9949 663.799,-36.4051 656.939,-44.4797 663.472,-46.9949\"/>\r\n",
       "</g>\r\n",
       "<!-- 236 -->\r\n",
       "<g id=\"node15\" class=\"node\"><title>236</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M829.5,-36C829.5,-36 799.5,-36 799.5,-36 793.5,-36 787.5,-30 787.5,-24 787.5,-24 787.5,-12 787.5,-12 787.5,-6 793.5,-0 799.5,-0 799.5,-0 829.5,-0 829.5,-0 835.5,-0 841.5,-6 841.5,-12 841.5,-12 841.5,-24 841.5,-24 841.5,-30 835.5,-36 829.5,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"814.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 235&#45;&gt;236 -->\r\n",
       "<g id=\"edge14\" class=\"edge\"><title>235&#45;&gt;236</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M834.815,-71.7615C831.457,-63.0419 827.991,-54.0385 824.893,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"828.061,-44.4797 821.201,-36.4051 821.528,-46.9949 828.061,-44.4797\"/>\r\n",
       "</g>\r\n",
       "<!-- 281 -->\r\n",
       "<g id=\"node16\" class=\"node\"><title>281</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M901.5,-36C901.5,-36 871.5,-36 871.5,-36 865.5,-36 859.5,-30 859.5,-24 859.5,-24 859.5,-12 859.5,-12 859.5,-6 865.5,-0 871.5,-0 871.5,-0 901.5,-0 901.5,-0 907.5,-0 913.5,-6 913.5,-12 913.5,-12 913.5,-24 913.5,-24 913.5,-30 907.5,-36 901.5,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"886.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 235&#45;&gt;281 -->\r\n",
       "<g id=\"edge15\" class=\"edge\"><title>235&#45;&gt;281</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M866.185,-71.7615C869.543,-63.0419 873.009,-54.0385 876.107,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"879.472,-46.9949 879.799,-36.4051 872.939,-44.4797 879.472,-46.9949\"/>\r\n",
       "</g>\r\n",
       "<!-- 283 -->\r\n",
       "<g id=\"node18\" class=\"node\"><title>283</title>\r\n",
       "<path fill=\"#b9dcf6\" stroke=\"black\" d=\"M1279,-274C1279,-274 1034,-274 1034,-274 1028,-274 1022,-268 1022,-262 1022,-262 1022,-203 1022,-203 1022,-197 1028,-191 1034,-191 1034,-191 1279,-191 1279,-191 1285,-191 1291,-197 1291,-203 1291,-203 1291,-262 1291,-262 1291,-268 1285,-274 1279,-274\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1156.5\" y=\"-258.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">operating_day_of_week_Sunday &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1156.5\" y=\"-243.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.477</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1156.5\" y=\"-228.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 36.3%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1156.5\" y=\"-213.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.393, 0.607]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1156.5\" y=\"-198.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = important_delay</text>\r\n",
       "</g>\r\n",
       "<!-- 282&#45;&gt;283 -->\r\n",
       "<g id=\"edge17\" class=\"edge\"><title>282&#45;&gt;283</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1156.5,-309.907C1156.5,-301.649 1156.5,-292.864 1156.5,-284.302\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1160,-284.021 1156.5,-274.021 1153,-284.021 1160,-284.021\"/>\r\n",
       "</g>\r\n",
       "<!-- 466 -->\r\n",
       "<g id=\"node25\" class=\"node\"><title>466</title>\r\n",
       "<path fill=\"#56abe9\" stroke=\"black\" d=\"M1663.5,-274C1663.5,-274 1521.5,-274 1521.5,-274 1515.5,-274 1509.5,-268 1509.5,-262 1509.5,-262 1509.5,-203 1509.5,-203 1509.5,-197 1515.5,-191 1521.5,-191 1521.5,-191 1663.5,-191 1663.5,-191 1669.5,-191 1675.5,-197 1675.5,-203 1675.5,-203 1675.5,-262 1675.5,-262 1675.5,-268 1669.5,-274 1663.5,-274\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1592.5\" y=\"-258.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">line_name_S &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1592.5\" y=\"-243.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.224</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1592.5\" y=\"-228.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2.8%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1592.5\" y=\"-213.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.129, 0.871]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1592.5\" y=\"-198.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = important_delay</text>\r\n",
       "</g>\r\n",
       "<!-- 282&#45;&gt;466 -->\r\n",
       "<g id=\"edge24\" class=\"edge\"><title>282&#45;&gt;466</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1297.76,-312.594C1363.82,-294.865 1440.67,-274.242 1499.33,-258.501\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1500.58,-261.792 1509.33,-255.819 1498.76,-255.031 1500.58,-261.792\"/>\r\n",
       "</g>\r\n",
       "<!-- 284 -->\r\n",
       "<g id=\"node19\" class=\"node\"><title>284</title>\r\n",
       "<path fill=\"#add6f4\" stroke=\"black\" d=\"M1219.5,-155C1219.5,-155 1001.5,-155 1001.5,-155 995.5,-155 989.5,-149 989.5,-143 989.5,-143 989.5,-84 989.5,-84 989.5,-78 995.5,-72 1001.5,-72 1001.5,-72 1219.5,-72 1219.5,-72 1225.5,-72 1231.5,-78 1231.5,-84 1231.5,-84 1231.5,-143 1231.5,-143 1231.5,-149 1225.5,-155 1219.5,-155\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1110.5\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">arrival_time_of_day_evening &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1110.5\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.465</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1110.5\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 31.7%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1110.5\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.369, 0.631]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1110.5\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = important_delay</text>\r\n",
       "</g>\r\n",
       "<!-- 283&#45;&gt;284 -->\r\n",
       "<g id=\"edge18\" class=\"edge\"><title>283&#45;&gt;284</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1140.54,-190.907C1137.19,-182.377 1133.61,-173.284 1130.14,-164.456\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1133.35,-163.047 1126.43,-155.021 1126.83,-165.608 1133.35,-163.047\"/>\r\n",
       "</g>\r\n",
       "<!-- 397 -->\r\n",
       "<g id=\"node22\" class=\"node\"><title>397</title>\r\n",
       "<path fill=\"#f1bc95\" stroke=\"black\" d=\"M1479.5,-155C1479.5,-155 1261.5,-155 1261.5,-155 1255.5,-155 1249.5,-149 1249.5,-143 1249.5,-143 1249.5,-84 1249.5,-84 1249.5,-78 1255.5,-72 1261.5,-72 1261.5,-72 1479.5,-72 1479.5,-72 1485.5,-72 1491.5,-78 1491.5,-84 1491.5,-84 1491.5,-143 1491.5,-143 1491.5,-149 1485.5,-155 1479.5,-155\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1370.5\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">arrival_time_of_day_evening &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1370.5\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.434</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1370.5\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 4.6%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1370.5\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.682, 0.318]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1370.5\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = no_delay</text>\r\n",
       "</g>\r\n",
       "<!-- 283&#45;&gt;397 -->\r\n",
       "<g id=\"edge21\" class=\"edge\"><title>283&#45;&gt;397</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1230.75,-190.907C1249.09,-180.879 1268.85,-170.075 1287.58,-159.837\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1289.29,-162.889 1296.39,-155.021 1285.93,-156.747 1289.29,-162.889\"/>\r\n",
       "</g>\r\n",
       "<!-- 285 -->\r\n",
       "<g id=\"node20\" class=\"node\"><title>285</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M1089.5,-36C1089.5,-36 1059.5,-36 1059.5,-36 1053.5,-36 1047.5,-30 1047.5,-24 1047.5,-24 1047.5,-12 1047.5,-12 1047.5,-6 1053.5,-0 1059.5,-0 1059.5,-0 1089.5,-0 1089.5,-0 1095.5,-0 1101.5,-6 1101.5,-12 1101.5,-12 1101.5,-24 1101.5,-24 1101.5,-30 1095.5,-36 1089.5,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1074.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 284&#45;&gt;285 -->\r\n",
       "<g id=\"edge19\" class=\"edge\"><title>284&#45;&gt;285</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1094.81,-71.7615C1091.46,-63.0419 1087.99,-54.0385 1084.89,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1088.06,-44.4797 1081.2,-36.4051 1081.53,-46.9949 1088.06,-44.4797\"/>\r\n",
       "</g>\r\n",
       "<!-- 344 -->\r\n",
       "<g id=\"node21\" class=\"node\"><title>344</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M1161.5,-36C1161.5,-36 1131.5,-36 1131.5,-36 1125.5,-36 1119.5,-30 1119.5,-24 1119.5,-24 1119.5,-12 1119.5,-12 1119.5,-6 1125.5,-0 1131.5,-0 1131.5,-0 1161.5,-0 1161.5,-0 1167.5,-0 1173.5,-6 1173.5,-12 1173.5,-12 1173.5,-24 1173.5,-24 1173.5,-30 1167.5,-36 1161.5,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1146.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 284&#45;&gt;344 -->\r\n",
       "<g id=\"edge20\" class=\"edge\"><title>284&#45;&gt;344</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1126.19,-71.7615C1129.54,-63.0419 1133.01,-54.0385 1136.11,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1139.47,-46.9949 1139.8,-36.4051 1132.94,-44.4797 1139.47,-46.9949\"/>\r\n",
       "</g>\r\n",
       "<!-- 398 -->\r\n",
       "<g id=\"node23\" class=\"node\"><title>398</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M1349.5,-36C1349.5,-36 1319.5,-36 1319.5,-36 1313.5,-36 1307.5,-30 1307.5,-24 1307.5,-24 1307.5,-12 1307.5,-12 1307.5,-6 1313.5,-0 1319.5,-0 1319.5,-0 1349.5,-0 1349.5,-0 1355.5,-0 1361.5,-6 1361.5,-12 1361.5,-12 1361.5,-24 1361.5,-24 1361.5,-30 1355.5,-36 1349.5,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1334.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 397&#45;&gt;398 -->\r\n",
       "<g id=\"edge22\" class=\"edge\"><title>397&#45;&gt;398</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1354.81,-71.7615C1351.46,-63.0419 1347.99,-54.0385 1344.89,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1348.06,-44.4797 1341.2,-36.4051 1341.53,-46.9949 1348.06,-44.4797\"/>\r\n",
       "</g>\r\n",
       "<!-- 435 -->\r\n",
       "<g id=\"node24\" class=\"node\"><title>435</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M1421.5,-36C1421.5,-36 1391.5,-36 1391.5,-36 1385.5,-36 1379.5,-30 1379.5,-24 1379.5,-24 1379.5,-12 1379.5,-12 1379.5,-6 1385.5,-0 1391.5,-0 1391.5,-0 1421.5,-0 1421.5,-0 1427.5,-0 1433.5,-6 1433.5,-12 1433.5,-12 1433.5,-24 1433.5,-24 1433.5,-30 1427.5,-36 1421.5,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1406.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 397&#45;&gt;435 -->\r\n",
       "<g id=\"edge23\" class=\"edge\"><title>397&#45;&gt;435</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1386.19,-71.7615C1389.54,-63.0419 1393.01,-54.0385 1396.11,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1399.47,-46.9949 1399.8,-36.4051 1392.94,-44.4797 1399.47,-46.9949\"/>\r\n",
       "</g>\r\n",
       "<!-- 467 -->\r\n",
       "<g id=\"node26\" class=\"node\"><title>467</title>\r\n",
       "<path fill=\"#61b1ea\" stroke=\"black\" d=\"M1663.5,-155C1663.5,-155 1521.5,-155 1521.5,-155 1515.5,-155 1509.5,-149 1509.5,-143 1509.5,-143 1509.5,-84 1509.5,-84 1509.5,-78 1515.5,-72 1521.5,-72 1521.5,-72 1663.5,-72 1663.5,-72 1669.5,-72 1675.5,-78 1675.5,-84 1675.5,-84 1675.5,-143 1675.5,-143 1675.5,-149 1669.5,-155 1663.5,-155\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1592.5\" y=\"-139.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">line_name_S3 &lt;= 0.5</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1592.5\" y=\"-124.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.278</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1592.5\" y=\"-109.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 2.6%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1592.5\" y=\"-94.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.167, 0.833]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1592.5\" y=\"-79.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = important_delay</text>\r\n",
       "</g>\r\n",
       "<!-- 466&#45;&gt;467 -->\r\n",
       "<g id=\"edge25\" class=\"edge\"><title>466&#45;&gt;467</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1592.5,-190.907C1592.5,-182.649 1592.5,-173.864 1592.5,-165.302\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1596,-165.021 1592.5,-155.021 1589,-165.021 1596,-165.021\"/>\r\n",
       "</g>\r\n",
       "<!-- 528 -->\r\n",
       "<g id=\"node29\" class=\"node\"><title>528</title>\r\n",
       "<path fill=\"#399de5\" stroke=\"black\" d=\"M1847.5,-147.5C1847.5,-147.5 1705.5,-147.5 1705.5,-147.5 1699.5,-147.5 1693.5,-141.5 1693.5,-135.5 1693.5,-135.5 1693.5,-91.5 1693.5,-91.5 1693.5,-85.5 1699.5,-79.5 1705.5,-79.5 1705.5,-79.5 1847.5,-79.5 1847.5,-79.5 1853.5,-79.5 1859.5,-85.5 1859.5,-91.5 1859.5,-91.5 1859.5,-135.5 1859.5,-135.5 1859.5,-141.5 1853.5,-147.5 1847.5,-147.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1776.5\" y=\"-132.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1776.5\" y=\"-117.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 0.2%</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1776.5\" y=\"-102.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0.0, 1.0]</text>\r\n",
       "<text text-anchor=\"middle\" x=\"1776.5\" y=\"-87.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = important_delay</text>\r\n",
       "</g>\r\n",
       "<!-- 466&#45;&gt;528 -->\r\n",
       "<g id=\"edge28\" class=\"edge\"><title>466&#45;&gt;528</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1656.34,-190.907C1675.6,-178.659 1696.69,-165.252 1715.74,-153.135\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1717.78,-155.986 1724.34,-147.667 1714.02,-150.079 1717.78,-155.986\"/>\r\n",
       "</g>\r\n",
       "<!-- 468 -->\r\n",
       "<g id=\"node27\" class=\"node\"><title>468</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M1571.5,-36C1571.5,-36 1541.5,-36 1541.5,-36 1535.5,-36 1529.5,-30 1529.5,-24 1529.5,-24 1529.5,-12 1529.5,-12 1529.5,-6 1535.5,-0 1541.5,-0 1541.5,-0 1571.5,-0 1571.5,-0 1577.5,-0 1583.5,-6 1583.5,-12 1583.5,-12 1583.5,-24 1583.5,-24 1583.5,-30 1577.5,-36 1571.5,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1556.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 467&#45;&gt;468 -->\r\n",
       "<g id=\"edge26\" class=\"edge\"><title>467&#45;&gt;468</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1576.81,-71.7615C1573.46,-63.0419 1569.99,-54.0385 1566.89,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1570.06,-44.4797 1563.2,-36.4051 1563.53,-46.9949 1570.06,-44.4797\"/>\r\n",
       "</g>\r\n",
       "<!-- 511 -->\r\n",
       "<g id=\"node28\" class=\"node\"><title>511</title>\r\n",
       "<path fill=\"#c0c0c0\" stroke=\"black\" d=\"M1643.5,-36C1643.5,-36 1613.5,-36 1613.5,-36 1607.5,-36 1601.5,-30 1601.5,-24 1601.5,-24 1601.5,-12 1601.5,-12 1601.5,-6 1607.5,-0 1613.5,-0 1613.5,-0 1643.5,-0 1643.5,-0 1649.5,-0 1655.5,-6 1655.5,-12 1655.5,-12 1655.5,-24 1655.5,-24 1655.5,-30 1649.5,-36 1643.5,-36\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"1628.5\" y=\"-14.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">(...)</text>\r\n",
       "</g>\r\n",
       "<!-- 467&#45;&gt;511 -->\r\n",
       "<g id=\"edge27\" class=\"edge\"><title>467&#45;&gt;511</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1608.19,-71.7615C1611.54,-63.0419 1615.01,-54.0385 1618.11,-45.9921\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1621.47,-46.9949 1621.8,-36.4051 1614.94,-44.4797 1621.47,-46.9949\"/>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1f32ef14048>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "# Export decision tree\n",
    "dot_data_i = export_graphviz(\n",
    "    dt_final_i, out_file=None,\n",
    "    max_depth=3,\n",
    "    feature_names=df_tr_arr_input_columns, \n",
    "    class_names=['no_delay','important_delay'],\n",
    "    filled=True, rounded=True, proportion=True)\n",
    "\n",
    "# Display decision tree\n",
    "graphviz.Source(dot_data_i)\n",
    "# maybe want to only consider non-balanced for DecisionTree ti make understanding predition more readable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments DecisionTree:**\n",
    "* Interesting to be able to visualize trees but not really readable in this case when there are so many dimensions\n",
    "* Overall good performance with f1 socres at 0.54 and 0.17 but slightly below LogisticRegression and SVC Linear Especially high recall which means many false positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance on test set (DecisionTree Linear) <a name='dt_test' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under PR Curve: 0.591\n",
      "Classification report: DecisionTree TEST delay\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    no_delay       0.95      0.68      0.79     80088\n",
      "       delay       0.49      0.88      0.63     27278\n",
      "\n",
      "    accuracy                           0.73    107366\n",
      "   macro avg       0.72      0.78      0.71    107366\n",
      "weighted avg       0.83      0.73      0.75    107366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# delay\n",
    "dt_test_probs_pos_d = dt_final_d.predict_proba(X_te_arr_reindex)[:,1]\n",
    "dt_precision_test_d, dt_recall_test_d, _ = precision_recall_curve(y_te_arr_delay_binary, dt_test_probs_pos_d, pos_label=1)\n",
    "dt_test_auc_pr_d = auc(dt_recall_test_d, dt_precision_test_d)\n",
    "print('Area Under PR Curve: {:.3f}'.format(dt_test_auc_pr_d))\n",
    "# use threshold\n",
    "y_pred_dt_test_d = dt_final_d.predict(X_te_arr_reindex) # prediction delay\n",
    "print('Classification report: DecisionTree TEST delay')\n",
    "report_dt_d= classification_report(y_true=y_te_arr_delay_binary, y_pred=y_pred_dt_test_d, target_names=['no_delay','delay'])\n",
    "f1_dt_test_d = classification_report(y_true=y_te_arr_delay_binary, y_pred=y_pred_dt_test_d, target_names=['no_delay','delay'], output_dict=True)['delay']['f1-score']\n",
    "precision_dt_test_d = classification_report(y_true=y_te_arr_delay_binary, y_pred=y_pred_dt_test_d, target_names=['no_delay','delay'], output_dict=True)['delay']['precision']\n",
    "recall_dt_test_d = classification_report(y_true=y_te_arr_delay_binary, y_pred=y_pred_dt_test_d, target_names=['no_delay','delay'], output_dict=True)['delay']['recall']\n",
    "print(report_dt_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under PR Curve: 0.256\n",
      "Classification report: DecisionTree TEST important delay\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       no_delay       0.98      0.62      0.76    100362\n",
      "important_delay       0.13      0.78      0.22      7004\n",
      "\n",
      "       accuracy                           0.63    107366\n",
      "      macro avg       0.55      0.70      0.49    107366\n",
      "   weighted avg       0.92      0.63      0.72    107366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# important delay\n",
    "dt_test_probs_pos_i = dt_final_i.predict_proba(X_te_arr_reindex)[:,1]\n",
    "dt_precision_test_i, dt_recall_test_i, _ = precision_recall_curve(y_te_arr_imp_delay_binary, dt_test_probs_pos_i, pos_label=1)\n",
    "dt_test_auc_pr_i = auc(dt_recall_test_i, dt_precision_test_i)\n",
    "print('Area Under PR Curve: {:.3f}'.format(dt_test_auc_pr_i))\n",
    "# use threshold\n",
    "y_pred_dt_test_i = dt_final_i.predict(X_te_arr_reindex) # prediction delay\n",
    "print('Classification report: DecisionTree TEST important delay')\n",
    "report_dt_i= classification_report(y_true=y_te_arr_imp_delay_binary, y_pred=y_pred_dt_test_i, target_names=['no_delay','important_delay'])\n",
    "f1_dt_test_i = classification_report(y_true=y_te_arr_imp_delay_binary, y_pred=y_pred_dt_test_i, target_names=['no_delay','important_delay'], output_dict=True)['important_delay']['f1-score']\n",
    "precision_dt_test_i = classification_report(y_true=y_te_arr_imp_delay_binary, y_pred=y_pred_dt_test_i, target_names=['no_delay','important_delay'], output_dict=True)['important_delay']['precision']\n",
    "recall_dt_test_i = classification_report(y_true=y_te_arr_imp_delay_binary, y_pred=y_pred_dt_test_i, target_names=['no_delay','important_delay'], output_dict=True)['important_delay']['recall']\n",
    "print(report_dt_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest <a name='rf' />\n",
    "*<a href=#top>Back to top</a>*\n",
    "#### Delay <a name='rf_delay' /> <a name='rf_delay_grid' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'class_weight': [None, 'balanced',\n",
       "                                          'balanced_subsample'],\n",
       "                         'max_depth': [3, 5, 7, 9, 11],\n",
       "                         'n_estimators': [1, 3, 5, 7, 9, 11, 13, 15]},\n",
       "             refit=False, return_train_score=True,\n",
       "             scoring=['precision', 'recall', 'average_precision', 'f1'])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create RandomForest\n",
    "forest_d = RandomForestClassifier()\n",
    "# parameters\n",
    "balance_rf = [None, 'balanced', 'balanced_subsample']\n",
    "trees_rf = [3,5,7,9,11]\n",
    "estimators_rf = [1,3,5,7,9,11,13,15]\n",
    "param_grid_rf = dict(class_weight=balance_rf, max_depth=trees_rf, n_estimators=estimators_rf)\n",
    "# define GridSearchCV\n",
    "scoring = ['precision','recall','average_precision','f1']\n",
    "grid_rf_d = GridSearchCV(estimator=forest_d, param_grid=param_grid_rf, n_jobs=-1, cv=5, scoring=scoring, refit=False, return_train_score=True)\n",
    "# fit\n",
    "grid_rf_d.fit(X_tr_arr, y_tr_arr_delay_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_class_weight', 'param_max_depth', 'param_n_estimators', 'params', 'split0_test_precision', 'split1_test_precision', 'split2_test_precision', 'split3_test_precision', 'split4_test_precision', 'mean_test_precision', 'std_test_precision', 'rank_test_precision', 'split0_train_precision', 'split1_train_precision', 'split2_train_precision', 'split3_train_precision', 'split4_train_precision', 'mean_train_precision', 'std_train_precision', 'split0_test_recall', 'split1_test_recall', 'split2_test_recall', 'split3_test_recall', 'split4_test_recall', 'mean_test_recall', 'std_test_recall', 'rank_test_recall', 'split0_train_recall', 'split1_train_recall', 'split2_train_recall', 'split3_train_recall', 'split4_train_recall', 'mean_train_recall', 'std_train_recall', 'split0_test_average_precision', 'split1_test_average_precision', 'split2_test_average_precision', 'split3_test_average_precision', 'split4_test_average_precision', 'mean_test_average_precision', 'std_test_average_precision', 'rank_test_average_precision', 'split0_train_average_precision', 'split1_train_average_precision', 'split2_train_average_precision', 'split3_train_average_precision', 'split4_train_average_precision', 'mean_train_average_precision', 'std_train_average_precision', 'split0_test_f1', 'split1_test_f1', 'split2_test_f1', 'split3_test_f1', 'split4_test_f1', 'mean_test_f1', 'std_test_f1', 'rank_test_f1', 'split0_train_f1', 'split1_train_f1', 'split2_train_f1', 'split3_train_f1', 'split4_train_f1', 'mean_train_f1', 'std_train_f1'])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the results with \"cv_results\"\n",
    "grid_rf_d.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03210183, 0.01840588, 0.01249549, 0.01389192, 0.00128669,\n",
       "       0.        , 0.00493679, 0.11833582, 0.07352153])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf_d.cv_results_['mean_test_f1'][1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_average_precision</th>\n",
       "      <th>mean_train_average_precision</th>\n",
       "      <th>std_test_average_precision</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>mean_train_f1</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_train_recall</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_train_precision</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.509801</td>\n",
       "      <td>0.605363</td>\n",
       "      <td>0.068372</td>\n",
       "      <td>0.567645</td>\n",
       "      <td>0.568688</td>\n",
       "      <td>0.957989</td>\n",
       "      <td>0.969250</td>\n",
       "      <td>0.403891</td>\n",
       "      <td>0.402465</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>19.264324</td>\n",
       "      <td>0.795781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.531043</td>\n",
       "      <td>0.593525</td>\n",
       "      <td>0.045520</td>\n",
       "      <td>0.566198</td>\n",
       "      <td>0.574916</td>\n",
       "      <td>0.951235</td>\n",
       "      <td>0.964769</td>\n",
       "      <td>0.403333</td>\n",
       "      <td>0.409528</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>10.713417</td>\n",
       "      <td>0.701610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.520073</td>\n",
       "      <td>0.611108</td>\n",
       "      <td>0.069928</td>\n",
       "      <td>0.565769</td>\n",
       "      <td>0.571288</td>\n",
       "      <td>0.952395</td>\n",
       "      <td>0.961092</td>\n",
       "      <td>0.402843</td>\n",
       "      <td>0.406692</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>balanced</td>\n",
       "      <td>21.762269</td>\n",
       "      <td>0.965477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.518269</td>\n",
       "      <td>0.617490</td>\n",
       "      <td>0.065305</td>\n",
       "      <td>0.565760</td>\n",
       "      <td>0.572682</td>\n",
       "      <td>0.958905</td>\n",
       "      <td>0.973319</td>\n",
       "      <td>0.401347</td>\n",
       "      <td>0.405817</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>22.019253</td>\n",
       "      <td>0.674433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.514527</td>\n",
       "      <td>0.606363</td>\n",
       "      <td>0.066703</td>\n",
       "      <td>0.564995</td>\n",
       "      <td>0.573467</td>\n",
       "      <td>0.950218</td>\n",
       "      <td>0.962551</td>\n",
       "      <td>0.402440</td>\n",
       "      <td>0.408555</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>18.106232</td>\n",
       "      <td>0.829804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.514533</td>\n",
       "      <td>0.612274</td>\n",
       "      <td>0.077018</td>\n",
       "      <td>0.564903</td>\n",
       "      <td>0.571710</td>\n",
       "      <td>0.954999</td>\n",
       "      <td>0.968339</td>\n",
       "      <td>0.401292</td>\n",
       "      <td>0.405718</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>balanced</td>\n",
       "      <td>18.949736</td>\n",
       "      <td>0.878226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.517870</td>\n",
       "      <td>0.609643</td>\n",
       "      <td>0.065371</td>\n",
       "      <td>0.564457</td>\n",
       "      <td>0.572110</td>\n",
       "      <td>0.946088</td>\n",
       "      <td>0.963864</td>\n",
       "      <td>0.402540</td>\n",
       "      <td>0.406883</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>balanced</td>\n",
       "      <td>16.383346</td>\n",
       "      <td>0.791699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.501786</td>\n",
       "      <td>0.609121</td>\n",
       "      <td>0.090708</td>\n",
       "      <td>0.564396</td>\n",
       "      <td>0.569620</td>\n",
       "      <td>0.971233</td>\n",
       "      <td>0.982712</td>\n",
       "      <td>0.398110</td>\n",
       "      <td>0.401051</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>22.920151</td>\n",
       "      <td>0.946035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.513937</td>\n",
       "      <td>0.601914</td>\n",
       "      <td>0.067329</td>\n",
       "      <td>0.564165</td>\n",
       "      <td>0.568453</td>\n",
       "      <td>0.959982</td>\n",
       "      <td>0.974407</td>\n",
       "      <td>0.400077</td>\n",
       "      <td>0.401318</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>15.984052</td>\n",
       "      <td>0.975893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.512109</td>\n",
       "      <td>0.605628</td>\n",
       "      <td>0.077752</td>\n",
       "      <td>0.564006</td>\n",
       "      <td>0.568020</td>\n",
       "      <td>0.961265</td>\n",
       "      <td>0.974305</td>\n",
       "      <td>0.399210</td>\n",
       "      <td>0.400967</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>balanced</td>\n",
       "      <td>21.448375</td>\n",
       "      <td>0.857709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.506284</td>\n",
       "      <td>0.589867</td>\n",
       "      <td>0.066471</td>\n",
       "      <td>0.563675</td>\n",
       "      <td>0.569343</td>\n",
       "      <td>0.974630</td>\n",
       "      <td>0.981838</td>\n",
       "      <td>0.397095</td>\n",
       "      <td>0.400966</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>10.709894</td>\n",
       "      <td>0.665725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.518153</td>\n",
       "      <td>0.569583</td>\n",
       "      <td>0.041590</td>\n",
       "      <td>0.563647</td>\n",
       "      <td>0.566195</td>\n",
       "      <td>0.948609</td>\n",
       "      <td>0.958488</td>\n",
       "      <td>0.402105</td>\n",
       "      <td>0.402040</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>22.268401</td>\n",
       "      <td>1.162000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.535605</td>\n",
       "      <td>0.596819</td>\n",
       "      <td>0.042455</td>\n",
       "      <td>0.562453</td>\n",
       "      <td>0.569407</td>\n",
       "      <td>0.947166</td>\n",
       "      <td>0.966702</td>\n",
       "      <td>0.400234</td>\n",
       "      <td>0.403713</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>balanced</td>\n",
       "      <td>12.983642</td>\n",
       "      <td>0.767908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.508973</td>\n",
       "      <td>0.578937</td>\n",
       "      <td>0.059078</td>\n",
       "      <td>0.560723</td>\n",
       "      <td>0.562280</td>\n",
       "      <td>0.941592</td>\n",
       "      <td>0.944623</td>\n",
       "      <td>0.399443</td>\n",
       "      <td>0.400377</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>24.679194</td>\n",
       "      <td>1.124401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.502141</td>\n",
       "      <td>0.554066</td>\n",
       "      <td>0.038213</td>\n",
       "      <td>0.560093</td>\n",
       "      <td>0.562812</td>\n",
       "      <td>0.964825</td>\n",
       "      <td>0.971498</td>\n",
       "      <td>0.394791</td>\n",
       "      <td>0.396262</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>14.977598</td>\n",
       "      <td>1.016001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.503065</td>\n",
       "      <td>0.585791</td>\n",
       "      <td>0.067695</td>\n",
       "      <td>0.560087</td>\n",
       "      <td>0.565263</td>\n",
       "      <td>0.930790</td>\n",
       "      <td>0.944236</td>\n",
       "      <td>0.400644</td>\n",
       "      <td>0.403604</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>balanced</td>\n",
       "      <td>16.594950</td>\n",
       "      <td>0.855720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.494597</td>\n",
       "      <td>0.570181</td>\n",
       "      <td>0.056512</td>\n",
       "      <td>0.559826</td>\n",
       "      <td>0.569811</td>\n",
       "      <td>0.925134</td>\n",
       "      <td>0.947588</td>\n",
       "      <td>0.401902</td>\n",
       "      <td>0.407674</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>balanced</td>\n",
       "      <td>7.667142</td>\n",
       "      <td>0.557011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.469391</td>\n",
       "      <td>0.499325</td>\n",
       "      <td>0.035287</td>\n",
       "      <td>0.559800</td>\n",
       "      <td>0.565536</td>\n",
       "      <td>0.935264</td>\n",
       "      <td>0.942991</td>\n",
       "      <td>0.400804</td>\n",
       "      <td>0.404950</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>5.014721</td>\n",
       "      <td>0.525238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.483998</td>\n",
       "      <td>0.526885</td>\n",
       "      <td>0.041776</td>\n",
       "      <td>0.559177</td>\n",
       "      <td>0.565008</td>\n",
       "      <td>0.930850</td>\n",
       "      <td>0.945950</td>\n",
       "      <td>0.400237</td>\n",
       "      <td>0.403563</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>balanced</td>\n",
       "      <td>6.925230</td>\n",
       "      <td>0.550516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.499274</td>\n",
       "      <td>0.571273</td>\n",
       "      <td>0.057911</td>\n",
       "      <td>0.558996</td>\n",
       "      <td>0.563219</td>\n",
       "      <td>0.936323</td>\n",
       "      <td>0.944999</td>\n",
       "      <td>0.399065</td>\n",
       "      <td>0.401806</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>balanced</td>\n",
       "      <td>14.133061</td>\n",
       "      <td>0.843775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_test_average_precision  mean_train_average_precision  \\\n",
       "117                     0.509801                      0.605363   \n",
       "114                     0.531043                      0.593525   \n",
       "79                      0.520073                      0.611108   \n",
       "119                     0.518269                      0.617490   \n",
       "116                     0.514527                      0.606363   \n",
       "77                      0.514533                      0.612274   \n",
       "76                      0.517870                      0.609643   \n",
       "118                     0.501786                      0.609121   \n",
       "115                     0.513937                      0.601914   \n",
       "78                      0.512109                      0.605628   \n",
       "74                      0.506284                      0.589867   \n",
       "108                     0.518153                      0.569583   \n",
       "75                      0.535605                      0.596819   \n",
       "109                     0.508973                      0.578937   \n",
       "106                     0.502141                      0.554066   \n",
       "69                      0.503065                      0.585791   \n",
       "73                      0.494597                      0.570181   \n",
       "72                      0.469391                      0.499325   \n",
       "65                      0.483998                      0.526885   \n",
       "68                      0.499274                      0.571273   \n",
       "\n",
       "     std_test_average_precision  mean_test_f1  mean_train_f1  \\\n",
       "117                    0.068372      0.567645       0.568688   \n",
       "114                    0.045520      0.566198       0.574916   \n",
       "79                     0.069928      0.565769       0.571288   \n",
       "119                    0.065305      0.565760       0.572682   \n",
       "116                    0.066703      0.564995       0.573467   \n",
       "77                     0.077018      0.564903       0.571710   \n",
       "76                     0.065371      0.564457       0.572110   \n",
       "118                    0.090708      0.564396       0.569620   \n",
       "115                    0.067329      0.564165       0.568453   \n",
       "78                     0.077752      0.564006       0.568020   \n",
       "74                     0.066471      0.563675       0.569343   \n",
       "108                    0.041590      0.563647       0.566195   \n",
       "75                     0.042455      0.562453       0.569407   \n",
       "109                    0.059078      0.560723       0.562280   \n",
       "106                    0.038213      0.560093       0.562812   \n",
       "69                     0.067695      0.560087       0.565263   \n",
       "73                     0.056512      0.559826       0.569811   \n",
       "72                     0.035287      0.559800       0.565536   \n",
       "65                     0.041776      0.559177       0.565008   \n",
       "68                     0.057911      0.558996       0.563219   \n",
       "\n",
       "     mean_test_recall  mean_train_recall  mean_test_precision  \\\n",
       "117          0.957989           0.969250             0.403891   \n",
       "114          0.951235           0.964769             0.403333   \n",
       "79           0.952395           0.961092             0.402843   \n",
       "119          0.958905           0.973319             0.401347   \n",
       "116          0.950218           0.962551             0.402440   \n",
       "77           0.954999           0.968339             0.401292   \n",
       "76           0.946088           0.963864             0.402540   \n",
       "118          0.971233           0.982712             0.398110   \n",
       "115          0.959982           0.974407             0.400077   \n",
       "78           0.961265           0.974305             0.399210   \n",
       "74           0.974630           0.981838             0.397095   \n",
       "108          0.948609           0.958488             0.402105   \n",
       "75           0.947166           0.966702             0.400234   \n",
       "109          0.941592           0.944623             0.399443   \n",
       "106          0.964825           0.971498             0.394791   \n",
       "69           0.930790           0.944236             0.400644   \n",
       "73           0.925134           0.947588             0.401902   \n",
       "72           0.935264           0.942991             0.400804   \n",
       "65           0.930850           0.945950             0.400237   \n",
       "68           0.936323           0.944999             0.399065   \n",
       "\n",
       "     mean_train_precision param_max_depth param_n_estimators  \\\n",
       "117              0.402465              11                 11   \n",
       "114              0.409528              11                  5   \n",
       "79               0.406692              11                 15   \n",
       "119              0.405817              11                 15   \n",
       "116              0.408555              11                  9   \n",
       "77               0.405718              11                 11   \n",
       "76               0.406883              11                  9   \n",
       "118              0.401051              11                 13   \n",
       "115              0.401318              11                  7   \n",
       "78               0.400967              11                 13   \n",
       "74               0.400966              11                  5   \n",
       "108              0.402040               9                  9   \n",
       "75               0.403713              11                  7   \n",
       "109              0.400377               9                 11   \n",
       "106              0.396262               9                  5   \n",
       "69               0.403604               9                 11   \n",
       "73               0.407674              11                  3   \n",
       "72               0.404950              11                  1   \n",
       "65               0.403563               9                  3   \n",
       "68               0.401806               9                  9   \n",
       "\n",
       "     param_class_weight  mean_fit_time  mean_score_time  \n",
       "117  balanced_subsample      19.264324         0.795781  \n",
       "114  balanced_subsample      10.713417         0.701610  \n",
       "79             balanced      21.762269         0.965477  \n",
       "119  balanced_subsample      22.019253         0.674433  \n",
       "116  balanced_subsample      18.106232         0.829804  \n",
       "77             balanced      18.949736         0.878226  \n",
       "76             balanced      16.383346         0.791699  \n",
       "118  balanced_subsample      22.920151         0.946035  \n",
       "115  balanced_subsample      15.984052         0.975893  \n",
       "78             balanced      21.448375         0.857709  \n",
       "74             balanced      10.709894         0.665725  \n",
       "108  balanced_subsample      22.268401         1.162000  \n",
       "75             balanced      12.983642         0.767908  \n",
       "109  balanced_subsample      24.679194         1.124401  \n",
       "106  balanced_subsample      14.977598         1.016001  \n",
       "69             balanced      16.594950         0.855720  \n",
       "73             balanced       7.667142         0.557011  \n",
       "72             balanced       5.014721         0.525238  \n",
       "65             balanced       6.925230         0.550516  \n",
       "68             balanced      14.133061         0.843775  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['mean_test_average_precision','mean_train_average_precision','std_test_average_precision',\\\n",
    "        'mean_test_f1','mean_train_f1',\\\n",
    "        'mean_test_recall','mean_train_recall','mean_test_precision','mean_train_precision',\\\n",
    "        'param_max_depth','param_n_estimators','param_class_weight',\\\n",
    "        'mean_fit_time','mean_score_time']\n",
    "# Delay GridSearchCV\n",
    "grid_rf_df_d = pd.DataFrame(grid_rf_d.cv_results_)[cols].sort_values(by='mean_test_f1', ascending=False)\n",
    "grid_rf_df_d.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under PR Curve: 0.487\n"
     ]
    }
   ],
   "source": [
    "# going with (73) because decent AP, very high f1 and recall, precision similar to other and best 'fit_time'\n",
    "forest_final_d = RandomForestClassifier(criterion='gini', max_depth=11, n_estimators=3, random_state=0, class_weight='balanced_subsample')\n",
    "# fit\n",
    "forest_final_d.fit(X_tr_arr, y_tr_arr_delay_binary)\n",
    "# predict\n",
    "y_pred_forest_va_final_d = forest_final_d.predict(X_va_arr_reindex) # prediction delay\n",
    "# predict probabilities\n",
    "forest_final_probs_d = forest_final_d.predict_proba(X_va_arr_reindex)\n",
    "# keep probabilities for the positive outcome only\n",
    "forest_final_probs_pos_d = forest_final_probs_d[:,1]\n",
    "# Precision-recall curve metrics\n",
    "rf_precision_final_d, rf_recall_final_d, rf_thres_final_d = precision_recall_curve(y_va_arr_delay_binary, forest_final_probs_pos_d, pos_label=1)\n",
    "rf_final_auprc_d = auc(rf_recall_final_d, rf_precision_final_d)\n",
    "print('Area Under PR Curve: {:.3f}'.format(rf_final_auprc_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best threshold (RandomForest - Delay) <a name='rf_delay_thres' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.608\n",
      "Probabilities: [0.61799597 0.52203743 0.61799597 0.55905321 0.89401426 0.64835105\n",
      " 0.71057243 0.71057243 0.71057243 0.71057243]\n",
      "Predictions: [1 0 1 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from numpy import argmax\n",
    "fscores_rf_d = (2 * rf_precision_final_d * rf_recall_final_d) / (rf_precision_final_d + rf_recall_final_d)\n",
    "rf_bt_d = rf_thres_final_d[argmax(fscores_rf_d)]\n",
    "print('Best Threshold: {:.3f}'.format(rf_bt_d))\n",
    "# use threshold in model\n",
    "rf_final_curve_d = np.where(forest_final_probs_d[:,1] > rf_bt_d, 1,0)\n",
    "print('Probabilities:',forest_final_probs_d[0:10,1])\n",
    "print('Predictions:',rf_final_curve_d[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report (RandomForest - Delay) <a name='rf_delay_report' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: RandomForest delay\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    no_delay       0.91      0.74      0.81     86652\n",
      "       delay       0.41      0.71      0.52     22068\n",
      "\n",
      "    accuracy                           0.73    108720\n",
      "   macro avg       0.66      0.72      0.66    108720\n",
      "weighted avg       0.81      0.73      0.75    108720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: RandomForest delay')\n",
    "report_forest_final_d= classification_report(y_true=y_va_arr_delay_binary, y_pred=rf_final_curve_d, target_names=['no_delay','delay'])\n",
    "print(report_forest_final_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix (RandomForest - Delay) <a name='rf_delay_report' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (normalized): RandomForest delay\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred: no delay</th>\n",
       "      <th>pred: delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true: no delay</th>\n",
       "      <td>0.585872</td>\n",
       "      <td>0.211148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true: delay</th>\n",
       "      <td>0.058913</td>\n",
       "      <td>0.144067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pred: no delay  pred: delay\n",
       "true: no delay        0.585872     0.211148\n",
       "true: delay           0.058913     0.144067"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix 'RF important delay'\n",
    "matrix_rf_d = confusion_matrix(y_true=y_va_arr_delay_binary, y_pred=rf_final_curve_d,normalize='all') # normalize either on columns/rows or all\n",
    "matrix_rf_d = pd.DataFrame(\n",
    "    matrix_rf_d, \n",
    "    columns=['pred: no delay', 'pred: delay'],\n",
    "    index=['true: no delay', 'true: delay']\n",
    ")\n",
    "print('Confusion matrix (normalized): RandomForest delay')\n",
    "matrix_rf_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important delay <a name='rf_imp_delay' /><a name='rf_imp_delay_grid' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'class_weight': [None, 'balanced',\n",
       "                                          'balanced_subsample'],\n",
       "                         'max_depth': [3, 5, 7, 9, 11],\n",
       "                         'n_estimators': [1, 3, 5, 7, 9, 11, 13, 15]},\n",
       "             refit=False, return_train_score=True,\n",
       "             scoring=['precision', 'recall', 'average_precision', 'f1'])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create RandomForest\n",
    "forest_i = RandomForestClassifier()\n",
    "# parameters\n",
    "balance_rf = [None, 'balanced', 'balanced_subsample']\n",
    "trees_rf = [3,5,7,9,11]\n",
    "estimators_rf = [1,3,5,7,9,11,13,15]\n",
    "param_grid_rf = dict(class_weight=balance_rf, max_depth=trees_rf, n_estimators=estimators_rf)\n",
    "# define GridSearchCV\n",
    "scoring = ['precision','recall','average_precision','f1']\n",
    "grid_rf_i = GridSearchCV(estimator=forest_i, param_grid=param_grid_rf, n_jobs=-1, cv=5, scoring=scoring, refit=False, return_train_score=True)\n",
    "# fit\n",
    "grid_rf_i.fit(X_tr_arr, y_tr_arr_imp_delay_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_class_weight', 'param_max_depth', 'param_n_estimators', 'params', 'split0_test_precision', 'split1_test_precision', 'split2_test_precision', 'split3_test_precision', 'split4_test_precision', 'mean_test_precision', 'std_test_precision', 'rank_test_precision', 'split0_train_precision', 'split1_train_precision', 'split2_train_precision', 'split3_train_precision', 'split4_train_precision', 'mean_train_precision', 'std_train_precision', 'split0_test_recall', 'split1_test_recall', 'split2_test_recall', 'split3_test_recall', 'split4_test_recall', 'mean_test_recall', 'std_test_recall', 'rank_test_recall', 'split0_train_recall', 'split1_train_recall', 'split2_train_recall', 'split3_train_recall', 'split4_train_recall', 'mean_train_recall', 'std_train_recall', 'split0_test_average_precision', 'split1_test_average_precision', 'split2_test_average_precision', 'split3_test_average_precision', 'split4_test_average_precision', 'mean_test_average_precision', 'std_test_average_precision', 'rank_test_average_precision', 'split0_train_average_precision', 'split1_train_average_precision', 'split2_train_average_precision', 'split3_train_average_precision', 'split4_train_average_precision', 'mean_train_average_precision', 'std_train_average_precision', 'split0_test_f1', 'split1_test_f1', 'split2_test_f1', 'split3_test_f1', 'split4_test_f1', 'mean_test_f1', 'std_test_f1', 'rank_test_f1', 'split0_train_f1', 'split1_train_f1', 'split2_train_f1', 'split3_train_f1', 'split4_train_f1', 'mean_train_f1', 'std_train_f1'])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the results with \"cv_results\"\n",
    "grid_rf_i.cv_results_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.53405475e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.35046554e-02, 3.36597314e-03, 3.56188780e-04, 1.59786951e-03,\n",
       "       2.83229814e-02, 3.53356890e-03, 0.00000000e+00, 0.00000000e+00,\n",
       "       3.56727526e-02, 1.56594735e-02, 3.54893995e-03, 3.65147550e-02,\n",
       "       1.78094390e-04, 2.41430009e-02, 0.00000000e+00, 2.22222222e-02,\n",
       "       6.55874835e-02, 7.58866897e-02, 1.77518602e-03, 2.57857586e-02,\n",
       "       4.46698258e-02, 3.58203521e-02, 3.69687086e-02, 2.48928581e-03,\n",
       "       5.86512202e-02, 5.92967812e-02, 4.64063417e-02, 5.98698195e-02,\n",
       "       4.53313146e-02, 6.30075066e-02, 3.94998684e-02, 2.42941591e-02,\n",
       "       1.53204454e-01, 1.48723808e-01, 1.66223271e-01, 1.65660789e-01,\n",
       "       1.67274729e-01, 1.67690226e-01, 1.64943394e-01, 1.63369246e-01,\n",
       "       1.39995943e-01, 1.63984117e-01, 1.69301585e-01, 1.65994164e-01,\n",
       "       1.70085999e-01, 1.69592741e-01, 1.72188813e-01, 1.72453443e-01,\n",
       "       1.58130697e-01, 1.64536262e-01, 1.68016475e-01, 1.69047482e-01,\n",
       "       1.64767752e-01, 1.68749108e-01, 1.69646798e-01, 1.68185546e-01,\n",
       "       1.61808082e-01, 1.68846573e-01, 1.67622314e-01, 1.71984886e-01,\n",
       "       1.68300031e-01, 1.73064754e-01, 1.70167649e-01, 1.69907433e-01,\n",
       "       1.62150652e-01, 1.70163013e-01, 1.78632516e-01, 1.70527041e-01,\n",
       "       1.73566416e-01, 1.74641101e-01, 1.67650181e-01, 1.74727364e-01,\n",
       "       1.33934873e-01, 1.75828656e-01, 1.65595902e-01, 1.63878889e-01,\n",
       "       1.67788103e-01, 1.63400442e-01, 1.62663943e-01, 1.67758426e-01,\n",
       "       1.66406187e-01, 1.61304180e-01, 1.61063083e-01, 1.67329127e-01,\n",
       "       1.69638524e-01, 1.71988777e-01, 1.73427172e-01, 1.72074276e-01,\n",
       "       1.60434824e-01, 1.60098957e-01, 1.69187628e-01, 1.72391051e-01,\n",
       "       1.72910002e-01, 1.70352676e-01, 1.69129988e-01, 1.72024011e-01,\n",
       "       1.63936542e-01, 1.63469762e-01, 1.64943321e-01, 1.70873811e-01,\n",
       "       1.68955125e-01, 1.71164500e-01, 1.74377189e-01, 1.69464919e-01,\n",
       "       1.62066644e-01, 1.69316556e-01, 1.72958000e-01, 1.71498301e-01,\n",
       "       1.71421493e-01, 1.68347498e-01, 1.78016289e-01, 1.72753810e-01])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_rf_i.cv_results_['mean_test_f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_average_precision</th>\n",
       "      <th>mean_train_average_precision</th>\n",
       "      <th>std_test_average_precision</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>mean_train_f1</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>mean_train_recall</th>\n",
       "      <th>mean_test_precision</th>\n",
       "      <th>mean_train_precision</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.168295</td>\n",
       "      <td>0.252143</td>\n",
       "      <td>0.065338</td>\n",
       "      <td>0.178633</td>\n",
       "      <td>0.195484</td>\n",
       "      <td>0.833467</td>\n",
       "      <td>0.911050</td>\n",
       "      <td>0.100084</td>\n",
       "      <td>0.109512</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>balanced</td>\n",
       "      <td>9.831347</td>\n",
       "      <td>0.609059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.192001</td>\n",
       "      <td>0.296008</td>\n",
       "      <td>0.067369</td>\n",
       "      <td>0.178016</td>\n",
       "      <td>0.193086</td>\n",
       "      <td>0.876086</td>\n",
       "      <td>0.950588</td>\n",
       "      <td>0.099215</td>\n",
       "      <td>0.107501</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>20.389284</td>\n",
       "      <td>0.823479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.125873</td>\n",
       "      <td>0.121584</td>\n",
       "      <td>0.023690</td>\n",
       "      <td>0.175829</td>\n",
       "      <td>0.169374</td>\n",
       "      <td>0.747153</td>\n",
       "      <td>0.730210</td>\n",
       "      <td>0.100738</td>\n",
       "      <td>0.096978</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>5.209566</td>\n",
       "      <td>0.500838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.194746</td>\n",
       "      <td>0.303931</td>\n",
       "      <td>0.086221</td>\n",
       "      <td>0.174727</td>\n",
       "      <td>0.194426</td>\n",
       "      <td>0.839797</td>\n",
       "      <td>0.940559</td>\n",
       "      <td>0.097616</td>\n",
       "      <td>0.108430</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>balanced</td>\n",
       "      <td>21.871230</td>\n",
       "      <td>0.911849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.182073</td>\n",
       "      <td>0.288337</td>\n",
       "      <td>0.064492</td>\n",
       "      <td>0.174641</td>\n",
       "      <td>0.197478</td>\n",
       "      <td>0.836582</td>\n",
       "      <td>0.925983</td>\n",
       "      <td>0.097645</td>\n",
       "      <td>0.110542</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>balanced</td>\n",
       "      <td>17.510272</td>\n",
       "      <td>0.841967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.164862</td>\n",
       "      <td>0.269002</td>\n",
       "      <td>0.078019</td>\n",
       "      <td>0.174377</td>\n",
       "      <td>0.185634</td>\n",
       "      <td>0.839074</td>\n",
       "      <td>0.890034</td>\n",
       "      <td>0.097572</td>\n",
       "      <td>0.103656</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>18.485956</td>\n",
       "      <td>0.806917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.168997</td>\n",
       "      <td>0.265954</td>\n",
       "      <td>0.060065</td>\n",
       "      <td>0.173566</td>\n",
       "      <td>0.193580</td>\n",
       "      <td>0.852190</td>\n",
       "      <td>0.934475</td>\n",
       "      <td>0.096695</td>\n",
       "      <td>0.108077</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>balanced</td>\n",
       "      <td>14.890866</td>\n",
       "      <td>0.759838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.167534</td>\n",
       "      <td>0.202379</td>\n",
       "      <td>0.067658</td>\n",
       "      <td>0.173427</td>\n",
       "      <td>0.174849</td>\n",
       "      <td>0.819645</td>\n",
       "      <td>0.830123</td>\n",
       "      <td>0.097145</td>\n",
       "      <td>0.097726</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>13.179725</td>\n",
       "      <td>0.741944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.154186</td>\n",
       "      <td>0.250003</td>\n",
       "      <td>0.062203</td>\n",
       "      <td>0.173065</td>\n",
       "      <td>0.184985</td>\n",
       "      <td>0.873225</td>\n",
       "      <td>0.921615</td>\n",
       "      <td>0.096131</td>\n",
       "      <td>0.102846</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>balanced</td>\n",
       "      <td>15.683378</td>\n",
       "      <td>0.799435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.158724</td>\n",
       "      <td>0.247207</td>\n",
       "      <td>0.061817</td>\n",
       "      <td>0.172958</td>\n",
       "      <td>0.193453</td>\n",
       "      <td>0.831058</td>\n",
       "      <td>0.925248</td>\n",
       "      <td>0.096727</td>\n",
       "      <td>0.108244</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>10.153089</td>\n",
       "      <td>0.609924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.171221</td>\n",
       "      <td>0.218434</td>\n",
       "      <td>0.064229</td>\n",
       "      <td>0.172910</td>\n",
       "      <td>0.180526</td>\n",
       "      <td>0.825616</td>\n",
       "      <td>0.845369</td>\n",
       "      <td>0.096712</td>\n",
       "      <td>0.101095</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>14.855491</td>\n",
       "      <td>0.755068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.198309</td>\n",
       "      <td>0.296253</td>\n",
       "      <td>0.087909</td>\n",
       "      <td>0.172754</td>\n",
       "      <td>0.194586</td>\n",
       "      <td>0.834715</td>\n",
       "      <td>0.922751</td>\n",
       "      <td>0.096517</td>\n",
       "      <td>0.108783</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>20.587648</td>\n",
       "      <td>0.589378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.169483</td>\n",
       "      <td>0.224426</td>\n",
       "      <td>0.080482</td>\n",
       "      <td>0.172453</td>\n",
       "      <td>0.174354</td>\n",
       "      <td>0.820181</td>\n",
       "      <td>0.826424</td>\n",
       "      <td>0.096437</td>\n",
       "      <td>0.097480</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>balanced</td>\n",
       "      <td>15.560883</td>\n",
       "      <td>0.833543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.158736</td>\n",
       "      <td>0.234045</td>\n",
       "      <td>0.082805</td>\n",
       "      <td>0.172391</td>\n",
       "      <td>0.180894</td>\n",
       "      <td>0.831679</td>\n",
       "      <td>0.872136</td>\n",
       "      <td>0.096269</td>\n",
       "      <td>0.100979</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>12.810071</td>\n",
       "      <td>0.702983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.178032</td>\n",
       "      <td>0.187470</td>\n",
       "      <td>0.075633</td>\n",
       "      <td>0.172189</td>\n",
       "      <td>0.174824</td>\n",
       "      <td>0.808414</td>\n",
       "      <td>0.831127</td>\n",
       "      <td>0.096438</td>\n",
       "      <td>0.097713</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>balanced</td>\n",
       "      <td>13.484461</td>\n",
       "      <td>0.948530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.157075</td>\n",
       "      <td>0.204474</td>\n",
       "      <td>0.047792</td>\n",
       "      <td>0.172074</td>\n",
       "      <td>0.174229</td>\n",
       "      <td>0.781661</td>\n",
       "      <td>0.804204</td>\n",
       "      <td>0.096775</td>\n",
       "      <td>0.097709</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>16.728168</td>\n",
       "      <td>1.359916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.184135</td>\n",
       "      <td>0.236544</td>\n",
       "      <td>0.078942</td>\n",
       "      <td>0.172024</td>\n",
       "      <td>0.179605</td>\n",
       "      <td>0.826778</td>\n",
       "      <td>0.852724</td>\n",
       "      <td>0.096120</td>\n",
       "      <td>0.100375</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>17.926673</td>\n",
       "      <td>0.816380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.144614</td>\n",
       "      <td>0.205628</td>\n",
       "      <td>0.033565</td>\n",
       "      <td>0.171989</td>\n",
       "      <td>0.173390</td>\n",
       "      <td>0.784605</td>\n",
       "      <td>0.803558</td>\n",
       "      <td>0.096672</td>\n",
       "      <td>0.097195</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>12.472715</td>\n",
       "      <td>0.662054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.168047</td>\n",
       "      <td>0.223057</td>\n",
       "      <td>0.059019</td>\n",
       "      <td>0.171985</td>\n",
       "      <td>0.182630</td>\n",
       "      <td>0.839978</td>\n",
       "      <td>0.888094</td>\n",
       "      <td>0.096018</td>\n",
       "      <td>0.101806</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>balanced</td>\n",
       "      <td>11.415544</td>\n",
       "      <td>0.703289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.165987</td>\n",
       "      <td>0.263017</td>\n",
       "      <td>0.089421</td>\n",
       "      <td>0.171498</td>\n",
       "      <td>0.192821</td>\n",
       "      <td>0.829632</td>\n",
       "      <td>0.919944</td>\n",
       "      <td>0.095746</td>\n",
       "      <td>0.107731</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>balanced_subsample</td>\n",
       "      <td>12.595621</td>\n",
       "      <td>0.650996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_test_average_precision  mean_train_average_precision  \\\n",
       "74                      0.168295                      0.252143   \n",
       "118                     0.192001                      0.296008   \n",
       "81                      0.125873                      0.121584   \n",
       "79                      0.194746                      0.303931   \n",
       "77                      0.182073                      0.288337   \n",
       "110                     0.164862                      0.269002   \n",
       "76                      0.168997                      0.265954   \n",
       "94                      0.167534                      0.202379   \n",
       "69                      0.154186                      0.250003   \n",
       "114                     0.158724                      0.247207   \n",
       "100                     0.171221                      0.218434   \n",
       "119                     0.198309                      0.296253   \n",
       "55                      0.169483                      0.224426   \n",
       "99                      0.158736                      0.234045   \n",
       "54                      0.178032                      0.187470   \n",
       "95                      0.157075                      0.204474   \n",
       "103                     0.184135                      0.236544   \n",
       "93                      0.144614                      0.205628   \n",
       "67                      0.168047                      0.223057   \n",
       "115                     0.165987                      0.263017   \n",
       "\n",
       "     std_test_average_precision  mean_test_f1  mean_train_f1  \\\n",
       "74                     0.065338      0.178633       0.195484   \n",
       "118                    0.067369      0.178016       0.193086   \n",
       "81                     0.023690      0.175829       0.169374   \n",
       "79                     0.086221      0.174727       0.194426   \n",
       "77                     0.064492      0.174641       0.197478   \n",
       "110                    0.078019      0.174377       0.185634   \n",
       "76                     0.060065      0.173566       0.193580   \n",
       "94                     0.067658      0.173427       0.174849   \n",
       "69                     0.062203      0.173065       0.184985   \n",
       "114                    0.061817      0.172958       0.193453   \n",
       "100                    0.064229      0.172910       0.180526   \n",
       "119                    0.087909      0.172754       0.194586   \n",
       "55                     0.080482      0.172453       0.174354   \n",
       "99                     0.082805      0.172391       0.180894   \n",
       "54                     0.075633      0.172189       0.174824   \n",
       "95                     0.047792      0.172074       0.174229   \n",
       "103                    0.078942      0.172024       0.179605   \n",
       "93                     0.033565      0.171989       0.173390   \n",
       "67                     0.059019      0.171985       0.182630   \n",
       "115                    0.089421      0.171498       0.192821   \n",
       "\n",
       "     mean_test_recall  mean_train_recall  mean_test_precision  \\\n",
       "74           0.833467           0.911050             0.100084   \n",
       "118          0.876086           0.950588             0.099215   \n",
       "81           0.747153           0.730210             0.100738   \n",
       "79           0.839797           0.940559             0.097616   \n",
       "77           0.836582           0.925983             0.097645   \n",
       "110          0.839074           0.890034             0.097572   \n",
       "76           0.852190           0.934475             0.096695   \n",
       "94           0.819645           0.830123             0.097145   \n",
       "69           0.873225           0.921615             0.096131   \n",
       "114          0.831058           0.925248             0.096727   \n",
       "100          0.825616           0.845369             0.096712   \n",
       "119          0.834715           0.922751             0.096517   \n",
       "55           0.820181           0.826424             0.096437   \n",
       "99           0.831679           0.872136             0.096269   \n",
       "54           0.808414           0.831127             0.096438   \n",
       "95           0.781661           0.804204             0.096775   \n",
       "103          0.826778           0.852724             0.096120   \n",
       "93           0.784605           0.803558             0.096672   \n",
       "67           0.839978           0.888094             0.096018   \n",
       "115          0.829632           0.919944             0.095746   \n",
       "\n",
       "     mean_train_precision param_max_depth param_n_estimators  \\\n",
       "74               0.109512              11                  5   \n",
       "118              0.107501              11                 13   \n",
       "81               0.096978               3                  3   \n",
       "79               0.108430              11                 15   \n",
       "77               0.110542              11                 11   \n",
       "110              0.103656               9                 13   \n",
       "76               0.108077              11                  9   \n",
       "94               0.097726               5                 13   \n",
       "69               0.102846               9                 11   \n",
       "114              0.108244              11                  5   \n",
       "100              0.101095               7                  9   \n",
       "119              0.108783              11                 15   \n",
       "55               0.097480               5                 15   \n",
       "99               0.100979               7                  7   \n",
       "54               0.097713               5                 13   \n",
       "95               0.097709               5                 15   \n",
       "103              0.100375               7                 15   \n",
       "93               0.097195               5                 11   \n",
       "67               0.101806               9                  7   \n",
       "115              0.107731              11                  7   \n",
       "\n",
       "     param_class_weight  mean_fit_time  mean_score_time  \n",
       "74             balanced       9.831347         0.609059  \n",
       "118  balanced_subsample      20.389284         0.823479  \n",
       "81   balanced_subsample       5.209566         0.500838  \n",
       "79             balanced      21.871230         0.911849  \n",
       "77             balanced      17.510272         0.841967  \n",
       "110  balanced_subsample      18.485956         0.806917  \n",
       "76             balanced      14.890866         0.759838  \n",
       "94   balanced_subsample      13.179725         0.741944  \n",
       "69             balanced      15.683378         0.799435  \n",
       "114  balanced_subsample      10.153089         0.609924  \n",
       "100  balanced_subsample      14.855491         0.755068  \n",
       "119  balanced_subsample      20.587648         0.589378  \n",
       "55             balanced      15.560883         0.833543  \n",
       "99   balanced_subsample      12.810071         0.702983  \n",
       "54             balanced      13.484461         0.948530  \n",
       "95   balanced_subsample      16.728168         1.359916  \n",
       "103  balanced_subsample      17.926673         0.816380  \n",
       "93   balanced_subsample      12.472715         0.662054  \n",
       "67             balanced      11.415544         0.703289  \n",
       "115  balanced_subsample      12.595621         0.650996  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['mean_test_average_precision','mean_train_average_precision','std_test_average_precision',\\\n",
    "        'mean_test_f1','mean_train_f1',\\\n",
    "        'mean_test_recall','mean_train_recall','mean_test_precision','mean_train_precision',\\\n",
    "        'param_max_depth','param_n_estimators','param_class_weight',\\\n",
    "        'mean_fit_time','mean_score_time']\n",
    "# Delay GridSearchCV\n",
    "grid_rf_df_i = pd.DataFrame(grid_rf_i.cv_results_)[cols].sort_values(by='mean_test_f1', ascending=False)\n",
    "grid_rf_df_i.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under PR Curve: 0.210\n"
     ]
    }
   ],
   "source": [
    "# going with (115) because decent AP, highest f1 and high recall, precision similar to other and good 'fit_time'\n",
    "forest_final_i = RandomForestClassifier(criterion='gini', max_depth=11, n_estimators=7, random_state=0, class_weight='balanced_subsample')\n",
    "# fit\n",
    "forest_final_i.fit(X_tr_arr, y_tr_arr_imp_delay_binary)\n",
    "# predict\n",
    "y_pred_forest_va_final_i = forest_final_i.predict(X_va_arr_reindex) # prediction delay\n",
    "# predict probabilities\n",
    "forest_final_probs_i = forest_final_i.predict_proba(X_va_arr_reindex)\n",
    "# keep probabilities for the positive outcome only\n",
    "forest_final_probs_pos_i = forest_final_probs_i[:,1]\n",
    "# Precision-recall curve metrics\n",
    "rf_precision_final_i, rf_recall_final_i, rf_thres_final_i = precision_recall_curve(y_va_arr_imp_delay_binary, forest_final_probs_pos_i, pos_label=1)\n",
    "rf_final_auprc_i = auc(rf_recall_final_i, rf_precision_final_i)\n",
    "print('Area Under PR Curve: {:.3f}'.format(rf_final_auprc_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best threshold (RandomForest - Important delay) <a name='rf_imp_delay_thres' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.661\n",
      "Probabilities: [0.59382634 0.59388932 0.63350715 0.63357013 0.6942393  0.64640551\n",
      " 0.66201457 0.66201457 0.64640551 0.65523314]\n",
      "Predictions: [0 0 0 0 1 0 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from numpy import argmax\n",
    "fscores_rf_i = (2 * rf_precision_final_i * rf_recall_final_i) / (rf_precision_final_i + rf_recall_final_i)\n",
    "rf_bt_i = rf_thres_final_i[argmax(fscores_rf_i)]\n",
    "print('Best Threshold: {:.3f}'.format(rf_bt_i))\n",
    "# use threshold in model\n",
    "rf_final_curve_i = np.where(forest_final_probs_i[:,1] > rf_bt_i, 1,0)\n",
    "print('Probabilities:',forest_final_probs_i[0:10,1])\n",
    "print('Predictions:',rf_final_curve_i[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report (RandomForest - Important delay) <a name='rf_imp_delay_report' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: RandomForest important delay\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       no_delay       0.96      0.94      0.95    103481\n",
      "important_delay       0.22      0.32      0.26      5239\n",
      "\n",
      "       accuracy                           0.91    108720\n",
      "      macro avg       0.59      0.63      0.61    108720\n",
      "   weighted avg       0.93      0.91      0.92    108720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: RandomForest important delay')\n",
    "report_forest_final_i= classification_report(y_true=y_va_arr_imp_delay_binary, y_pred=rf_final_curve_i, target_names=['no_delay','important_delay'])\n",
    "print(report_forest_final_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix (RandomForest - Important delay) <a name='rf_imp_delay_matrix' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (normalized): RandomForest important delay\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred: no delay</th>\n",
       "      <th>pred: important delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true: no delay</th>\n",
       "      <td>0.75826</td>\n",
       "      <td>0.03876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true: important delay</th>\n",
       "      <td>0.17099</td>\n",
       "      <td>0.03199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       pred: no delay  pred: important delay\n",
       "true: no delay                0.75826                0.03876\n",
       "true: important delay         0.17099                0.03199"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix 'RF important delay'\n",
    "matrix_rf_d = confusion_matrix(y_true=y_va_arr_delay_binary, y_pred=rf_final_curve_i,normalize='all') # normalize either on columns/rows or all\n",
    "matrix_rf_d = pd.DataFrame(\n",
    "    matrix_rf_d, \n",
    "    columns=['pred: no delay', 'pred: important delay'],\n",
    "    index=['true: no delay', 'true: important delay']\n",
    ")\n",
    "print('Confusion matrix (normalized): RandomForest important delay')\n",
    "matrix_rf_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass imbalanced (RandomForest) <a name='rf_multi_report' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_arr_delay_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_arr_imp_delay_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_arr_delay_multi = y_tr_arr_delay_binary + y_tr_arr_imp_delay_binary\n",
    "y_va_arr_delay_multi = y_va_arr_delay_binary + y_va_arr_imp_delay_binary\n",
    "y_te_arr_delay_multi = y_te_arr_delay_binary + y_te_arr_imp_delay_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8031456953642384"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_multi = RandomForestClassifier()\n",
    "# could grid search class_weight\n",
    "forest_multi.fit(X_tr_arr, y_tr_arr_delay_multi)\n",
    "forest_multi.score(X_va_arr_reindex, y_va_arr_delay_multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "y_pred_va_forest_multi = forest_multi.predict(X_va_arr_reindex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report (RandomForest - Multiclass) <a name='rf_multi_report' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       no_delay       0.86      0.92      0.89     86652\n",
      "          delay       0.48      0.42      0.45     16829\n",
      "important_delay       0.42      0.14      0.21      5239\n",
      "\n",
      "       accuracy                           0.80    108720\n",
      "      macro avg       0.59      0.49      0.52    108720\n",
      "   weighted avg       0.78      0.80      0.79    108720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_forest_multi = classification_report(y_true=y_va_arr_delay_multi, y_pred=y_pred_va_forest_multi, target_names=['no_delay','delay','important_delay'])\n",
    "print(report_forest_multi)\n",
    "# why f1-score better for \"important delay\" in multi-class over binary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53532143, 0.        , 0.46467857],\n",
       "       [0.48022884, 0.01602116, 0.50375   ],\n",
       "       [0.82444558, 0.17555442, 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.2524197 , 0.45168522, 0.29589508],\n",
       "       [0.69373977, 0.05986292, 0.24639731],\n",
       "       [0.4803979 , 0.2495473 , 0.27005479],\n",
       "       [0.40829106, 0.34802075, 0.24368818],\n",
       "       [0.64545499, 0.1033296 , 0.25121541],\n",
       "       [0.64655107, 0.10416936, 0.24927957]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_multi.predict_proba(X_va_arr_reindex)[0:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_va_forest_multi[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37286661068985616"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_final_i.predict_proba(X_va_arr_reindex)[:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_forest_va_final_i[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix (RandomForest - Multiclass) <a name='rf_multi_matrix' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (normalized): RandomForest important delay multi\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred: no delay</th>\n",
       "      <th>pred: delay</th>\n",
       "      <th>pred: imp delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true: no delay</th>\n",
       "      <td>0.730740</td>\n",
       "      <td>0.059796</td>\n",
       "      <td>0.006485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred: delay</th>\n",
       "      <td>0.086231</td>\n",
       "      <td>0.065508</td>\n",
       "      <td>0.003054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true: imp delay</th>\n",
       "      <td>0.030951</td>\n",
       "      <td>0.010338</td>\n",
       "      <td>0.006898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pred: no delay  pred: delay  pred: imp delay\n",
       "true: no delay         0.730740     0.059796         0.006485\n",
       "pred: delay            0.086231     0.065508         0.003054\n",
       "true: imp delay        0.030951     0.010338         0.006898"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix 'RF multi important delay'\n",
    "matrix_rf_multi = confusion_matrix(y_true=y_va_arr_delay_multi, y_pred=y_pred_va_forest_multi,normalize='all') # normalize either on columns/rows or all\n",
    "matrix_rf_multi = pd.DataFrame(\n",
    "    matrix_rf_multi, \n",
    "    columns=['pred: no delay','pred: delay', 'pred: imp delay'],\n",
    "    index=['true: no delay','pred: delay', 'true: imp delay']\n",
    ")\n",
    "print('Confusion matrix (normalized): RandomForest important delay multi')\n",
    "matrix_rf_multi\n",
    "# multi class seems to be overperforming on almost all classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments (RandomForest):**\n",
    "* Classifier seems to be performing especially well with the more imbalanced data set, reaching f1 score of 0.26 while f1 score for delay is slightly below other top performing classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance on test set (RandomForest) <a name='rf_test' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under PR Curve: 0.583\n",
      "Classification report: RandomForest TEST delay\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    no_delay       0.89      0.77      0.82     80088\n",
      "       delay       0.51      0.71      0.60     27278\n",
      "\n",
      "    accuracy                           0.75    107366\n",
      "   macro avg       0.70      0.74      0.71    107366\n",
      "weighted avg       0.79      0.75      0.76    107366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# delay\n",
    "rf_test_probs_pos_d = forest_final_d.predict_proba(X_te_arr_reindex)[:,1]\n",
    "rf_precision_test_d, rf_recall_test_d, _ = precision_recall_curve(y_te_arr_delay_binary, rf_test_probs_pos_d, pos_label=1)\n",
    "rf_test_auc_pr_d = auc(rf_recall_test_d, rf_precision_test_d)\n",
    "print('Area Under PR Curve: {:.3f}'.format(rf_test_auc_pr_d))\n",
    "# use threshold\n",
    "rf_test_d = np.where(forest_final_d.predict_proba(X_te_arr_reindex)[:,1] > rf_bt_d, 1,0)\n",
    "print('Classification report: RandomForest TEST delay')\n",
    "report_rf_d= classification_report(y_true=y_te_arr_delay_binary, y_pred=rf_test_d, target_names=['no_delay','delay'])\n",
    "f1_rf_test_d = classification_report(y_true=y_te_arr_delay_binary, y_pred=rf_test_d, target_names=['no_delay','delay'], output_dict=True)['delay']['f1-score']\n",
    "precision_rf_test_d = classification_report(y_true=y_te_arr_delay_binary, y_pred=rf_test_d, target_names=['no_delay','delay'], output_dict=True)['delay']['precision']\n",
    "recall_rf_test_d = classification_report(y_true=y_te_arr_delay_binary, y_pred=rf_test_d, target_names=['no_delay','delay'], output_dict=True)['delay']['recall']\n",
    "print(report_rf_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under PR Curve: 0.263\n",
      "Classification report: RandomForest TEST Important delay\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       no_delay       0.95      0.95      0.95    100362\n",
      "important_delay       0.29      0.30      0.30      7004\n",
      "\n",
      "       accuracy                           0.91    107366\n",
      "      macro avg       0.62      0.63      0.62    107366\n",
      "   weighted avg       0.91      0.91      0.91    107366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# important delay\n",
    "rf_test_probs_pos_i = forest_final_i.predict_proba(X_te_arr_reindex)[:,1]\n",
    "rf_precision_test_i, rf_recall_test_i, _ = precision_recall_curve(y_te_arr_imp_delay_binary, rf_test_probs_pos_i, pos_label=1)\n",
    "rf_test_auc_pr_i = auc(rf_recall_test_i, rf_precision_test_i)\n",
    "print('Area Under PR Curve: {:.3f}'.format(rf_test_auc_pr_i))\n",
    "# use threshold\n",
    "rf_test_i = np.where(forest_final_i.predict_proba(X_te_arr_reindex)[:,1] > rf_bt_i, 1,0)\n",
    "print('Classification report: RandomForest TEST Important delay')\n",
    "report_rf_i= classification_report(y_true=y_te_arr_imp_delay_binary, y_pred=rf_test_i, target_names=['no_delay','important_delay'])\n",
    "f1_rf_test_i = classification_report(y_true=y_te_arr_imp_delay_binary, y_pred=rf_test_i, target_names=['no_delay','important_delay'], output_dict=True)['important_delay']['f1-score']\n",
    "precision_rf_test_i = classification_report(y_true=y_te_arr_imp_delay_binary, y_pred=rf_test_i, target_names=['no_delay','important_delay'], output_dict=True)['important_delay']['precision']\n",
    "recall_rf_test_i = classification_report(y_true=y_te_arr_imp_delay_binary, y_pred=rf_test_i, target_names=['no_delay','important_delay'], output_dict=True)['important_delay']['recall']\n",
    "print(report_rf_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: RandomForest TEST Multiclass delay\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       no_delay       0.82      0.93      0.87     80088\n",
      "          delay       0.54      0.39      0.45     20274\n",
      "important_delay       0.47      0.12      0.19      7004\n",
      "\n",
      "       accuracy                           0.78    107366\n",
      "      macro avg       0.61      0.48      0.50    107366\n",
      "   weighted avg       0.74      0.78      0.75    107366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# multiclass delay\n",
    "y_pred_rf_test_m = forest_multi.predict(X_te_arr_reindex) # prediction delay\n",
    "print('Classification report: RandomForest TEST Multiclass delay')\n",
    "report_rf_m= classification_report(y_true=y_te_arr_delay_multi, y_pred=y_pred_rf_test_m, target_names=['no_delay','delay','important_delay'])\n",
    "f1_rf_test_m = classification_report(y_true=y_te_arr_delay_multi, y_pred=y_pred_rf_test_m, target_names=['no_delay','delay','important_delay'], output_dict=True)['important_delay']['f1-score']\n",
    "precision_rf_test_m = classification_report(y_true=y_te_arr_delay_multi, y_pred=y_pred_rf_test_m, target_names=['no_delay','delay','important_delay'], output_dict=True)['important_delay']['precision']\n",
    "recall_rf_test_m = classification_report(y_true=y_te_arr_delay_multi, y_pred=y_pred_rf_test_m, target_names=['no_delay','delay','important_delay'], output_dict=True)['important_delay']['recall']\n",
    "print(report_rf_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V) Keras (with class_weight) <a name='keras' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# had to install latest version of tensorflow to get below metrics\n",
    "# https://www.tensorflow.org/tutorials/structured_data/imbalanced_data\n",
    "# https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "metrics = [\n",
    "      metrics.TruePositives(name='tp'),\n",
    "      metrics.FalsePositives(name='fp'),\n",
    "      metrics.TrueNegatives(name='tn'),\n",
    "      metrics.FalseNegatives(name='fn'), \n",
    "      metrics.BinaryAccuracy(name='accuracy'),\n",
    "      metrics.Precision(name='precision'),\n",
    "      metrics.Recall(name='recall'),\n",
    "      metrics.AUC(name='auc'),\n",
    "      metrics.AUC(name='prc', curve='PR'), # precision-recall curve,\n",
    "      f1_m\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delay:\n",
      "    Total: 215050\n",
      "    Positive: 49154 (22.86% of total)\n",
      "\n",
      "Important delay:\n",
      "    Total: 215050\n",
      "    Positive: 11217 (5.22% of total)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "neg_d, pos_d = np.bincount(y_tr_arr_delay_binary)\n",
    "total_d = neg_d + pos_d\n",
    "print('Delay:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total_d, pos_d, 100 * pos_d / total_d))\n",
    "neg_i, pos_i = np.bincount(y_tr_arr_imp_delay_binary)\n",
    "total_i = neg_i + pos_i\n",
    "print('Important delay:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total_i, pos_i, 100 * pos_i / total_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delay <a name='keras_delay' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class no_delay: 0.65\n",
      "Weight for class delay: 2.19\n"
     ]
    }
   ],
   "source": [
    "# Scaling by total/2 to help keep loss to similar magnitude\n",
    "weight_no_delay_d = (1 / neg_d)*(total_d)/2.0\n",
    "weight_delay = (1 / pos_d)*(total_d)/2.0\n",
    "\n",
    "class_weight_d = {0: weight_no_delay_d, 1: weight_delay}\n",
    "\n",
    "print('Weight for class no_delay: {:.2f}'.format(weight_no_delay_d))\n",
    "print('Weight for class delay: {:.2f}'.format(weight_delay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                6960      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 6,977\n",
      "Trainable params: 6,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# class weight model\n",
    "cw_model = Sequential()\n",
    "cw_model.add(Dense(16, activation='relu', input_dim=X_tr_arr.shape[1]))\n",
    "cw_model.add(Dropout(0.5))\n",
    "cw_model.add(Dense(1, activation='sigmoid', bias_initializer=None))\n",
    "\n",
    "cw_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "    loss='BinaryCrossentropy',\n",
    "    metrics=metrics)\n",
    "\n",
    "cw_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define if want to add \"initial_weights\"\n",
    "# model.load_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit model (Keras - Delay) <a name='keras_delay_fit' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "108/108 [==============================] - 6s 29ms/step - loss: 0.4962 - tp: 22032.1651 - fp: 33898.7798 - tn: 51055.9908 - fn: 2977.2844 - accuracy: 0.6762 - precision: 0.3979 - recall: 0.8233 - auc: 0.8154 - prc: 0.5154 - f1_m: 0.5176 - val_loss: 0.4798 - val_tp: 19937.0000 - val_fp: 31940.0000 - val_tn: 54712.0000 - val_fn: 2131.0000 - val_accuracy: 0.6866 - val_precision: 0.3843 - val_recall: 0.9034 - val_auc: 0.8518 - val_prc: 0.5708 - val_f1_m: 0.4707\n",
      "Epoch 2/30\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.4427 - tp: 23343.5046 - fp: 34621.3670 - tn: 50146.4587 - fn: 1852.8899 - accuracy: 0.6731 - precision: 0.4074 - recall: 0.9213 - auc: 0.8529 - prc: 0.6009 - f1_m: 0.5673 - val_loss: 0.4640 - val_tp: 19718.0000 - val_fp: 30751.0000 - val_tn: 55901.0000 - val_fn: 2350.0000 - val_accuracy: 0.6955 - val_precision: 0.3907 - val_recall: 0.8935 - val_auc: 0.8509 - val_prc: 0.5681 - val_f1_m: 0.4717\n",
      "Epoch 3/30\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.4427 - tp: 23745.7064 - fp: 36298.3394 - tn: 48467.1743 - fn: 1453.0000 - accuracy: 0.6665 - precision: 0.4026 - recall: 0.9311 - auc: 0.8528 - prc: 0.5972 - f1_m: 0.5637 - val_loss: 0.4904 - val_tp: 21474.0000 - val_fp: 39946.0000 - val_tn: 46706.0000 - val_fn: 594.0000 - val_accuracy: 0.6271 - val_precision: 0.3496 - val_recall: 0.9731 - val_auc: 0.8539 - val_prc: 0.5775 - val_f1_m: 0.4526\n",
      "Epoch 4/30\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.4405 - tp: 24571.8165 - fp: 39987.8440 - tn: 44796.1927 - fn: 608.3670 - accuracy: 0.6276 - precision: 0.3787 - recall: 0.9801 - auc: 0.8556 - prc: 0.6043 - f1_m: 0.5467 - val_loss: 0.4660 - val_tp: 21576.0000 - val_fp: 40369.0000 - val_tn: 46283.0000 - val_fn: 492.0000 - val_accuracy: 0.6242 - val_precision: 0.3483 - val_recall: 0.9777 - val_auc: 0.8505 - val_prc: 0.5713 - val_f1_m: 0.4598\n",
      "Epoch 5/30\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.4398 - tp: 23638.4954 - fp: 36445.4037 - tn: 48399.6514 - fn: 1480.6697 - accuracy: 0.6525 - precision: 0.3922 - recall: 0.9438 - auc: 0.8545 - prc: 0.6072 - f1_m: 0.5564 - val_loss: 0.4671 - val_tp: 21482.0000 - val_fp: 40619.0000 - val_tn: 46033.0000 - val_fn: 586.0000 - val_accuracy: 0.6210 - val_precision: 0.3459 - val_recall: 0.9734 - val_auc: 0.8530 - val_prc: 0.5790 - val_f1_m: 0.4486\n",
      "Epoch 6/30\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.4411 - tp: 24212.2294 - fp: 38050.8899 - tn: 46714.4862 - fn: 986.6147 - accuracy: 0.6402 - precision: 0.3859 - recall: 0.9671 - auc: 0.8552 - prc: 0.6025 - f1_m: 0.5531 - val_loss: 0.4875 - val_tp: 21344.0000 - val_fp: 39300.0000 - val_tn: 47352.0000 - val_fn: 724.0000 - val_accuracy: 0.6319 - val_precision: 0.3520 - val_recall: 0.9672 - val_auc: 0.8522 - val_prc: 0.5748 - val_f1_m: 0.4532\n",
      "Epoch 7/30\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.4404 - tp: 24521.9358 - fp: 39418.0459 - tn: 45387.1651 - fn: 637.0734 - accuracy: 0.6328 - precision: 0.3827 - recall: 0.9784 - auc: 0.8548 - prc: 0.6052 - f1_m: 0.5506 - val_loss: 0.4532 - val_tp: 20833.0000 - val_fp: 36563.0000 - val_tn: 50089.0000 - val_fn: 1235.0000 - val_accuracy: 0.6523 - val_precision: 0.3630 - val_recall: 0.9440 - val_auc: 0.8514 - val_prc: 0.5751 - val_f1_m: 0.4600\n",
      "Epoch 8/30\n",
      "108/108 [==============================] - 1s 13ms/step - loss: 0.4408 - tp: 24716.6606 - fp: 39986.4404 - tn: 44751.3119 - fn: 509.8073 - accuracy: 0.6309 - precision: 0.3824 - recall: 0.9802 - auc: 0.8550 - prc: 0.6075 - f1_m: 0.5501 - val_loss: 0.5038 - val_tp: 20996.0000 - val_fp: 37023.0000 - val_tn: 49629.0000 - val_fn: 1072.0000 - val_accuracy: 0.6496 - val_precision: 0.3619 - val_recall: 0.9514 - val_auc: 0.8540 - val_prc: 0.5809 - val_f1_m: 0.4604\n",
      "Epoch 9/30\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.4404 - tp: 24675.3670 - fp: 40363.8349 - tn: 44485.5138 - fn: 439.5046 - accuracy: 0.6286 - precision: 0.3790 - recall: 0.9815 - auc: 0.8536 - prc: 0.6048 - f1_m: 0.5467 - val_loss: 0.4679 - val_tp: 21308.0000 - val_fp: 38844.0000 - val_tn: 47808.0000 - val_fn: 760.0000 - val_accuracy: 0.6357 - val_precision: 0.3542 - val_recall: 0.9656 - val_auc: 0.8529 - val_prc: 0.5789 - val_f1_m: 0.4555\n",
      "Epoch 10/30\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.4397 - tp: 24487.0826 - fp: 39620.1927 - tn: 45192.1468 - fn: 664.7982 - accuracy: 0.6370 - precision: 0.3838 - recall: 0.9675 - auc: 0.8539 - prc: 0.6103 - f1_m: 0.5504 - val_loss: 0.4599 - val_tp: 20968.0000 - val_fp: 36967.0000 - val_tn: 49685.0000 - val_fn: 1100.0000 - val_accuracy: 0.6499 - val_precision: 0.3619 - val_recall: 0.9502 - val_auc: 0.8544 - val_prc: 0.5796 - val_f1_m: 0.4595\n",
      "Epoch 11/30\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.4378 - tp: 24038.9450 - fp: 37844.5505 - tn: 47053.3761 - fn: 1027.3486 - accuracy: 0.6456 - precision: 0.3884 - recall: 0.9610 - auc: 0.8556 - prc: 0.6096 - f1_m: 0.5545 - val_loss: 0.4566 - val_tp: 21272.0000 - val_fp: 38329.0000 - val_tn: 48323.0000 - val_fn: 796.0000 - val_accuracy: 0.6401 - val_precision: 0.3569 - val_recall: 0.9639 - val_auc: 0.8535 - val_prc: 0.5802 - val_f1_m: 0.4592\n",
      "Epoch 12/30\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.4382 - tp: 24556.4495 - fp: 39787.6147 - tn: 45050.7156 - fn: 569.4404 - accuracy: 0.6330 - precision: 0.3810 - recall: 0.9770 - auc: 0.8552 - prc: 0.6091 - f1_m: 0.5485 - val_loss: 0.4592 - val_tp: 20597.0000 - val_fp: 35158.0000 - val_tn: 51494.0000 - val_fn: 1471.0000 - val_accuracy: 0.6631 - val_precision: 0.3694 - val_recall: 0.9333 - val_auc: 0.8526 - val_prc: 0.5758 - val_f1_m: 0.4629\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "b_size=2000 # important to be high enough to contain information on positive class\n",
    "e=30\n",
    "early_stop= tf.keras.callbacks.EarlyStopping(monitor='val_f1_m', verbose = 1, patience=10, mode='max', restore_best_weights=True)\n",
    "\n",
    "cw_history = cw_model.fit(\n",
    "    x=X_tr_arr, \n",
    "    y=y_tr_arr_delay_binary,\n",
    "    batch_size=b_size,\n",
    "    epochs=e,\n",
    "    callbacks=[early_stop],\n",
    "    validation_data=(X_va_arr_reindex, y_va_arr_delay_binary),\n",
    "    shuffle=True, # Shuffle training samples\n",
    "    class_weight=class_weight_d\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check training history\n",
    "def plot_metrics(history):\n",
    "  metrics = ['f1_m', 'prc', 'precision', 'recall']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric], linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "plot_metrics(cw_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9034348130226135,\n",
       " 0.8935109376907349,\n",
       " 0.9730831980705261,\n",
       " 0.9777052998542786,\n",
       " 0.97344571352005,\n",
       " 0.9671922922134399,\n",
       " 0.944036602973938,\n",
       " 0.9514228701591492,\n",
       " 0.9655609726905823,\n",
       " 0.9501540660858154,\n",
       " 0.9639296531677246,\n",
       " 0.9333423972129822]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw_history.history['val_recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "y_pred_va_keras_d = cw_model.predict(X_va_arr_reindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    no_delay       0.96      0.65      0.77     86652\n",
      "       delay       0.39      0.89      0.54     22068\n",
      "\n",
      "    accuracy                           0.70    108720\n",
      "   macro avg       0.68      0.77      0.66    108720\n",
      "weighted avg       0.84      0.70      0.73    108720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_keras_d = classification_report(y_true=y_va_arr_delay_binary, y_pred=(y_pred_va_keras_d > 0.5)*1, target_names=['no_delay','delay'])\n",
    "print(report_keras_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under PR Curve: 0.568\n"
     ]
    }
   ],
   "source": [
    "# Precision-recall curve metrics\n",
    "keras_precision_d, keras_recall_d, keras_thres_d = precision_recall_curve(y_va_arr_delay_binary, y_pred_va_keras_d, pos_label=1)\n",
    "keras_auprc_d = auc(keras_recall_d, keras_precision_d)\n",
    "print('Area Under PR Curve: {:.3f}'.format(keras_auprc_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize threshold (Keras - Delay) <a name='keras_delay_thres' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.569\n",
      "Probabilities: [[0.5925672 ]\n",
      " [0.54520875]\n",
      " [0.5689906 ]\n",
      " [0.56060505]\n",
      " [0.9215561 ]\n",
      " [0.48765883]\n",
      " [0.8491559 ]\n",
      " [0.9017005 ]\n",
      " [0.6197516 ]\n",
      " [0.5346859 ]]\n",
      "Predictions: [[1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import argmax\n",
    "fscores_keras_d = (2 * keras_precision_d * keras_recall_d) / (keras_precision_d + keras_recall_d)\n",
    "keras_bt_d = keras_thres_d[argmax(fscores_keras_d)]\n",
    "print('Best Threshold: {:.3f}'.format(keras_bt_d))\n",
    "# use threshold in model\n",
    "keras_curve_d = np.where(y_pred_va_keras_d > keras_bt_d, 1,0)\n",
    "print('Probabilities:',y_pred_va_keras_d[0:10])\n",
    "print('Predictions:',keras_curve_d[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report (Keras - Delay) <a name='keras_delay_report' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: Keras delay - optimzed threshold at 0.569 on PR curve\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    no_delay       0.92      0.78      0.84     86652\n",
      "       delay       0.45      0.73      0.56     22068\n",
      "\n",
      "    accuracy                           0.77    108720\n",
      "   macro avg       0.69      0.75      0.70    108720\n",
      "weighted avg       0.82      0.77      0.78    108720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: Keras delay - optimzed threshold at {:.3f} on PR curve'.format(keras_bt_d))\n",
    "report_keras_preds_d = classification_report(y_true=y_va_arr_delay_binary, y_pred=keras_curve_d, target_names=['no_delay','delay'])\n",
    "#f1_logreg_pr_d = classification_report(y_true=y_va_arr_delay_binary, y_pred=lr_curve_d, target_names=['no_delay','delay'], output_dict=True)['delay']['f1-score']\n",
    "print(report_keras_preds_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix (Keras - Delay) <a name='keras_delay_matrix' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (normalized): Keras delay\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred: no delay</th>\n",
       "      <th>pred: delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true: no delay</th>\n",
       "      <td>0.618561</td>\n",
       "      <td>0.178458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true: delay</th>\n",
       "      <td>0.055537</td>\n",
       "      <td>0.147443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pred: no delay  pred: delay\n",
       "true: no delay        0.618561     0.178458\n",
       "true: delay           0.055537     0.147443"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix 'RF important delay'\n",
    "matrix_keras_d = confusion_matrix(y_true=y_va_arr_delay_binary, y_pred=keras_curve_d,normalize='all') # normalize either on columns/rows or all\n",
    "matrix_keras_d = pd.DataFrame(\n",
    "    matrix_keras_d, \n",
    "    columns=['pred: no delay', 'pred: delay'],\n",
    "    index=['true: no delay', 'true: delay']\n",
    ")\n",
    "print('Confusion matrix (normalized): Keras delay')\n",
    "matrix_keras_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important delay <a name='keras_imp_delay' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class no_delay: 0.53\n",
      "Weight for class delay: 9.59\n"
     ]
    }
   ],
   "source": [
    "# Scaling by total/2 to help keep loss to similar magnitude\n",
    "weight_no_delay_i = (1 / neg_i)*(total_i)/2.0\n",
    "weight_imp_delay = (1 / pos_i)*(total_i)/2.0\n",
    "\n",
    "class_weight_i = {0: weight_no_delay_d, 1: weight_imp_delay}\n",
    "\n",
    "print('Weight for class no_delay: {:.2f}'.format(weight_no_delay_i))\n",
    "print('Weight for class delay: {:.2f}'.format(weight_imp_delay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 16)                6960      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 6,977\n",
      "Trainable params: 6,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# class weight model\n",
    "cw_model_i = Sequential()\n",
    "cw_model_i.add(Dense(16, activation='relu', input_dim=X_tr_arr.shape[1]))\n",
    "cw_model_i.add(Dropout(0.5))\n",
    "cw_model_i.add(Dense(1, activation='sigmoid', bias_initializer=None))\n",
    "\n",
    "cw_model_i.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "    loss='BinaryCrossentropy',\n",
    "    metrics=metrics)\n",
    "\n",
    "cw_model_i.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define if want to add \"initial_weights\"\n",
    "# model.load_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit model (Keras - Important delay) <a name='keras_imp_delay_fit' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "108/108 [==============================] - 5s 27ms/step - loss: 0.6069 - tp: 25774.9266 - fp: 86551.0826 - tn: 104312.0092 - fn: 2046.2018 - accuracy: 0.6008 - precision: 0.2427 - recall: 0.9267 - auc: 0.8486 - prc: 0.4748 - f1_m: 0.1600 - val_loss: 0.4868 - val_tp: 4330.0000 - val_fp: 46681.0000 - val_tn: 56800.0000 - val_fn: 909.0000 - val_accuracy: 0.5623 - val_precision: 0.0849 - val_recall: 0.8265 - val_auc: 0.7925 - val_prc: 0.2092 - val_f1_m: 0.1339\n",
      "Epoch 2/30\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.5595 - tp: 5322.7982 - fp: 50153.6789 - tn: 54023.8073 - fn: 463.9358 - accuracy: 0.5354 - precision: 0.0961 - recall: 0.9273 - auc: 0.7949 - prc: 0.2213 - f1_m: 0.1751 - val_loss: 0.5166 - val_tp: 4688.0000 - val_fp: 50842.0000 - val_tn: 52639.0000 - val_fn: 551.0000 - val_accuracy: 0.5273 - val_precision: 0.0844 - val_recall: 0.8948 - val_auc: 0.8008 - val_prc: 0.2158 - val_f1_m: 0.1374\n",
      "Epoch 3/30\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.5483 - tp: 5164.1651 - fp: 48742.1193 - tn: 55468.8624 - fn: 589.0734 - accuracy: 0.5423 - precision: 0.0945 - recall: 0.9113 - auc: 0.8024 - prc: 0.2226 - f1_m: 0.1750 - val_loss: 0.4459 - val_tp: 4615.0000 - val_fp: 49557.0000 - val_tn: 53924.0000 - val_fn: 624.0000 - val_accuracy: 0.5384 - val_precision: 0.0852 - val_recall: 0.8809 - val_auc: 0.7969 - val_prc: 0.2175 - val_f1_m: 0.1369\n",
      "Epoch 4/30\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.5478 - tp: 5450.5138 - fp: 51319.6147 - tn: 52888.4312 - fn: 305.6606 - accuracy: 0.5251 - precision: 0.0962 - recall: 0.9510 - auc: 0.8044 - prc: 0.2320 - f1_m: 0.1746 - val_loss: 0.4247 - val_tp: 2748.0000 - val_fp: 15797.0000 - val_tn: 87684.0000 - val_fn: 2491.0000 - val_accuracy: 0.8318 - val_precision: 0.1482 - val_recall: 0.5245 - val_auc: 0.7939 - val_prc: 0.2223 - val_f1_m: 0.1865\n",
      "Epoch 5/30\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.5436 - tp: 4996.5780 - fp: 46361.5963 - tn: 57889.8716 - fn: 716.1743 - accuracy: 0.5957 - precision: 0.1027 - recall: 0.8440 - auc: 0.8039 - prc: 0.2340 - f1_m: 0.1906 - val_loss: 0.4869 - val_tp: 4936.0000 - val_fp: 54538.0000 - val_tn: 48943.0000 - val_fn: 303.0000 - val_accuracy: 0.4956 - val_precision: 0.0830 - val_recall: 0.9422 - val_auc: 0.8034 - val_prc: 0.2274 - val_f1_m: 0.1347\n",
      "Epoch 6/30\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.5403 - tp: 5102.2385 - fp: 48134.6789 - tn: 56108.2294 - fn: 619.0734 - accuracy: 0.5382 - precision: 0.0945 - recall: 0.9182 - auc: 0.8034 - prc: 0.2435 - f1_m: 0.1772 - val_loss: 0.4483 - val_tp: 2904.0000 - val_fp: 17319.0000 - val_tn: 86162.0000 - val_fn: 2335.0000 - val_accuracy: 0.8192 - val_precision: 0.1436 - val_recall: 0.5543 - val_auc: 0.8001 - val_prc: 0.2260 - val_f1_m: 0.1797\n",
      "Epoch 7/30\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.5353 - tp: 4481.2569 - fp: 37852.7706 - tn: 66398.9358 - fn: 1231.2569 - accuracy: 0.6908 - precision: 0.1212 - recall: 0.7204 - auc: 0.8084 - prc: 0.2436 - f1_m: 0.2180 - val_loss: 0.4391 - val_tp: 4343.0000 - val_fp: 44249.0000 - val_tn: 59232.0000 - val_fn: 896.0000 - val_accuracy: 0.5848 - val_precision: 0.0894 - val_recall: 0.8290 - val_auc: 0.8010 - val_prc: 0.2221 - val_f1_m: 0.1413\n",
      "Epoch 8/30\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.5327 - tp: 4354.4679 - fp: 35702.2202 - tn: 68576.6422 - fn: 1330.8899 - accuracy: 0.6405 - precision: 0.1069 - recall: 0.7988 - auc: 0.8134 - prc: 0.2383 - f1_m: 0.2039 - val_loss: 0.4594 - val_tp: 4331.0000 - val_fp: 44763.0000 - val_tn: 58718.0000 - val_fn: 908.0000 - val_accuracy: 0.5799 - val_precision: 0.0882 - val_recall: 0.8267 - val_auc: 0.7989 - val_prc: 0.2202 - val_f1_m: 0.1422\n",
      "Epoch 9/30\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.5473 - tp: 4797.7982 - fp: 42515.7339 - tn: 61681.5505 - fn: 969.1376 - accuracy: 0.5795 - precision: 0.1004 - recall: 0.8683 - auc: 0.8077 - prc: 0.2438 - f1_m: 0.1918 - val_loss: 0.4813 - val_tp: 4695.0000 - val_fp: 48675.0000 - val_tn: 54806.0000 - val_fn: 544.0000 - val_accuracy: 0.5473 - val_precision: 0.0880 - val_recall: 0.8962 - val_auc: 0.8063 - val_prc: 0.2201 - val_f1_m: 0.1422\n",
      "Epoch 10/30\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.5314 - tp: 5346.3303 - fp: 50575.7982 - tn: 53691.7798 - fn: 350.3119 - accuracy: 0.5309 - precision: 0.0949 - recall: 0.9469 - auc: 0.8093 - prc: 0.2368 - f1_m: 0.1750 - val_loss: 0.4842 - val_tp: 4697.0000 - val_fp: 47919.0000 - val_tn: 55562.0000 - val_fn: 542.0000 - val_accuracy: 0.5543 - val_precision: 0.0893 - val_recall: 0.8965 - val_auc: 0.8104 - val_prc: 0.2289 - val_f1_m: 0.1424\n",
      "Epoch 11/30\n",
      "108/108 [==============================] - 2s 16ms/step - loss: 0.5310 - tp: 5236.6330 - fp: 48681.2477 - tn: 55572.8165 - fn: 473.5229 - accuracy: 0.5530 - precision: 0.0965 - recall: 0.9174 - auc: 0.8114 - prc: 0.2416 - f1_m: 0.1800 - val_loss: 0.4617 - val_tp: 4552.0000 - val_fp: 46477.0000 - val_tn: 57004.0000 - val_fn: 687.0000 - val_accuracy: 0.5662 - val_precision: 0.0892 - val_recall: 0.8689 - val_auc: 0.8067 - val_prc: 0.2236 - val_f1_m: 0.1420\n",
      "Epoch 12/30\n",
      "108/108 [==============================] - 1s 14ms/step - loss: 0.5304 - tp: 5132.4587 - fp: 46817.6147 - tn: 57409.3486 - fn: 604.7982 - accuracy: 0.5568 - precision: 0.0980 - recall: 0.9128 - auc: 0.8128 - prc: 0.2518 - f1_m: 0.1838 - val_loss: 0.4842 - val_tp: 4647.0000 - val_fp: 46271.0000 - val_tn: 57210.0000 - val_fn: 592.0000 - val_accuracy: 0.5690 - val_precision: 0.0913 - val_recall: 0.8870 - val_auc: 0.8096 - val_prc: 0.2215 - val_f1_m: 0.1446\n",
      "Epoch 13/30\n",
      "108/108 [==============================] - 2s 14ms/step - loss: 0.5358 - tp: 5234.1651 - fp: 46804.3028 - tn: 57389.8532 - fn: 535.8991 - accuracy: 0.5592 - precision: 0.1002 - recall: 0.9244 - auc: 0.8143 - prc: 0.2349 - f1_m: 0.1875 - val_loss: 0.4449 - val_tp: 4393.0000 - val_fp: 42581.0000 - val_tn: 60900.0000 - val_fn: 846.0000 - val_accuracy: 0.6006 - val_precision: 0.0935 - val_recall: 0.8385 - val_auc: 0.8097 - val_prc: 0.2256 - val_f1_m: 0.1467\n",
      "Epoch 14/30\n",
      "108/108 [==============================] - 2s 15ms/step - loss: 0.5331 - tp: 5538.3028 - fp: 51282.4679 - tn: 52924.8165 - fn: 218.6330 - accuracy: 0.5351 - precision: 0.0986 - recall: 0.9631 - auc: 0.8147 - prc: 0.2436 - f1_m: 0.1791 - val_loss: 0.4133 - val_tp: 4578.0000 - val_fp: 46734.0000 - val_tn: 56747.0000 - val_fn: 661.0000 - val_accuracy: 0.5641 - val_precision: 0.0892 - val_recall: 0.8738 - val_auc: 0.8067 - val_prc: 0.2241 - val_f1_m: 0.1417\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n"
     ]
    }
   ],
   "source": [
    "b_size=2000 # important to be high enough to contain information on positive class\n",
    "e=30\n",
    "early_stop= tf.keras.callbacks.EarlyStopping(monitor='val_f1_m', verbose = 1, patience=10, mode='max', restore_best_weights=True)\n",
    "\n",
    "cw_history_i = cw_model_i.fit(\n",
    "    x=X_tr_arr, \n",
    "    y=y_tr_arr_imp_delay_binary,\n",
    "    batch_size=b_size,\n",
    "    epochs=e,\n",
    "    callbacks=[early_stop],\n",
    "    validation_data=(X_va_arr_reindex, y_va_arr_imp_delay_binary),\n",
    "    shuffle=True, # Shuffle training samples\n",
    "    class_weight=class_weight_i\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check training history\n",
    "\n",
    "plot_metrics(cw_history_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8264936208724976,\n",
       " 0.8948272466659546,\n",
       " 0.8808932900428772,\n",
       " 0.5245276093482971,\n",
       " 0.9421645402908325,\n",
       " 0.5543042421340942,\n",
       " 0.8289750218391418,\n",
       " 0.8266844749450684,\n",
       " 0.8961634039878845,\n",
       " 0.8965451717376709,\n",
       " 0.8688681125640869,\n",
       " 0.8870013356208801,\n",
       " 0.8385187983512878,\n",
       " 0.8738308548927307]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cw_history_i.history['val_recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "y_pred_va_keras_i = cw_model_i.predict(X_va_arr_reindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       no_delay       0.97      0.85      0.91    103481\n",
      "important_delay       0.15      0.52      0.23      5239\n",
      "\n",
      "       accuracy                           0.83    108720\n",
      "      macro avg       0.56      0.69      0.57    108720\n",
      "   weighted avg       0.93      0.83      0.87    108720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_keras_i = classification_report(y_true=y_va_arr_imp_delay_binary, y_pred=(y_pred_va_keras_i > 0.5)*1 , target_names=['no_delay','important_delay'])\n",
    "print(report_keras_i)\n",
    "# why f1-score better for \"important delay\" in multi-class over binary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under PR Curve: 0.226\n"
     ]
    }
   ],
   "source": [
    "# Precision-recall curve metrics\n",
    "keras_precision_i, keras_recall_i, keras_thres_i = precision_recall_curve(y_va_arr_imp_delay_binary, y_pred_va_keras_i, pos_label=1)\n",
    "keras_auprc_i = auc(keras_recall_i, keras_precision_i)\n",
    "print('Area Under PR Curve: {:.3f}'.format(keras_auprc_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimize threshold (Keras - Important delay) <a name='keras_imp_delay_thres' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.604\n",
      "Probabilities: [[0.49247447]\n",
      " [0.492954  ]\n",
      " [0.5895435 ]\n",
      " [0.59583604]\n",
      " [0.728505  ]\n",
      " [0.5253348 ]\n",
      " [0.6661505 ]\n",
      " [0.6897077 ]\n",
      " [0.5935712 ]\n",
      " [0.5493499 ]]\n",
      "Predictions: [[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import argmax\n",
    "fscores_keras_i = (2 * keras_precision_i * keras_recall_i) / (keras_precision_i + keras_recall_i)\n",
    "keras_bt_i = keras_thres_i[argmax(fscores_keras_i)]\n",
    "print('Best Threshold: {:.3f}'.format(keras_bt_i))\n",
    "# use threshold in model\n",
    "keras_curve_i = np.where(y_pred_va_keras_i > keras_bt_i, 1,0)\n",
    "print('Probabilities:',y_pred_va_keras_i[0:10])\n",
    "print('Predictions:',keras_curve_i[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report (Keras - Important delay) <a name='keras_imp_delay_report' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: Keras delay - optimzed threshold at 0.604 on PR curve\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       no_delay       0.96      0.94      0.95    103481\n",
      "important_delay       0.22      0.32      0.26      5239\n",
      "\n",
      "       accuracy                           0.91    108720\n",
      "      macro avg       0.59      0.63      0.61    108720\n",
      "   weighted avg       0.93      0.91      0.92    108720\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report: Keras delay - optimzed threshold at {:.3f} on PR curve'.format(keras_bt_i))\n",
    "report_keras_preds_i = classification_report(y_true=y_va_arr_imp_delay_binary, y_pred=keras_curve_i, target_names=['no_delay','important_delay'])\n",
    "#f1_logreg_pr_d = classification_report(y_true=y_va_arr_delay_binary, y_pred=lr_curve_d, target_names=['no_delay','delay'], output_dict=True)['delay']['f1-score']\n",
    "print(report_keras_preds_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix (Keras - Important delay) <a name='keras_imp_delay_matrix' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (normalized): Keras Important delay\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred: no delay</th>\n",
       "      <th>pred: delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true: no delay</th>\n",
       "      <td>0.618561</td>\n",
       "      <td>0.178458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true: delay</th>\n",
       "      <td>0.055537</td>\n",
       "      <td>0.147443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pred: no delay  pred: delay\n",
       "true: no delay        0.618561     0.178458\n",
       "true: delay           0.055537     0.147443"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix 'RF important delay'\n",
    "matrix_keras_i = confusion_matrix(y_true=y_va_arr_imp_delay_binary, y_pred=keras_curve_i,normalize='all') # normalize either on columns/rows or all\n",
    "matrix_keras_i = pd.DataFrame(\n",
    "    matrix_keras_i, \n",
    "    columns=['pred: no delay', 'pred: important_delay'],\n",
    "    index=['true: no delay', 'true: important_delay']\n",
    ")\n",
    "print('Confusion matrix (normalized): Keras Important delay')\n",
    "matrix_keras_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments (Keras):**\n",
    "* Model seems to be able to capture patterns from early iterations/epochs and has therefore low improvements (as can be seen on 4-box line graphs)\n",
    "* Overall strong performance on both delay and important delay with high f1 scores on par with best classifiers at 0.56 and 0.23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance on test set (Keras) <a name='keras_test' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under PR Curve: 0.647\n",
      "Probabilities: [[0.5925672 ]\n",
      " [0.54520875]\n",
      " [0.5689906 ]\n",
      " [0.56060505]\n",
      " [0.9215561 ]\n",
      " [0.48765883]\n",
      " [0.8491559 ]\n",
      " [0.9017005 ]\n",
      " [0.6197516 ]\n",
      " [0.5346859 ]]\n",
      "Predictions: [[1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      "Classification report: Keras delay TEST - optimzed threshold at 0.569 on PR curve\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    no_delay       0.89      0.80      0.84     80088\n",
      "       delay       0.55      0.71      0.62     27278\n",
      "\n",
      "    accuracy                           0.78    107366\n",
      "   macro avg       0.72      0.76      0.73    107366\n",
      "weighted avg       0.80      0.78      0.79    107366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# delay\n",
    "keras_test_probs_pos_d = cw_model.predict(X_te_arr_reindex)\n",
    "keras_precision_test_d, keras_recall_test_d, _ = precision_recall_curve(y_te_arr_delay_binary, keras_test_probs_pos_d, pos_label=1)\n",
    "keras_test_auc_pr_d = auc(keras_recall_test_d, keras_precision_test_d)\n",
    "print('Area Under PR Curve: {:.3f}'.format(keras_test_auc_pr_d))\n",
    "# use threshold in model\n",
    "keras_test_d = np.where(cw_model.predict(X_te_arr_reindex) > keras_bt_d, 1,0) # with Keras 'predict' gives probability (shouldn't use 'predict_proba')\n",
    "print('Probabilities:',cw_model.predict(X_te_arr_reindex)[0:10])\n",
    "print('Predictions:',keras_test_d[0:10])\n",
    "print('Classification report: Keras delay TEST - optimzed threshold at {:.3f} on PR curve'.format(keras_bt_d))\n",
    "report_keras_test_d = classification_report(y_true=y_te_arr_delay_binary, y_pred=keras_test_d, target_names=['no_delay','delay'])\n",
    "f1_keras_test_d = classification_report(y_true=y_te_arr_delay_binary, y_pred=keras_test_d, target_names=['no_delay','delay'], output_dict=True)['delay']['f1-score']\n",
    "precision_keras_test_d = classification_report(y_true=y_te_arr_delay_binary, y_pred=keras_test_d, target_names=['no_delay','delay'], output_dict=True)['delay']['precision']\n",
    "recall_keras_test_d = classification_report(y_true=y_te_arr_delay_binary, y_pred=keras_test_d, target_names=['no_delay','delay'], output_dict=True)['delay']['recall']\n",
    "print(report_keras_test_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under PR Curve: 0.288\n",
      "Probabilities: [[0.49247447]\n",
      " [0.492954  ]\n",
      " [0.5895435 ]\n",
      " [0.59583604]\n",
      " [0.728505  ]\n",
      " [0.5253348 ]\n",
      " [0.6661505 ]\n",
      " [0.6897077 ]\n",
      " [0.5935712 ]\n",
      " [0.5493499 ]]\n",
      "Predictions: [[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "Classification report: Keras important delay TEST - optimzed threshold at 0.604 on PR curve\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       no_delay       0.95      0.95      0.95    100362\n",
      "important_delay       0.30      0.33      0.31      7004\n",
      "\n",
      "       accuracy                           0.91    107366\n",
      "      macro avg       0.63      0.64      0.63    107366\n",
      "   weighted avg       0.91      0.91      0.91    107366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# important delay\n",
    "keras_test_probs_pos_i = cw_model_i.predict(X_te_arr_reindex)\n",
    "keras_precision_test_i, keras_recall_test_i, _ = precision_recall_curve(y_te_arr_imp_delay_binary, keras_test_probs_pos_i, pos_label=1)\n",
    "keras_test_auc_pr_i = auc(keras_recall_test_i, keras_precision_test_i)\n",
    "print('Area Under PR Curve: {:.3f}'.format(keras_test_auc_pr_i))\n",
    "# use threshold in model\n",
    "keras_test_i = np.where(cw_model_i.predict(X_te_arr_reindex) > keras_bt_i, 1,0) # with Keras 'predict' gives probability (shouldn't use 'predict_proba')\n",
    "print('Probabilities:',cw_model_i.predict(X_te_arr_reindex)[0:10])\n",
    "print('Predictions:',keras_test_i[0:10])\n",
    "print('Classification report: Keras important delay TEST - optimzed threshold at {:.3f} on PR curve'.format(keras_bt_i))\n",
    "report_keras_test_i = classification_report(y_true=y_te_arr_imp_delay_binary, y_pred=keras_test_i, target_names=['no_delay','important_delay'])\n",
    "f1_keras_test_i = classification_report(y_true=y_te_arr_imp_delay_binary, y_pred=keras_test_i, target_names=['no_delay','important_delay'], output_dict=True)['important_delay']['f1-score']\n",
    "precision_keras_test_i = classification_report(y_true=y_te_arr_imp_delay_binary, y_pred=keras_test_i, target_names=['no_delay','important_delay'], output_dict=True)['important_delay']['precision']\n",
    "recall_keras_test_i = classification_report(y_true=y_te_arr_imp_delay_binary, y_pred=keras_test_i, target_names=['no_delay','important_delay'], output_dict=True)['important_delay']['recall']\n",
    "print(report_keras_test_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final comparison and comments\n",
    "*<a href=#top>Back to top</a>*\n",
    "\n",
    "### Final comments\n",
    "- **F1 scores:**\n",
    "    * Delay: \n",
    "        * Two classifiers (k-NN untuned and RandomForest) are under-performing slightly\n",
    "        * All other clasifiers are reaching almost same f1 score ~0.63 with LogisticRegression reaching the highest score at 0.635\n",
    "        * From all classifiers performing well, Keras is the one with the best balance between precision (0.55) and recall (0.71)\n",
    "    * Important delay:\n",
    "        * Two classifiers (k-NN untuned and DecisionTree) are under-performing slightly\n",
    "        * All other clasifiers are reaching almost same f1 score ~0.30 with Keras reaching the highest score at 0.313\n",
    "        * From all classifiers performing well LogisticRegression, RandomForest and Keras have the strongest balance between precision and recall (0.55)\n",
    "- **Area under Precision-Recall:**\n",
    "    * Delay:\n",
    "        * Baseline (0.25) is largely over-performed by all classifiers (0.58 to 0.64)\n",
    "        * SVC Linear and LogisticRegression achieve the highest AUC with 0.652, Keras is very second with 0.647\n",
    "    * Important delay: \n",
    "        * Baseline (0.06) is largely over-performed by all classifiers (0.22 to 0.29)\n",
    "        * Keras achieves the highst AUC with 0.288, SVC Linear (0.281) very close\n",
    "\n",
    "\n",
    "* **Overall comment:** link back to initial question. How often trains are delay at arrival? Is it possible to predict?\n",
    "    * Classifiers: Keras, LogisticRegression and Linear SVC seem to be over-performing other classifiers on those tasks and getting very close results one to another. DecisionTree and RandomForest have good results on train-validatoin sets but seems to have over-fitting impacting performance on test set. K-NN achieves good performance given the fact is has not been tuned.\n",
    "    * Optimization: hyper-parameters (incl. class_weight) tuning and threshold optimization prove to have significant impact on final performance of the models\n",
    "    * Preditions: Overall performance relatively low with precision and recall between 0.5 and 0.7 seems to indicate there are limited number of patterns to extract from the data to perdict delay. This would indicate that delays are not a systematic issues in some connection, don't happen frequently on same connection and are therefore relatively hard to precit\n",
    "    \n",
    "\n",
    "- **Limitations and additional steps:**\n",
    "    * Limitation - scope: would have needed to use more data points to get to better models. It seems there was very few patterns to identify from 2-3 weeks of data (which probably indicates that delays on swiss trian network is rather rare and not frequent on same lines). Could have limited to even smaller scope but include 2-3 months of data.\n",
    "    * Limitation - features: additional feature engineering or external data points could have helped enhanced a data set which had alsmot only categorical variables\n",
    "    * Additional steps: didn't cover over- and under-sampling which would also improve performance\n",
    "    * Alternative steps: could have thought of aggregating data and buildling model for example at \"stop\" level instead of each connections. This could have allowed to take into consideration data for a longer time period\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final comparison <a name='final' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 scores <a name='final_f1' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELAY - F1 SCORE\n",
      "LogisticRegression - delay: 0.635\n",
      "k-nn - delay: 0.537\n",
      "SVC Linear - delay: 0.628\n",
      "DecisionTree - delay: 0.627\n",
      "RandomForest - delay: 0.595\n",
      "Keras - delay: 0.620\n",
      "***\n",
      "IMPORTANT DELAY - F1 SCORE\n",
      "LogisticRegression - important delay: 0.298\n",
      "k-nn - important delay: 0.163\n",
      "SVC Linear - important delay: 0.322\n",
      "DecisionTree - important delay: 0.216\n",
      "RandomForest - important delay: 0.296\n",
      "Keras - important delay: 0.313\n"
     ]
    }
   ],
   "source": [
    "print('DELAY - F1 SCORE')\n",
    "print('LogisticRegression - delay: {:.3f}'.format(f1_logreg_test_d))\n",
    "print('k-nn - delay: {:.3f}'.format(f1_knn_test_d))\n",
    "print('SVC Linear - delay: {:.3f}'.format(f1_svc_test_d))\n",
    "print('DecisionTree - delay: {:.3f}'.format(f1_dt_test_d))\n",
    "print('RandomForest - delay: {:.3f}'.format(f1_rf_test_d))\n",
    "print('Keras - delay: {:.3f}'.format(f1_keras_test_d))\n",
    "print('***')\n",
    "print('IMPORTANT DELAY - F1 SCORE')\n",
    "print('LogisticRegression - important delay: {:.3f}'.format(f1_logreg_test_i))\n",
    "print('k-nn - important delay: {:.3f}'.format(f1_knn_test_i))\n",
    "print('SVC Linear - important delay: {:.3f}'.format(f1_svc_test_i))\n",
    "print('DecisionTree - important delay: {:.3f}'.format(f1_dt_test_i))\n",
    "print('RandomForest - important delay: {:.3f}'.format(f1_rf_test_i))\n",
    "print('Keras - important delay: {:.3f}'.format(f1_keras_test_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bar charts comparison on f1, precision and recall <a name='final_bar' />\n",
    "*<a href=#top>Back to top</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_f1=[1,2,3,4,5,6]\n",
    "x_precision = []\n",
    "for x_p in x_f1: x_precision.append(x_p + 0.2)\n",
    "x_recall = []\n",
    "for x_r in x_f1: x_recall.append(x_r - 0.2)\n",
    "    \n",
    "h_f1_d = [f1_logreg_test_d,f1_knn_test_d,f1_svc_test_d,f1_dt_test_d,f1_rf_test_d,f1_keras_test_d]\n",
    "h_precision_d = [precision_logreg_test_d,precision_knn_test_d,precision_svc_test_d,precision_dt_test_d,precision_rf_test_d,precision_keras_test_d]\n",
    "h_recall_d = [recall_logreg_test_d,recall_knn_test_d,recall_svc_test_d,recall_dt_test_d,recall_rf_test_d,recall_keras_test_d]\n",
    "\n",
    "plt.bar(x=x_f1, height=h_f1_d, label='F1 score', alpha=0.8)\n",
    "plt.bar(x=x_precision, height=h_recall_d, color='orange', alpha=0.2, width=0.4, label='Precision')\n",
    "plt.bar(x=x_recall, height=h_precision_d, color='red', alpha=0.2, width=0.4, label='Recall')\n",
    "plt.xticks(ticks=[1,2,3,4,5,6],labels=['LogisticRegression','K-NN','SVC Linear','DecisionTree','RandomForest','Keras'], rotation=70)\n",
    "plt.ylabel('F1, Precision and Recall - Delay')\n",
    "plt.ylim((0.4,1))\n",
    "plt.title('Delay prediction - classifiers comparison')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_f1=[1,2,3,4,5,6,7]\n",
    "x_precision = []\n",
    "for x_p in x_f1: x_precision.append(x_p + 0.2)\n",
    "x_recall = []\n",
    "for x_r in x_f1: x_recall.append(x_r - 0.2)\n",
    "    \n",
    "h_f1_i = [f1_logreg_test_i,f1_knn_test_i,f1_svc_test_i,f1_dt_test_i,f1_rf_test_i,f1_rf_test_m,f1_keras_test_i]\n",
    "h_precision_i = [precision_logreg_test_i,precision_knn_test_i,precision_svc_test_i,precision_dt_test_i,precision_rf_test_i,precision_rf_test_m,precision_keras_test_i]\n",
    "h_recall_i = [recall_logreg_test_i,recall_knn_test_i,recall_svc_test_i,recall_dt_test_i,recall_rf_test_i,recall_rf_test_m,recall_keras_test_i]\n",
    "\n",
    "plt.bar(x=x_f1, height=h_f1_i, label='F1 score', alpha=0.8)\n",
    "plt.bar(x=x_precision, height=h_recall_i, color='orange', alpha=0.2, width=0.4, label='Precision')\n",
    "plt.bar(x=x_recall, height=h_precision_i, color='red', alpha=0.2, width=0.4, label='Recall')\n",
    "plt.xticks(ticks=[1,2,3,4,5,6,7],labels=['LogisticRegression','K-NN','SVC Linear','DecisionTree','RandomForest','RandomForest Multi','Keras'], rotation=70)\n",
    "plt.ylabel('F1, Precision and Recall - Important delay')\n",
    "plt.ylim((0,1))\n",
    "plt.title('Important delay prediction - classifiers comparison')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# have area under curve directly after name of classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Area under precision-recall cuvre comparison <a name='final_auprc' />\n",
    "*<a href=#top>Back to top</a>*\n",
    "<br>*<a href=#logreg_a_pr>Initial area under pr curve</a>*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELAY - AUPRC\n",
      "LogisticRegression - delay: 0.652\n",
      "k-nn - delay: 0.610\n",
      "SVC Linear - delay: 0.652\n",
      "DecisionTree - delay: 0.591\n",
      "RandomForest - delay: 0.583\n",
      "Keras - delay: 0.647\n",
      "***\n",
      "IMPORTANT DELAY - AUPRC\n",
      "LogisticRegression - important delay: 0.270\n",
      "k-nn - important delay: 0.223\n",
      "SVC Linear - important delay: 0.281\n",
      "DecisionTree - important delay: 0.256\n",
      "RandomForest - important delay: 0.263\n",
      "Keras - important delay: 0.288\n"
     ]
    }
   ],
   "source": [
    "## probably still needs to be calculated for test test for all classifiers \n",
    "\n",
    "print('DELAY - AUPRC')\n",
    "print('LogisticRegression - delay: {:.3f}'.format(lr_test_auc_pr_d)) # on validation data\n",
    "print('k-nn - delay: {:.3f}'.format(knn_test_auc_pr_d))\n",
    "print('SVC Linear - delay: {:.3f}'.format(svc_test_auc_pr_d))\n",
    "print('DecisionTree - delay: {:.3f}'.format(dt_test_auc_pr_d))\n",
    "print('RandomForest - delay: {:.3f}'.format(rf_test_auc_pr_d))\n",
    "print('Keras - delay: {:.3f}'.format(keras_test_auc_pr_d))\n",
    "print('***')\n",
    "print('IMPORTANT DELAY - AUPRC')\n",
    "print('LogisticRegression - important delay: {:.3f}'.format(lr_test_auc_pr_i)) # on validation data\n",
    "print('k-nn - important delay: {:.3f}'.format(knn_test_auc_pr_i))\n",
    "print('SVC Linear - important delay: {:.3f}'.format(svc_test_auc_pr_i))\n",
    "print('DecisionTree - important delay: {:.3f}'.format(dt_test_auc_pr_i))\n",
    "print('RandomForest - important delay: {:.3f}'.format(rf_test_auc_pr_i))\n",
    "print('Keras - important delay: {:.3f}'.format(keras_test_auc_pr_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the precision-recall curves for all models on test set\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "lr_precision_test_d, lr_recall_test_d, _ = precision_recall_curve(y_te_arr_delay_binary, lr_test_probs_pos_d, pos_label=1)\n",
    "lr_test_auc_pr_d\n",
    "\n",
    "ax1.plot([0,1], [(27278/107366),(27278/107366)], linestyle='--', label='Baseline, {:.3f}'.format(27278/107366))  # baseline is share of positive classes\n",
    "ax1.plot(lr_recall_test_d, lr_precision_test_d, marker='.', label='logistic, {:.3f}'.format(lr_test_auc_pr_d))\n",
    "ax1.plot(knn_recall_test_d, knn_precision_test_d, marker='.', label='knn, {:.3f}'.format(knn_test_auc_pr_d))\n",
    "ax1.plot(svc_recall_test_d, svc_precision_test_d, marker='.', label='SVC Linear, {:.3f}'.format(svc_test_auc_pr_d))\n",
    "ax1.plot(dt_recall_test_d, dt_precision_test_d, marker='.', label='DecisionTree, {:.3f}'.format(dt_test_auc_pr_d))\n",
    "ax1.plot(rf_recall_test_d, rf_precision_test_d, marker='.', label='RandomForest, {:.3f}'.format(rf_test_auc_pr_d))\n",
    "ax1.plot(keras_recall_test_d, keras_precision_test_d, marker='.', label='Keras, {:.3f}'.format(keras_test_auc_pr_d))\n",
    "ax1.set_xlabel('Recall')\n",
    "ax1.set_ylabel('Precision')\n",
    "ax1.legend(title='Area under curve')\n",
    "ax1.set_title('PR curve: Delay')\n",
    "\n",
    "ax2.plot([0,1], [(7004/107366),(7004/107366)], linestyle='--', label='Baseline, {:.3f}'.format(7004/107366))  # baseline is share of positive classes\n",
    "ax2.plot(lr_recall_test_i, lr_precision_test_i, marker='.', label='logistic, {:.3f}'.format(lr_test_auc_pr_i))\n",
    "ax2.plot(knn_recall_test_i, knn_precision_test_i, marker='.', label='knn, {:.3f}'.format(knn_test_auc_pr_i))\n",
    "ax2.plot(svc_recall_test_i, svc_precision_test_i, marker='.', label='SVC Linear, {:.3f}'.format(svc_test_auc_pr_i))\n",
    "ax2.plot(dt_recall_test_i, dt_precision_test_i, marker='.', label='DecisionTree, {:.3f}'.format(dt_test_auc_pr_i))\n",
    "ax2.plot(rf_recall_test_i, rf_precision_test_i, marker='.', label='RandomForest, {:.3f}'.format(rf_test_auc_pr_i))\n",
    "ax2.plot(keras_recall_test_i, keras_precision_test_i, marker='.', label='Keras, {:.3f}'.format(keras_test_auc_pr_i))\n",
    "ax2.set_xlabel('Recall')\n",
    "ax2.set_ylabel('Precision')\n",
    "ax2.legend(title='Area under curve')\n",
    "ax2.set_title('PR curve: Important delay')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: incorrect title above, please ignore 'Logistic Regression'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
